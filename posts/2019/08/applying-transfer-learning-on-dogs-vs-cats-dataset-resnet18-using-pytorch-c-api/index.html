<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C++ API | Kushashwa Ravi Shrimali (Kush)</title><meta name=keywords content="development,coding,cpp,notes,pytorch-cpp,libtorch"><meta name=description content="Transfer Learning
&ndash;
Before we go ahead and discuss the Why question of Transfer Learning, let&rsquo;s have a look at What is Transfer Learning? Let&rsquo;s have a look at the Notes from CS231n on Transfer Learning:

In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest."><meta name=author content="Kushashwa Ravi Shrimali"><link rel=canonical href=https://krshrimali.github.io/posts/2019/08/applying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api/><link crossorigin=anonymous href=https://krshrimali.github.io/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css integrity="sha256-j+ECM6cGvIfy4Is8+XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as=style><link rel=icon href=https://krshrimali.github.io/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://krshrimali.github.io/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://krshrimali.github.io/favicon-32x32.png><link rel=apple-touch-icon href=https://krshrimali.github.io/apple-touch-icon.png><link rel=mask-icon href=https://krshrimali.github.io/safari-pinned-tab.svg><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><link rel=alternate hreflang=en href=https://krshrimali.github.io/posts/2019/08/applying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api/><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--code-block-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><link rel=stylesheet href=https://krshrimali.github.io/css/custom.css><meta property="og:url" content="https://krshrimali.github.io/posts/2019/08/applying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api/"><meta property="og:site_name" content="Kushashwa Ravi Shrimali (Kush)"><meta property="og:title" content="Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C++ API"><meta property="og:description" content="Transfer Learning – Before we go ahead and discuss the Why question of Transfer Learning, let’s have a look at What is Transfer Learning? Let’s have a look at the Notes from CS231n on Transfer Learning:
In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest."><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="article:section" content="posts"><meta property="article:published_time" content="2019-08-16T00:00:00+00:00"><meta property="article:modified_time" content="2019-08-16T00:00:00+00:00"><meta property="article:tag" content="Development"><meta property="article:tag" content="Coding"><meta property="article:tag" content="Cpp"><meta property="article:tag" content="Notes"><meta property="article:tag" content="Pytorch-Cpp"><meta property="article:tag" content="Libtorch"><meta name=twitter:card content="summary"><meta name=twitter:title content="Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C++ API"><meta name=twitter:description content="Transfer Learning
&ndash;
Before we go ahead and discuss the Why question of Transfer Learning, let&rsquo;s have a look at What is Transfer Learning? Let&rsquo;s have a look at the Notes from CS231n on Transfer Learning:

In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest."></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://krshrimali.github.io/ accesskey=h title="Kushashwa Ravi Shrimali (Kush) (Alt + H)">Kushashwa Ravi Shrimali (Kush)</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)" aria-label="Toggle theme">
<svg id="moon" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg>
<svg id="sun" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://krshrimali.github.io/search/ title="Search (Alt + /)" accesskey=/><span>Search</span></a></li><li><a href=https://krshrimali.github.io/about title=About><span>About</span></a></li><li><a href=https://krshrimali.github.io/posts title=Blog><span>Blog</span></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><div class=breadcrumbs><a href=https://krshrimali.github.io/>Home</a>&nbsp;»&nbsp;<a href=https://krshrimali.github.io/posts/>Posts</a></div><h1 class="post-title entry-hint-parent">Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C++ API</h1><div class=post-meta><span title='2019-08-16 00:00:00 +0000 UTC'>August 16, 2019</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;Kushashwa Ravi Shrimali</div></header><div class=toc><details><summary accesskey=c title="(Alt + C)"><span class=details>Table of Contents</span></summary><div class=inner><ul><li><a href=#transfer-learning aria-label="Transfer Learning">Transfer Learning</a></li><li><a href=#setting-up-the-data-with-pytorch-c-api aria-label="Setting up the data with PyTorch C++ API">Setting up the data with PyTorch C++ API</a></li><li><a href=#loading-the-pre-trained-model aria-label="Loading the pre-trained model">Loading the pre-trained model</a><ul><li><a href=#step-1-download-the-pre-trained-model-of-resnet18 aria-label="Step-1: Download the pre-trained model of ResNet18">Step-1: Download the pre-trained model of ResNet18</a></li><li><a href=#step-2-load-the-pre-trained-model aria-label="Step-2: Load the pre-trained model">Step-2: Load the pre-trained model</a></li></ul></li><li><a href=#trainining-the-fc-layer aria-label="Trainining the FC Layer">Trainining the FC Layer</a></li><li><a href=#results aria-label=Results>Results</a></li><li><a href=#acknowledgements aria-label=Acknowledgements>Acknowledgements</a></li></ul></div></details></div><div class=post-content><h2 id=transfer-learning>Transfer Learning<a hidden class=anchor aria-hidden=true href=#transfer-learning>#</a></h2><p>&ndash;
Before we go ahead and discuss the <strong>Why</strong> question of Transfer Learning, let&rsquo;s have a look at <strong>What is Transfer Learning?</strong> Let&rsquo;s have a look at the <a href=http://cs231n.github.io/transfer-learning>Notes</a> from CS231n on Transfer Learning:</p><blockquote><p>In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest.</p></blockquote><p><img loading=lazy src=https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Cover-Transfer-Learning.jpg></p><p>There are 3 scenarios possible:</p><ol><li>When the data you have is similar (but not enough) to data trained on pre-trained model: Take an example of a pre-trained model trained on ImageNet dataset (containing 1000 classes). And the data we have has Dogs and Cats classes. Fortunate enough, ImageNet has some of the classes of Dog and Cat breeds and thus the model must have learned important features from the data. Let&rsquo;s say we don&rsquo;t have enough data but since the data is similar to the breeds in the ImageNet data set, we can simply use the ConvNet (except the last FC layer) to extract features from our dataset and train only the last Linear (FC) layer.</li><li>When you have enough data (and is similar to the data trained with pre-trained model): Then you might go for fine tuning the weights of all the layers in the network. This is largely due to the reason that we know we won&rsquo;t overfit because we have enough data.</li><li>Using pre-trained models might just be enough if you have the data which matches the classes in the original data set.</li></ol><p>Transfer Learning came into existence (the answer of <strong>Why Transfer Learning?</strong>) because of some major reasons, which include:</p><ol><li>Lack of resources or data set to train a CNN. At times, we either don&rsquo;t have enough data or we don&rsquo;t have enough resources to train a CNN from scratch.</li><li>Random Initialization of weights vs Initialization of weights from the pre-trained model. Sometimes, it&rsquo;s just better to initialize weights from the pre-trained model (as it must have learned the generic features from it&rsquo;s data set) instead of randomly initializing the weights.</li></ol><h2 id=setting-up-the-data-with-pytorch-c-api>Setting up the data with PyTorch C++ API<a hidden class=anchor aria-hidden=true href=#setting-up-the-data-with-pytorch-c-api>#</a></h2><p>At every stage, we will compare the Python and C++ codes to do the same thing, to make the analogy easier and understandable. Starting with setting up the data we have. Note that we do have enough data and it is also similar to the original data set of ImageNet, but since I don&rsquo;t have enough resources to fine tune through the whole network, we perform Transfer Learning on the final FC layer only.</p><p>Starting with loading the dataset, as discussed in the blogs before, I&rsquo;ll just post a flow chart of procedure.</p><p><img loading=lazy src=https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Steps-Loading-Data-PyTorch.png></p><p>Once done, we can initialize the <code>CustomDataset</code> class:</p><p><strong>C++</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#75715e>// List of images of Dogs and Cats, use load_data_from_folder function explained in previous blogs
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>std<span style=color:#f92672>::</span>vector<span style=color:#f92672>&lt;</span>std<span style=color:#f92672>::</span>string<span style=color:#f92672>&gt;</span> list_images; 
</span></span><span style=display:flex><span><span style=color:#75715e>// List of labels of the images
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>std<span style=color:#f92672>::</span>vector<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>int</span><span style=color:#f92672>&gt;</span> list_labels; 
</span></span><span style=display:flex><span><span style=color:#66d9ef>auto</span> custom_dataset <span style=color:#f92672>=</span> CustomDataset(list_images, list_labels).map(torch<span style=color:#f92672>::</span>data<span style=color:#f92672>::</span>transforms<span style=color:#f92672>::</span>Stack<span style=color:#f92672>&lt;&gt;</span>());
</span></span></code></pre></div><p><strong>Python</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#f92672>from</span> torchvision <span style=color:#f92672>import</span> datasets, transforms
</span></span><span style=display:flex><span><span style=color:#f92672>import</span> torch
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>folder_path <span style=color:#f92672>=</span> <span style=color:#e6db74>&#34;/Users/krshrimali/Documents/dataset/train/&#34;</span>
</span></span><span style=display:flex><span>transform <span style=color:#f92672>=</span> transforms<span style=color:#f92672>.</span>Compose([transforms<span style=color:#f92672>.</span>CenterCrop(<span style=color:#ae81ff>224</span>), transforms<span style=color:#f92672>.</span>ToTensor())
</span></span><span style=display:flex><span>data <span style=color:#f92672>=</span> datasets<span style=color:#f92672>.</span>ImageFolder(root <span style=color:#f92672>=</span> os<span style=color:#f92672>.</span>path<span style=color:#f92672>.</span>join(folder_path), transform <span style=color:#f92672>=</span> transform)
</span></span></code></pre></div><p>We then use <code>RandomSampler</code> to make our data loader: (Note: it&rsquo;s important to use <code>RandomSampler</code> as we load the images sequentially and we want mixture of images in each batch of data passed to the network in an epoch)</p><p><strong>C++</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#66d9ef>int</span> batch_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>4</span>;
</span></span><span style=display:flex><span><span style=color:#66d9ef>auto</span> data_loader <span style=color:#f92672>=</span> torch<span style=color:#f92672>::</span>data<span style=color:#f92672>::</span>make_data_loader<span style=color:#f92672>&lt;</span>torch<span style=color:#f92672>::</span>data<span style=color:#f92672>::</span>samplers<span style=color:#f92672>::</span>RandomSampler<span style=color:#f92672>&gt;</span>(std<span style=color:#f92672>::</span>move(custom_dataset), batch_size);
</span></span></code></pre></div><p><strong>Python</strong></p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>batch_size <span style=color:#f92672>=</span> <span style=color:#ae81ff>4</span>
</span></span><span style=display:flex><span>data_loader <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>utils<span style=color:#f92672>.</span>data<span style=color:#f92672>.</span>DataLoader(dataset<span style=color:#f92672>=</span>data, batch_size <span style=color:#f92672>=</span> batch_size, shuffle <span style=color:#f92672>=</span> <span style=color:#66d9ef>True</span>)
</span></span></code></pre></div><h2 id=loading-the-pre-trained-model>Loading the pre-trained model<a hidden class=anchor aria-hidden=true href=#loading-the-pre-trained-model>#</a></h2><p>The steps to load the pre-trained model and perform Transfer Learning are listed below:</p><ol><li>Download the pre-trained model of <strong>ResNet18</strong>.</li><li>Load pre-trained model.</li><li>Change output features of the final FC layer of the model loaded. (Number of classes would change from 1000 - ImageNet to 2 - Dogs vs Cats).</li><li>Define optimizer on parameters from the final FC layer to be trained.</li><li>Train the FC layer on Dogs vs Cats dataset.</li><li>Save the model.</li></ol><p>Let&rsquo;s go step by step.</p><h3 id=step-1-download-the-pre-trained-model-of-resnet18>Step-1: Download the pre-trained model of ResNet18<a hidden class=anchor aria-hidden=true href=#step-1-download-the-pre-trained-model-of-resnet18>#</a></h3><p>Thanks to the developers, we do have C++ models available in torchvision
(<a href=https://github.com/pytorch/vision/pull/728>https://github.com/pytorch/vision/pull/728</a>) but for this tutorial, transferring the pre- trained model from Python to C++ using torch.jit is a good idea, as most PyTorch models in the wild are written in Python right now, and people can use this tutorial to learn how to trace their Python model and transfer it to C++.</p><p>First we download the pre-trained model and save it in the form of <code>torch.jit.trace</code> format to our local drive.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># Reference: #TODO- Add Link</span>
</span></span><span style=display:flex><span><span style=color:#f92672>from</span> torchvision <span style=color:#f92672>import</span> models
</span></span><span style=display:flex><span><span style=color:#75715e># Download and load the pre-trained model</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> models<span style=color:#f92672>.</span>resnet18(pretrained<span style=color:#f92672>=</span><span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Set upgrading the gradients to False</span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> param <span style=color:#f92672>in</span> model<span style=color:#f92672>.</span>parameters():
</span></span><span style=display:flex><span>	param<span style=color:#f92672>.</span>requires_grad <span style=color:#f92672>=</span> <span style=color:#66d9ef>False</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e># Save the model except the final FC Layer</span>
</span></span><span style=display:flex><span>resnet18 <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>nn<span style=color:#f92672>.</span>Sequential(<span style=color:#f92672>*</span>list(resnet18<span style=color:#f92672>.</span>children())[:<span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>])
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>example_input <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>rand(<span style=color:#ae81ff>1</span>, <span style=color:#ae81ff>3</span>, <span style=color:#ae81ff>224</span>, <span style=color:#ae81ff>224</span>)
</span></span><span style=display:flex><span>script_module <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>jit<span style=color:#f92672>.</span>trace(resnet18, example_input)
</span></span><span style=display:flex><span>script_module<span style=color:#f92672>.</span>save(<span style=color:#e6db74>&#39;resnet18_without_last_layer.pt&#39;</span>)
</span></span></code></pre></div><p>We will be using <code>resnet18_without_last_layer.pt</code> model file as our pre-trained model for transfer learning.</p><h3 id=step-2-load-the-pre-trained-model>Step-2: Load the pre-trained model<a hidden class=anchor aria-hidden=true href=#step-2-load-the-pre-trained-model>#</a></h3><p>Let&rsquo;s go ahead and load the pre-trained model using <code>torch::jit</code> module. Note that the reason we have converted <code>torch.nn.Module</code> to <code>torch.jit.ScriptModule</code> type, is because C++ API currently does not support loading Python <code>torch.nn.Module</code> models directly.</p><p><strong>C++</strong>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span>torch<span style=color:#f92672>::</span>jit<span style=color:#f92672>::</span>script<span style=color:#f92672>::</span>Module module;
</span></span><span style=display:flex><span><span style=color:#75715e>// argv[1] should be the path to the model
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>module <span style=color:#f92672>=</span> torch<span style=color:#f92672>::</span>jit<span style=color:#f92672>::</span>load(argv[<span style=color:#ae81ff>1</span>]); 
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>/* We need to convert last layer input and output features from (512, 1000) to (512, 2) since we only have 2 classes */</span>
</span></span><span style=display:flex><span>torch<span style=color:#f92672>::</span>nn<span style=color:#f92672>::</span>Linear linear_layer(<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>2</span>);
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#75715e>// Define the optimizer on parameters of linear_layer with learning_rate = 1e-3
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>torch<span style=color:#f92672>::</span>optim<span style=color:#f92672>::</span>Adam optimizer(linear_layer<span style=color:#f92672>-&gt;</span>parameters(), torch<span style=color:#f92672>::</span>optim<span style=color:#f92672>::</span>AdamOptions(<span style=color:#ae81ff>1e-3</span>))
</span></span></code></pre></div><p><strong>Python</strong>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span><span style=color:#75715e># We will directly load the torch.nn pre-trained model</span>
</span></span><span style=display:flex><span>model <span style=color:#f92672>=</span> models<span style=color:#f92672>.</span>resnet18(pretrained <span style=color:#f92672>=</span> <span style=color:#66d9ef>True</span>)
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> param <span style=color:#f92672>in</span> model<span style=color:#f92672>.</span>parameters():
</span></span><span style=display:flex><span>    param<span style=color:#f92672>.</span>requires_grad <span style=color:#f92672>=</span> <span style=color:#66d9ef>False</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>model<span style=color:#f92672>.</span>fc <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>nn<span style=color:#f92672>.</span>Linear(<span style=color:#ae81ff>512</span>, <span style=color:#ae81ff>2</span>)
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> param <span style=color:#f92672>in</span> model<span style=color:#f92672>.</span>fc<span style=color:#f92672>.</span>parameters():
</span></span><span style=display:flex><span>	param<span style=color:#f92672>.</span>requires_grad <span style=color:#f92672>=</span> <span style=color:#66d9ef>True</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>optimizer <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>optim<span style=color:#f92672>.</span>Adam(model<span style=color:#f92672>.</span>fc<span style=color:#f92672>.</span>parameters())
</span></span><span style=display:flex><span>cost <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>nn<span style=color:#f92672>.</span>CrossEntropyLoss()
</span></span></code></pre></div><h2 id=trainining-the-fc-layer>Trainining the FC Layer<a hidden class=anchor aria-hidden=true href=#trainining-the-fc-layer>#</a></h2><p>Let&rsquo;s first have a look at ResNet18 Network Architecture</p><p><img alt=https://www.researchgate.net/figure/ResNet-18-Architecture_tbl1_322476121 loading=lazy src=https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/ResNet18-Architecture.png></p><p>The final step is to train the Fully Connected layer that we inserted at the end of the network (<code>linear_layer</code>). This one should be pretty straight forward, let&rsquo;s see how to do it.</p><p><strong>C++</strong>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-cpp data-lang=cpp><span style=display:flex><span><span style=color:#66d9ef>void</span> <span style=color:#a6e22e>train</span>(torch<span style=color:#f92672>::</span>jit<span style=color:#f92672>::</span>script<span style=color:#f92672>::</span>Module net, torch<span style=color:#f92672>::</span>nn<span style=color:#f92672>::</span>Linear lin, Dataloader<span style=color:#f92672>&amp;</span> data_loader, torch<span style=color:#f92672>::</span>optim<span style=color:#f92672>::</span>Optimizer<span style=color:#f92672>&amp;</span> optimizer, size_t dataset_size) {
</span></span><span style=display:flex><span>    <span style=color:#75715e>/*
</span></span></span><span style=display:flex><span><span style=color:#75715e>     This function trains the network on our data loader using optimizer for given number of epochs.
</span></span></span><span style=display:flex><span><span style=color:#75715e>     
</span></span></span><span style=display:flex><span><span style=color:#75715e>     Parameters
</span></span></span><span style=display:flex><span><span style=color:#75715e>     ==================
</span></span></span><span style=display:flex><span><span style=color:#75715e>     torch::jit::script::Module net: Pre-trained model
</span></span></span><span style=display:flex><span><span style=color:#75715e>     torch::nn::Linear lin: Linear layer
</span></span></span><span style=display:flex><span><span style=color:#75715e>     DataLoader&amp; data_loader: Training data loader
</span></span></span><span style=display:flex><span><span style=color:#75715e>     torch::optim::Optimizer&amp; optimizer: Optimizer like Adam, SGD etc.
</span></span></span><span style=display:flex><span><span style=color:#75715e>     size_t dataset_size: Size of training dataset
</span></span></span><span style=display:flex><span><span style=color:#75715e>     */</span>
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>float</span> batch_index <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>;
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>int</span> i<span style=color:#f92672>=</span><span style=color:#ae81ff>0</span>; i<span style=color:#f92672>&lt;</span><span style=color:#ae81ff>15</span>; i<span style=color:#f92672>++</span>) {
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>float</span> mse <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>;
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>float</span> Acc <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.0</span>;
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        <span style=color:#66d9ef>for</span>(<span style=color:#66d9ef>auto</span><span style=color:#f92672>&amp;</span> batch: <span style=color:#f92672>*</span>data_loader) {
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>auto</span> data <span style=color:#f92672>=</span> batch.data;
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>auto</span> target <span style=color:#f92672>=</span> batch.target.squeeze();
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#75715e>// Should be of length: batch_size
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>            data <span style=color:#f92672>=</span> data.to(torch<span style=color:#f92672>::</span>kF32);
</span></span><span style=display:flex><span>            target <span style=color:#f92672>=</span> target.to(torch<span style=color:#f92672>::</span>kInt64);
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            std<span style=color:#f92672>::</span>vector<span style=color:#f92672>&lt;</span>torch<span style=color:#f92672>::</span>jit<span style=color:#f92672>::</span>IValue<span style=color:#f92672>&gt;</span> input;
</span></span><span style=display:flex><span>            input.push_back(data);
</span></span><span style=display:flex><span>            optimizer.zero_grad();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>auto</span> output <span style=color:#f92672>=</span> net.forward(input).toTensor();
</span></span><span style=display:flex><span>            <span style=color:#75715e>// For transfer learning
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>            output <span style=color:#f92672>=</span> output.view({output.size(<span style=color:#ae81ff>0</span>), <span style=color:#f92672>-</span><span style=color:#ae81ff>1</span>});
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            output <span style=color:#f92672>=</span> lin(output);
</span></span><span style=display:flex><span>            <span style=color:#75715e>// Explicitly calculate torch::log_softmax of output from the FC Layer
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>            <span style=color:#66d9ef>auto</span> loss <span style=color:#f92672>=</span> torch<span style=color:#f92672>::</span>nll_loss(torch<span style=color:#f92672>::</span>log_softmax(output, <span style=color:#ae81ff>1</span>), target);
</span></span><span style=display:flex><span>           	
</span></span><span style=display:flex><span>            loss.backward();
</span></span><span style=display:flex><span>            optimizer.step();
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            <span style=color:#66d9ef>auto</span> acc <span style=color:#f92672>=</span> output.argmax(<span style=color:#ae81ff>1</span>).eq(target).sum();
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>            Acc <span style=color:#f92672>+=</span> acc.<span style=color:#66d9ef>template</span> item<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>float</span><span style=color:#f92672>&gt;</span>();
</span></span><span style=display:flex><span>            mse <span style=color:#f92672>+=</span> loss.<span style=color:#66d9ef>template</span> item<span style=color:#f92672>&lt;</span><span style=color:#66d9ef>float</span><span style=color:#f92672>&gt;</span>();
</span></span><span style=display:flex><span>            
</span></span><span style=display:flex><span>            batch_index <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>;
</span></span><span style=display:flex><span>        }
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        mse <span style=color:#f92672>=</span> mse<span style=color:#f92672>/</span><span style=color:#66d9ef>float</span>(batch_index); <span style=color:#75715e>// Take mean of loss
</span></span></span><span style=display:flex><span><span style=color:#75715e></span>        std<span style=color:#f92672>::</span>cout <span style=color:#f92672>&lt;&lt;</span> <span style=color:#e6db74>&#34;Epoch: &#34;</span> <span style=color:#f92672>&lt;&lt;</span> i  <span style=color:#f92672>&lt;&lt;</span> <span style=color:#e6db74>&#34;, &#34;</span> <span style=color:#f92672>&lt;&lt;</span> <span style=color:#e6db74>&#34;Accuracy: &#34;</span> <span style=color:#f92672>&lt;&lt;</span> Acc<span style=color:#f92672>/</span>dataset_size <span style=color:#f92672>&lt;&lt;</span> <span style=color:#e6db74>&#34;, &#34;</span> <span style=color:#f92672>&lt;&lt;</span> <span style=color:#e6db74>&#34;MSE: &#34;</span> <span style=color:#f92672>&lt;&lt;</span> mse <span style=color:#f92672>&lt;&lt;</span> std<span style=color:#f92672>::</span>endl;
</span></span><span style=display:flex><span>        net.save(<span style=color:#e6db74>&#34;model.pt&#34;</span>);
</span></span><span style=display:flex><span>    }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p><strong>Python</strong>:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-python data-lang=python><span style=display:flex><span>n_epochs <span style=color:#f92672>=</span> <span style=color:#ae81ff>15</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span><span style=color:#66d9ef>for</span> epoch <span style=color:#f92672>in</span> range(n_epochs):
</span></span><span style=display:flex><span>    mse <span style=color:#f92672>=</span> <span style=color:#ae81ff>0.0</span>
</span></span><span style=display:flex><span>    acc <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>    batch_index <span style=color:#f92672>=</span> <span style=color:#ae81ff>0</span>
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>    <span style=color:#66d9ef>for</span> data_batch <span style=color:#f92672>in</span> data_loader:
</span></span><span style=display:flex><span>        batch_index <span style=color:#f92672>+=</span> <span style=color:#ae81ff>1</span>
</span></span><span style=display:flex><span>        image, label <span style=color:#f92672>=</span> data_batch
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        optimizer<span style=color:#f92672>.</span>zero_grad()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        output <span style=color:#f92672>=</span> model(image)
</span></span><span style=display:flex><span>        _, predicted_label <span style=color:#f92672>=</span> torch<span style=color:#f92672>.</span>max(output<span style=color:#f92672>.</span>data, <span style=color:#ae81ff>1</span>)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        loss <span style=color:#f92672>=</span> cost(output, label)
</span></span><span style=display:flex><span>        
</span></span><span style=display:flex><span>        loss<span style=color:#f92672>.</span>backward()
</span></span><span style=display:flex><span>        optimizer<span style=color:#f92672>.</span>step()
</span></span><span style=display:flex><span>
</span></span><span style=display:flex><span>        mse <span style=color:#f92672>+=</span> loss<span style=color:#f92672>.</span>item() <span style=color:#75715e># data[0]</span>
</span></span><span style=display:flex><span>        acc <span style=color:#f92672>+=</span> torch<span style=color:#f92672>.</span>sum(predicted_label <span style=color:#f92672>==</span> label<span style=color:#f92672>.</span>data)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    mse <span style=color:#f92672>=</span> mse<span style=color:#f92672>/</span>len(data)
</span></span><span style=display:flex><span>    acc <span style=color:#f92672>=</span> <span style=color:#ae81ff>100</span><span style=color:#f92672>*</span>acc<span style=color:#f92672>/</span>len(data)
</span></span><span style=display:flex><span>    
</span></span><span style=display:flex><span>    print(<span style=color:#e6db74>&#34;Epoch: </span><span style=color:#e6db74>{}</span><span style=color:#e6db74>/</span><span style=color:#e6db74>{}</span><span style=color:#e6db74>, Loss: </span><span style=color:#e6db74>{:.4f}</span><span style=color:#e6db74>, Accuracy: </span><span style=color:#e6db74>{:.4f}</span><span style=color:#e6db74>&#34;</span><span style=color:#f92672>.</span>format(epoch<span style=color:#f92672>+</span><span style=color:#ae81ff>1</span>, n_epochs, mse, acc))
</span></span></code></pre></div><p>The code to test should also not change much except the need of optimizer.</p><h2 id=results>Results<a hidden class=anchor aria-hidden=true href=#results>#</a></h2><p><img alt="Results using PyTorch C++ API" loading=lazy src=https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Training-Results.png>
<img alt="Results using PyTorch in Python" loading=lazy src=https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Training-Results-Python.png></p><p>On a set of 400 images for training data, the maximum training Accuracy I could achieve was 91.25% in just less than 15 epochs using PyTorch C++ API and 89.0% using Python. (Note that this doesn&rsquo;t conclude superiority in terms of accuracy between any of the two backends - C++ or Python)</p><p>Let&rsquo;s have a look at correct and wrong predictions.</p><p><strong>Correct Predictions - Dogs</strong>
<img loading=lazy src=https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/correct-predictions-dogs-transfer-learning.png></p><p><strong>Wrong Predictions - Dogs</strong>
<img loading=lazy src=https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/wrong-predictions-dogs-transfer-learning.png></p><p><strong>Correct Predictions - Cats</strong>
<img loading=lazy src=https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/correct-predictions-cats-transfer-learning.png></p><p><strong>Wrong Predictions - Cats</strong>
<img loading=lazy src=https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/wrong-predictions-cats-transfer-learning.png></p><h2 id=acknowledgements>Acknowledgements<a hidden class=anchor aria-hidden=true href=#acknowledgements>#</a></h2><p>I would like to thank a few people to help me bring this out to the community. Thanks to <a href=https://github.com/ptrblck>Piotr</a> for his comments and answers in the PyTorch Discussion forum. Thanks to <a href=https://github.com/yf225>Will Feng</a> for reviewing the blog and the code and also his constant motivation to bring this out to you all. Would like to thank my constant motivation behind all my work, <a href=https://github.com/vishwesh5>Vishwesh Ravi Shrimali</a> for all his help to start with PyTorch C++ API and help the community. Special thanks to <a href=https://github.com/krutikabapat>Krutika Bapat</a> as well, for reviewing the Python equivalent code and suggesting modifications.</p><p>And shout out to all the readers, please share your feedback with me in the comments below. I would love to hear if this blog helped you!</p><p>In the upcoming blog, I&rsquo;ll be sharing something very exciting. Till then, happy learning!</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://krshrimali.github.io/tags/development/>Development</a></li><li><a href=https://krshrimali.github.io/tags/coding/>Coding</a></li><li><a href=https://krshrimali.github.io/tags/cpp/>Cpp</a></li><li><a href=https://krshrimali.github.io/tags/notes/>Notes</a></li><li><a href=https://krshrimali.github.io/tags/pytorch-cpp/>Pytorch-Cpp</a></li><li><a href=https://krshrimali.github.io/tags/libtorch/>Libtorch</a></li></ul><nav class=paginav><a class=prev href=https://krshrimali.github.io/posts/2019/08/setting-up-jupyter-notebook-xeus-cling-for-libtorch-and-opencv-libraries/><span class=title>« Prev</span><br><span>Setting up Jupyter Notebook (Xeus Cling) for Libtorch and OpenCV Libraries</span>
</a><a class=next href=https://krshrimali.github.io/posts/2019/07/classifying-dogs-vs-cats-using-pytorch-c-part-2/><span class=title>Next »</span><br><span>Classifying Dogs vs Cats using PyTorch C++: Part 2</span></a></nav><ul class=share-buttons><li><a target=_blank rel="noopener noreferrer" aria-label="share Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C++ API on x" href="https://x.com/intent/tweet/?text=Applying%20Transfer%20Learning%20on%20Dogs%20vs%20Cats%20Dataset%20%28ResNet18%29%20using%20PyTorch%20C%2b%2b%20API&amp;url=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f08%2fapplying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api%2f&amp;hashtags=development%2ccoding%2ccpp%2cnotes%2cpytorch-cpp%2clibtorch"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446C483.971.0 512 28.03 512 62.554zM269.951 190.75 182.567 75.216H56L207.216 272.95 63.9 436.783h61.366L235.9 310.383l96.667 126.4H456L298.367 228.367l134-153.151H371.033zM127.633 110h36.468l219.38 290.065H349.5z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C++ API on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f08%2fapplying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api%2f&amp;title=Applying%20Transfer%20Learning%20on%20Dogs%20vs%20Cats%20Dataset%20%28ResNet18%29%20using%20PyTorch%20C%2b%2b%20API&amp;summary=Applying%20Transfer%20Learning%20on%20Dogs%20vs%20Cats%20Dataset%20%28ResNet18%29%20using%20PyTorch%20C%2b%2b%20API&amp;source=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f08%2fapplying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0V293.839c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02V297.222c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768H431zM123.448 88.722C97.774 88.722 81 105.601 81 127.724c0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C++ API on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f08%2fapplying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api%2f&title=Applying%20Transfer%20Learning%20on%20Dogs%20vs%20Cats%20Dataset%20%28ResNet18%29%20using%20PyTorch%20C%2b%2b%20API"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zM326.526 373.831c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zM160.91 295.348c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C++ API on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f08%2fapplying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978V319.085h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C++ API on whatsapp" href="https://api.whatsapp.com/send?text=Applying%20Transfer%20Learning%20on%20Dogs%20vs%20Cats%20Dataset%20%28ResNet18%29%20using%20PyTorch%20C%2b%2b%20API%20-%20https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f08%2fapplying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api%2f"><svg viewBox="0 0 512 512" height="30" width="30" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H62.554c-34.524.0-62.554-28.03-62.554-62.554V62.554c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23C231.8 264.15 222.81 249.484 220.198 245s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C++ API on telegram" href="https://telegram.me/share/url?text=Applying%20Transfer%20Learning%20on%20Dogs%20vs%20Cats%20Dataset%20%28ResNet18%29%20using%20PyTorch%20C%2b%2b%20API&amp;url=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f08%2fapplying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api%2f"><svg viewBox="2 2 28 28" height="30" width="30" fill="currentColor"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47 3.38 3.38.0 01-2.51 1.02zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></li><li><a target=_blank rel="noopener noreferrer" aria-label="share Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C++ API on ycombinator" href="https://news.ycombinator.com/submitlink?t=Applying%20Transfer%20Learning%20on%20Dogs%20vs%20Cats%20Dataset%20%28ResNet18%29%20using%20PyTorch%20C%2b%2b%20API&u=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f08%2fapplying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api%2f"><svg width="30" height="30" viewBox="0 0 512 512" fill="currentColor"><path d="M449.446.0C483.971.0 512 28.03 512 62.554V449.446C512 483.97 483.97 512 449.446 512H62.554C28.03 512 0 483.97.0 449.446V62.554C0 28.03 28.029.0 62.554.0H449.446zM183.8767 87.9921h-62.034L230.6673 292.4508V424.0079h50.6655V292.4508L390.1575 87.9921H328.1233L256 238.2489z"/></svg></a></li></ul></footer></article></main><footer class=footer><span>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</span> ·
<span>Powered by
<a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a> &
<a href=https://github.com/adityatelange/hugo-PaperMod/ rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg viewBox="0 0 12 6" fill="currentColor"><path d="M12 6H0l6-6z"/></svg>
</a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>