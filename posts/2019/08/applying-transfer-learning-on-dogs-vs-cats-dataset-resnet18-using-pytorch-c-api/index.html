<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C&#43;&#43; API | Kushashwa Ravi Shrimali (Kush)</title>
<meta name="keywords" content="development, coding, cpp, notes, pytorch-cpp, libtorch">
<meta name="description" content="Transfer Learning
&ndash;
Before we go ahead and discuss the Why question of Transfer Learning, let&rsquo;s have a look at What is Transfer Learning? Let&rsquo;s have a look at the Notes from CS231n on Transfer Learning:

In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest.">
<meta name="author" content="map[name:Kushashwa Ravi Shrimali]">
<link rel="canonical" href="https://krshrimali.github.io/posts/2019/08/applying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api/">
<link crossorigin="anonymous" href="https://krshrimali.github.io/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css" integrity="sha256-j&#43;ECM6cGvIfy4Is8&#43;XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://krshrimali.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://krshrimali.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://krshrimali.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://krshrimali.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://krshrimali.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://krshrimali.github.io/posts/2019/08/applying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="https://krshrimali.github.io/posts/2019/08/applying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api/">
  <meta property="og:site_name" content="Kushashwa Ravi Shrimali (Kush)">
  <meta property="og:title" content="Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C&#43;&#43; API">
  <meta property="og:description" content="Transfer Learning – Before we go ahead and discuss the Why question of Transfer Learning, let’s have a look at What is Transfer Learning? Let’s have a look at the Notes from CS231n on Transfer Learning:
In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2019-08-16T00:00:00+00:00">
    <meta property="article:modified_time" content="2019-08-16T00:00:00+00:00">
    <meta property="article:tag" content="Development">
    <meta property="article:tag" content="Coding">
    <meta property="article:tag" content="Cpp">
    <meta property="article:tag" content="Notes">
    <meta property="article:tag" content="Pytorch-Cpp">
    <meta property="article:tag" content="Libtorch">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C&#43;&#43; API">
<meta name="twitter:description" content="Transfer Learning
&ndash;
Before we go ahead and discuss the Why question of Transfer Learning, let&rsquo;s have a look at What is Transfer Learning? Let&rsquo;s have a look at the Notes from CS231n on Transfer Learning:

In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://krshrimali.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C++ API",
      "item": "https://krshrimali.github.io/posts/2019/08/applying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C++ API",
  "name": "Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C\u002b\u002b API",
  "description": "Transfer Learning \u0026ndash; Before we go ahead and discuss the Why question of Transfer Learning, let\u0026rsquo;s have a look at What is Transfer Learning? Let\u0026rsquo;s have a look at the Notes from CS231n on Transfer Learning:\nIn practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest.\n",
  "keywords": [
    "development", "coding", "cpp", "notes", "pytorch-cpp", "libtorch"
  ],
  "articleBody": "Transfer Learning – Before we go ahead and discuss the Why question of Transfer Learning, let’s have a look at What is Transfer Learning? Let’s have a look at the Notes from CS231n on Transfer Learning:\nIn practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest.\nThere are 3 scenarios possible:\nWhen the data you have is similar (but not enough) to data trained on pre-trained model: Take an example of a pre-trained model trained on ImageNet dataset (containing 1000 classes). And the data we have has Dogs and Cats classes. Fortunate enough, ImageNet has some of the classes of Dog and Cat breeds and thus the model must have learned important features from the data. Let’s say we don’t have enough data but since the data is similar to the breeds in the ImageNet data set, we can simply use the ConvNet (except the last FC layer) to extract features from our dataset and train only the last Linear (FC) layer. When you have enough data (and is similar to the data trained with pre-trained model): Then you might go for fine tuning the weights of all the layers in the network. This is largely due to the reason that we know we won’t overfit because we have enough data. Using pre-trained models might just be enough if you have the data which matches the classes in the original data set. Transfer Learning came into existence (the answer of Why Transfer Learning?) because of some major reasons, which include:\nLack of resources or data set to train a CNN. At times, we either don’t have enough data or we don’t have enough resources to train a CNN from scratch. Random Initialization of weights vs Initialization of weights from the pre-trained model. Sometimes, it’s just better to initialize weights from the pre-trained model (as it must have learned the generic features from it’s data set) instead of randomly initializing the weights. Setting up the data with PyTorch C++ API At every stage, we will compare the Python and C++ codes to do the same thing, to make the analogy easier and understandable. Starting with setting up the data we have. Note that we do have enough data and it is also similar to the original data set of ImageNet, but since I don’t have enough resources to fine tune through the whole network, we perform Transfer Learning on the final FC layer only.\nStarting with loading the dataset, as discussed in the blogs before, I’ll just post a flow chart of procedure.\nOnce done, we can initialize the CustomDataset class:\nC++\n// List of images of Dogs and Cats, use load_data_from_folder function explained in previous blogs std::vector\u003cstd::string\u003e list_images; // List of labels of the images std::vector\u003cint\u003e list_labels; auto custom_dataset = CustomDataset(list_images, list_labels).map(torch::data::transforms::Stack\u003c\u003e()); Python\nfrom torchvision import datasets, transforms import torch folder_path = \"/Users/krshrimali/Documents/dataset/train/\" transform = transforms.Compose([transforms.CenterCrop(224), transforms.ToTensor()) data = datasets.ImageFolder(root = os.path.join(folder_path), transform = transform) We then use RandomSampler to make our data loader: (Note: it’s important to use RandomSampler as we load the images sequentially and we want mixture of images in each batch of data passed to the network in an epoch)\nC++\nint batch_size = 4; auto data_loader = torch::data::make_data_loader\u003ctorch::data::samplers::RandomSampler\u003e(std::move(custom_dataset), batch_size); Python\nbatch_size = 4 data_loader = torch.utils.data.DataLoader(dataset=data, batch_size = batch_size, shuffle = True) Loading the pre-trained model The steps to load the pre-trained model and perform Transfer Learning are listed below:\nDownload the pre-trained model of ResNet18. Load pre-trained model. Change output features of the final FC layer of the model loaded. (Number of classes would change from 1000 - ImageNet to 2 - Dogs vs Cats). Define optimizer on parameters from the final FC layer to be trained. Train the FC layer on Dogs vs Cats dataset. Save the model. Let’s go step by step.\nStep-1: Download the pre-trained model of ResNet18 Thanks to the developers, we do have C++ models available in torchvision (https://github.com/pytorch/vision/pull/728) but for this tutorial, transferring the pre- trained model from Python to C++ using torch.jit is a good idea, as most PyTorch models in the wild are written in Python right now, and people can use this tutorial to learn how to trace their Python model and transfer it to C++.\nFirst we download the pre-trained model and save it in the form of torch.jit.trace format to our local drive.\n# Reference: #TODO- Add Link from torchvision import models # Download and load the pre-trained model model = models.resnet18(pretrained=True) # Set upgrading the gradients to False for param in model.parameters(): param.requires_grad = False # Save the model except the final FC Layer resnet18 = torch.nn.Sequential(*list(resnet18.children())[:-1]) example_input = torch.rand(1, 3, 224, 224) script_module = torch.jit.trace(resnet18, example_input) script_module.save('resnet18_without_last_layer.pt') We will be using resnet18_without_last_layer.pt model file as our pre-trained model for transfer learning.\nStep-2: Load the pre-trained model Let’s go ahead and load the pre-trained model using torch::jit module. Note that the reason we have converted torch.nn.Module to torch.jit.ScriptModule type, is because C++ API currently does not support loading Python torch.nn.Module models directly.\nC++:\ntorch::jit::script::Module module; // argv[1] should be the path to the model module = torch::jit::load(argv[1]); /* We need to convert last layer input and output features from (512, 1000) to (512, 2) since we only have 2 classes */ torch::nn::Linear linear_layer(512, 2); // Define the optimizer on parameters of linear_layer with learning_rate = 1e-3 torch::optim::Adam optimizer(linear_layer-\u003eparameters(), torch::optim::AdamOptions(1e-3)) Python:\n# We will directly load the torch.nn pre-trained model model = models.resnet18(pretrained = True) for param in model.parameters(): param.requires_grad = False model.fc = torch.nn.Linear(512, 2) for param in model.fc.parameters(): param.requires_grad = True optimizer = torch.optim.Adam(model.fc.parameters()) cost = torch.nn.CrossEntropyLoss() Trainining the FC Layer Let’s first have a look at ResNet18 Network Architecture\nThe final step is to train the Fully Connected layer that we inserted at the end of the network (linear_layer). This one should be pretty straight forward, let’s see how to do it.\nC++:\nvoid train(torch::jit::script::Module net, torch::nn::Linear lin, Dataloader\u0026 data_loader, torch::optim::Optimizer\u0026 optimizer, size_t dataset_size) { /* This function trains the network on our data loader using optimizer for given number of epochs. Parameters ================== torch::jit::script::Module net: Pre-trained model torch::nn::Linear lin: Linear layer DataLoader\u0026 data_loader: Training data loader torch::optim::Optimizer\u0026 optimizer: Optimizer like Adam, SGD etc. size_t dataset_size: Size of training dataset */ float batch_index = 0; for(int i=0; i\u003c15; i++) { float mse = 0; float Acc = 0.0; for(auto\u0026 batch: *data_loader) { auto data = batch.data; auto target = batch.target.squeeze(); // Should be of length: batch_size data = data.to(torch::kF32); target = target.to(torch::kInt64); std::vector\u003ctorch::jit::IValue\u003e input; input.push_back(data); optimizer.zero_grad(); auto output = net.forward(input).toTensor(); // For transfer learning output = output.view({output.size(0), -1}); output = lin(output); // Explicitly calculate torch::log_softmax of output from the FC Layer auto loss = torch::nll_loss(torch::log_softmax(output, 1), target); loss.backward(); optimizer.step(); auto acc = output.argmax(1).eq(target).sum(); Acc += acc.template item\u003cfloat\u003e(); mse += loss.template item\u003cfloat\u003e(); batch_index += 1; } mse = mse/float(batch_index); // Take mean of loss std::cout \u003c\u003c \"Epoch: \" \u003c\u003c i \u003c\u003c \", \" \u003c\u003c \"Accuracy: \" \u003c\u003c Acc/dataset_size \u003c\u003c \", \" \u003c\u003c \"MSE: \" \u003c\u003c mse \u003c\u003c std::endl; net.save(\"model.pt\"); } } Python:\nn_epochs = 15 for epoch in range(n_epochs): mse = 0.0 acc = 0 batch_index = 0 for data_batch in data_loader: batch_index += 1 image, label = data_batch optimizer.zero_grad() output = model(image) _, predicted_label = torch.max(output.data, 1) loss = cost(output, label) loss.backward() optimizer.step() mse += loss.item() # data[0] acc += torch.sum(predicted_label == label.data) mse = mse/len(data) acc = 100*acc/len(data) print(\"Epoch: {}/{}, Loss: {:.4f}, Accuracy: {:.4f}\".format(epoch+1, n_epochs, mse, acc)) The code to test should also not change much except the need of optimizer.\nResults On a set of 400 images for training data, the maximum training Accuracy I could achieve was 91.25% in just less than 15 epochs using PyTorch C++ API and 89.0% using Python. (Note that this doesn’t conclude superiority in terms of accuracy between any of the two backends - C++ or Python)\nLet’s have a look at correct and wrong predictions.\nCorrect Predictions - Dogs Wrong Predictions - Dogs Correct Predictions - Cats Wrong Predictions - Cats Acknowledgements I would like to thank a few people to help me bring this out to the community. Thanks to Piotr for his comments and answers in the PyTorch Discussion forum. Thanks to Will Feng for reviewing the blog and the code and also his constant motivation to bring this out to you all. Would like to thank my constant motivation behind all my work, Vishwesh Ravi Shrimali for all his help to start with PyTorch C++ API and help the community. Special thanks to Krutika Bapat as well, for reviewing the Python equivalent code and suggesting modifications.\nAnd shout out to all the readers, please share your feedback with me in the comments below. I would love to hear if this blog helped you!\nIn the upcoming blog, I’ll be sharing something very exciting. Till then, happy learning!\n",
  "wordCount" : "1518",
  "inLanguage": "en",
  "datePublished": "2019-08-16T00:00:00Z",
  "dateModified": "2019-08-16T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": {"name":"Kushashwa Ravi Shrimali"}
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://krshrimali.github.io/posts/2019/08/applying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Kushashwa Ravi Shrimali (Kush)",
    "logo": {
      "@type": "ImageObject",
      "url": "https://krshrimali.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://krshrimali.github.io/" accesskey="h" title="Kushashwa Ravi Shrimali (Kush) (Alt + H)">Kushashwa Ravi Shrimali (Kush)</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://krshrimali.github.io/about" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://krshrimali.github.io/posts" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://krshrimali.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://krshrimali.github.io/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C&#43;&#43; API
    </h1>
    <div class="post-meta"><span title='2019-08-16 00:00:00 +0000 UTC'>August 16, 2019</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;map[name:Kushashwa Ravi Shrimali]

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#transfer-learning" aria-label="Transfer Learning">Transfer Learning</a></li>
                <li>
                    <a href="#setting-up-the-data-with-pytorch-c-api" aria-label="Setting up the data with PyTorch C&#43;&#43; API">Setting up the data with PyTorch C++ API</a></li>
                <li>
                    <a href="#loading-the-pre-trained-model" aria-label="Loading the pre-trained model">Loading the pre-trained model</a><ul>
                        
                <li>
                    <a href="#step-1-download-the-pre-trained-model-of-resnet18" aria-label="Step-1: Download the pre-trained model of ResNet18">Step-1: Download the pre-trained model of ResNet18</a></li>
                <li>
                    <a href="#step-2-load-the-pre-trained-model" aria-label="Step-2: Load the pre-trained model">Step-2: Load the pre-trained model</a></li></ul>
                </li>
                <li>
                    <a href="#trainining-the-fc-layer" aria-label="Trainining the FC Layer">Trainining the FC Layer</a></li>
                <li>
                    <a href="#results" aria-label="Results">Results</a></li>
                <li>
                    <a href="#acknowledgements" aria-label="Acknowledgements">Acknowledgements</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h2 id="transfer-learning">Transfer Learning<a hidden class="anchor" aria-hidden="true" href="#transfer-learning">#</a></h2>
<p>&ndash;
Before we go ahead and discuss the <strong>Why</strong> question of Transfer Learning, let&rsquo;s have a look at <strong>What is Transfer Learning?</strong> Let&rsquo;s have a look at the <a href="http://cs231n.github.io/transfer-learning">Notes</a> from CS231n on Transfer Learning:</p>
<blockquote>
<p>In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest.</p></blockquote>
<p><img loading="lazy" src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Cover-Transfer-Learning.jpg"></p>
<p>There are 3 scenarios possible:</p>
<ol>
<li>When the data you have is similar (but not enough) to data trained on pre-trained model: Take an example of a pre-trained model trained on ImageNet dataset (containing 1000 classes). And the data we have has Dogs and Cats classes. Fortunate enough, ImageNet has some of the classes of Dog and Cat breeds and thus the model must have learned important features from the data. Let&rsquo;s say we don&rsquo;t have enough data but since the data is similar to the breeds in the ImageNet data set, we can simply use the ConvNet (except the last FC layer) to extract features from our dataset and train only the last Linear (FC) layer.</li>
<li>When you have enough data (and is similar to the data trained with pre-trained model): Then you might go for fine tuning the weights of all the layers in the network. This is largely due to the reason that we know we won&rsquo;t overfit because we have enough data.</li>
<li>Using pre-trained models might just be enough if you have the data which matches the classes in the original data set.</li>
</ol>
<p>Transfer Learning came into existence (the answer of <strong>Why Transfer Learning?</strong>) because of some major reasons, which include:</p>
<ol>
<li>Lack of resources or data set to train a CNN. At times, we either don&rsquo;t have enough data or we don&rsquo;t have enough resources to train a CNN from scratch.</li>
<li>Random Initialization of weights vs Initialization of weights from the pre-trained model. Sometimes, it&rsquo;s just better to initialize weights from the pre-trained model (as it must have learned the generic features from it&rsquo;s data set) instead of randomly initializing the weights.</li>
</ol>
<h2 id="setting-up-the-data-with-pytorch-c-api">Setting up the data with PyTorch C++ API<a hidden class="anchor" aria-hidden="true" href="#setting-up-the-data-with-pytorch-c-api">#</a></h2>
<p>At every stage, we will compare the Python and C++ codes to do the same thing, to make the analogy easier and understandable. Starting with setting up the data we have. Note that we do have enough data and it is also similar to the original data set of ImageNet, but since I don&rsquo;t have enough resources to fine tune through the whole network, we perform Transfer Learning on the final FC layer only.</p>
<p>Starting with loading the dataset, as discussed in the blogs before, I&rsquo;ll just post a flow chart of procedure.</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Steps-Loading-Data-PyTorch.png"></p>
<p>Once done, we can initialize the <code>CustomDataset</code> class:</p>
<p><strong>C++</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// List of images of Dogs and Cats, use load_data_from_folder function explained in previous blogs
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span>std<span style="color:#f92672">::</span>string<span style="color:#f92672">&gt;</span> list_images; 
</span></span><span style="display:flex;"><span><span style="color:#75715e">// List of labels of the images
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> list_labels; 
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> custom_dataset <span style="color:#f92672">=</span> CustomDataset(list_images, list_labels).map(torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>transforms<span style="color:#f92672">::</span>Stack<span style="color:#f92672">&lt;&gt;</span>());
</span></span></code></pre></div><p><strong>Python</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> torchvision <span style="color:#f92672">import</span> datasets, transforms
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>folder_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/Users/krshrimali/Documents/dataset/train/&#34;</span>
</span></span><span style="display:flex;"><span>transform <span style="color:#f92672">=</span> transforms<span style="color:#f92672">.</span>Compose([transforms<span style="color:#f92672">.</span>CenterCrop(<span style="color:#ae81ff">224</span>), transforms<span style="color:#f92672">.</span>ToTensor())
</span></span><span style="display:flex;"><span>data <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>ImageFolder(root <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(folder_path), transform <span style="color:#f92672">=</span> transform)
</span></span></code></pre></div><p>We then use <code>RandomSampler</code> to make our data loader: (Note: it&rsquo;s important to use <code>RandomSampler</code> as we load the images sequentially and we want mixture of images in each batch of data passed to the network in an epoch)</p>
<p><strong>C++</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">int</span> batch_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">4</span>;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> data_loader <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>make_data_loader<span style="color:#f92672">&lt;</span>torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>samplers<span style="color:#f92672">::</span>RandomSampler<span style="color:#f92672">&gt;</span>(std<span style="color:#f92672">::</span>move(custom_dataset), batch_size);
</span></span></code></pre></div><p><strong>Python</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>batch_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">4</span>
</span></span><span style="display:flex;"><span>data_loader <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>DataLoader(dataset<span style="color:#f92672">=</span>data, batch_size <span style="color:#f92672">=</span> batch_size, shuffle <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>)
</span></span></code></pre></div><h2 id="loading-the-pre-trained-model">Loading the pre-trained model<a hidden class="anchor" aria-hidden="true" href="#loading-the-pre-trained-model">#</a></h2>
<p>The steps to load the pre-trained model and perform Transfer Learning are listed below:</p>
<ol>
<li>Download the pre-trained model of <strong>ResNet18</strong>.</li>
<li>Load pre-trained model.</li>
<li>Change output features of the final FC layer of the model loaded. (Number of classes would change from 1000 - ImageNet to 2 - Dogs vs Cats).</li>
<li>Define optimizer on parameters from the final FC layer to be trained.</li>
<li>Train the FC layer on Dogs vs Cats dataset.</li>
<li>Save the model.</li>
</ol>
<p>Let&rsquo;s go step by step.</p>
<h3 id="step-1-download-the-pre-trained-model-of-resnet18">Step-1: Download the pre-trained model of ResNet18<a hidden class="anchor" aria-hidden="true" href="#step-1-download-the-pre-trained-model-of-resnet18">#</a></h3>
<p>Thanks to the developers, we do have C++ models available in torchvision
(<a href="https://github.com/pytorch/vision/pull/728">https://github.com/pytorch/vision/pull/728</a>) but for this tutorial, transferring the pre- trained model from Python to C++ using torch.jit is a good idea, as most PyTorch models in the wild are written in Python right now, and people can use this tutorial to learn how to trace their Python model and transfer it to C++.</p>
<p>First we download the pre-trained model and save it in the form of <code>torch.jit.trace</code> format to our local drive.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Reference: #TODO- Add Link</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torchvision <span style="color:#f92672">import</span> models
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Download and load the pre-trained model</span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> models<span style="color:#f92672">.</span>resnet18(pretrained<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Set upgrading the gradients to False</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> param <span style="color:#f92672">in</span> model<span style="color:#f92672">.</span>parameters():
</span></span><span style="display:flex;"><span>	param<span style="color:#f92672">.</span>requires_grad <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Save the model except the final FC Layer</span>
</span></span><span style="display:flex;"><span>resnet18 <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Sequential(<span style="color:#f92672">*</span>list(resnet18<span style="color:#f92672">.</span>children())[:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>example_input <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>rand(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">224</span>)
</span></span><span style="display:flex;"><span>script_module <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>trace(resnet18, example_input)
</span></span><span style="display:flex;"><span>script_module<span style="color:#f92672">.</span>save(<span style="color:#e6db74">&#39;resnet18_without_last_layer.pt&#39;</span>)
</span></span></code></pre></div><p>We will be using <code>resnet18_without_last_layer.pt</code> model file as our pre-trained model for transfer learning.</p>
<h3 id="step-2-load-the-pre-trained-model">Step-2: Load the pre-trained model<a hidden class="anchor" aria-hidden="true" href="#step-2-load-the-pre-trained-model">#</a></h3>
<p>Let&rsquo;s go ahead and load the pre-trained model using <code>torch::jit</code> module. Note that the reason we have converted <code>torch.nn.Module</code> to <code>torch.jit.ScriptModule</code> type, is because C++ API currently does not support loading Python <code>torch.nn.Module</code> models directly.</p>
<p><strong>C++</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>jit<span style="color:#f92672">::</span>script<span style="color:#f92672">::</span>Module module;
</span></span><span style="display:flex;"><span><span style="color:#75715e">// argv[1] should be the path to the model
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>module <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>jit<span style="color:#f92672">::</span>load(argv[<span style="color:#ae81ff">1</span>]); 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">/* We need to convert last layer input and output features from (512, 1000) to (512, 2) since we only have 2 classes */</span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear linear_layer(<span style="color:#ae81ff">512</span>, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Define the optimizer on parameters of linear_layer with learning_rate = 1e-3
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>Adam optimizer(linear_layer<span style="color:#f92672">-&gt;</span>parameters(), torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>AdamOptions(<span style="color:#ae81ff">1e-3</span>))
</span></span></code></pre></div><p><strong>Python</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># We will directly load the torch.nn pre-trained model</span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> models<span style="color:#f92672">.</span>resnet18(pretrained <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> param <span style="color:#f92672">in</span> model<span style="color:#f92672">.</span>parameters():
</span></span><span style="display:flex;"><span>    param<span style="color:#f92672">.</span>requires_grad <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>fc <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">512</span>, <span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> param <span style="color:#f92672">in</span> model<span style="color:#f92672">.</span>fc<span style="color:#f92672">.</span>parameters():
</span></span><span style="display:flex;"><span>	param<span style="color:#f92672">.</span>requires_grad <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>optimizer <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>optim<span style="color:#f92672">.</span>Adam(model<span style="color:#f92672">.</span>fc<span style="color:#f92672">.</span>parameters())
</span></span><span style="display:flex;"><span>cost <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>CrossEntropyLoss()
</span></span></code></pre></div><h2 id="trainining-the-fc-layer">Trainining the FC Layer<a hidden class="anchor" aria-hidden="true" href="#trainining-the-fc-layer">#</a></h2>
<p>Let&rsquo;s first have a look at ResNet18 Network Architecture</p>
<p><img alt="https://www.researchgate.net/figure/ResNet-18-Architecture_tbl1_322476121" loading="lazy" src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/ResNet18-Architecture.png"></p>
<p>The final step is to train the Fully Connected layer that we inserted at the end of the network (<code>linear_layer</code>). This one should be pretty straight forward, let&rsquo;s see how to do it.</p>
<p><strong>C++</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">train</span>(torch<span style="color:#f92672">::</span>jit<span style="color:#f92672">::</span>script<span style="color:#f92672">::</span>Module net, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear lin, Dataloader<span style="color:#f92672">&amp;</span> data_loader, torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>Optimizer<span style="color:#f92672">&amp;</span> optimizer, size_t dataset_size) {
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">/*
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     This function trains the network on our data loader using optimizer for given number of epochs.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     Parameters
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     ==================
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     torch::jit::script::Module net: Pre-trained model
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     torch::nn::Linear lin: Linear layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     DataLoader&amp; data_loader: Training data loader
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     torch::optim::Optimizer&amp; optimizer: Optimizer like Adam, SGD etc.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     size_t dataset_size: Size of training dataset
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     */</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> batch_index <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">int</span> i<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; i<span style="color:#f92672">&lt;</span><span style="color:#ae81ff">15</span>; i<span style="color:#f92672">++</span>) {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">float</span> mse <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">float</span> Acc <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>;
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">auto</span><span style="color:#f92672">&amp;</span> batch: <span style="color:#f92672">*</span>data_loader) {
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">auto</span> data <span style="color:#f92672">=</span> batch.data;
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">auto</span> target <span style="color:#f92672">=</span> batch.target.squeeze();
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e">// Should be of length: batch_size
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>            data <span style="color:#f92672">=</span> data.to(torch<span style="color:#f92672">::</span>kF32);
</span></span><span style="display:flex;"><span>            target <span style="color:#f92672">=</span> target.to(torch<span style="color:#f92672">::</span>kInt64);
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span>torch<span style="color:#f92672">::</span>jit<span style="color:#f92672">::</span>IValue<span style="color:#f92672">&gt;</span> input;
</span></span><span style="display:flex;"><span>            input.push_back(data);
</span></span><span style="display:flex;"><span>            optimizer.zero_grad();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">auto</span> output <span style="color:#f92672">=</span> net.forward(input).toTensor();
</span></span><span style="display:flex;"><span>            <span style="color:#75715e">// For transfer learning
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>            output <span style="color:#f92672">=</span> output.view({output.size(<span style="color:#ae81ff">0</span>), <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>});
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            output <span style="color:#f92672">=</span> lin(output);
</span></span><span style="display:flex;"><span>            <span style="color:#75715e">// Explicitly calculate torch::log_softmax of output from the FC Layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>            <span style="color:#66d9ef">auto</span> loss <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>nll_loss(torch<span style="color:#f92672">::</span>log_softmax(output, <span style="color:#ae81ff">1</span>), target);
</span></span><span style="display:flex;"><span>           	
</span></span><span style="display:flex;"><span>            loss.backward();
</span></span><span style="display:flex;"><span>            optimizer.step();
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">auto</span> acc <span style="color:#f92672">=</span> output.argmax(<span style="color:#ae81ff">1</span>).eq(target).sum();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            Acc <span style="color:#f92672">+=</span> acc.<span style="color:#66d9ef">template</span> item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>();
</span></span><span style="display:flex;"><span>            mse <span style="color:#f92672">+=</span> loss.<span style="color:#66d9ef">template</span> item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>();
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            batch_index <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>;
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        mse <span style="color:#f92672">=</span> mse<span style="color:#f92672">/</span><span style="color:#66d9ef">float</span>(batch_index); <span style="color:#75715e">// Take mean of loss
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Epoch: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> i  <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;, &#34;</span> <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Accuracy: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> Acc<span style="color:#f92672">/</span>dataset_size <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;, &#34;</span> <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;MSE: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> mse <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>        net.save(<span style="color:#e6db74">&#34;model.pt&#34;</span>);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p><strong>Python</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>n_epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">15</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(n_epochs):
</span></span><span style="display:flex;"><span>    mse <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>
</span></span><span style="display:flex;"><span>    acc <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    batch_index <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> data_batch <span style="color:#f92672">in</span> data_loader:
</span></span><span style="display:flex;"><span>        batch_index <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        image, label <span style="color:#f92672">=</span> data_batch
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        optimizer<span style="color:#f92672">.</span>zero_grad()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        output <span style="color:#f92672">=</span> model(image)
</span></span><span style="display:flex;"><span>        _, predicted_label <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>max(output<span style="color:#f92672">.</span>data, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        loss <span style="color:#f92672">=</span> cost(output, label)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        loss<span style="color:#f92672">.</span>backward()
</span></span><span style="display:flex;"><span>        optimizer<span style="color:#f92672">.</span>step()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        mse <span style="color:#f92672">+=</span> loss<span style="color:#f92672">.</span>item() <span style="color:#75715e"># data[0]</span>
</span></span><span style="display:flex;"><span>        acc <span style="color:#f92672">+=</span> torch<span style="color:#f92672">.</span>sum(predicted_label <span style="color:#f92672">==</span> label<span style="color:#f92672">.</span>data)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    mse <span style="color:#f92672">=</span> mse<span style="color:#f92672">/</span>len(data)
</span></span><span style="display:flex;"><span>    acc <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span><span style="color:#f92672">*</span>acc<span style="color:#f92672">/</span>len(data)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;Epoch: </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">/</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">, Loss: </span><span style="color:#e6db74">{:.4f}</span><span style="color:#e6db74">, Accuracy: </span><span style="color:#e6db74">{:.4f}</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format(epoch<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>, n_epochs, mse, acc))
</span></span></code></pre></div><p>The code to test should also not change much except the need of optimizer.</p>
<h2 id="results">Results<a hidden class="anchor" aria-hidden="true" href="#results">#</a></h2>
<p><img alt="Results using PyTorch C++ API" loading="lazy" src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Training-Results.png">
<img alt="Results using PyTorch in Python" loading="lazy" src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Training-Results-Python.png"></p>
<p>On a set of 400 images for training data, the maximum training Accuracy I could achieve was 91.25% in just less than 15 epochs using PyTorch C++ API and 89.0% using Python. (Note that this doesn&rsquo;t conclude superiority in terms of accuracy between any of the two backends - C++ or Python)</p>
<p>Let&rsquo;s have a look at correct and wrong predictions.</p>
<p><strong>Correct Predictions - Dogs</strong>
<img loading="lazy" src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/correct-predictions-dogs-transfer-learning.png"></p>
<p><strong>Wrong Predictions - Dogs</strong>
<img loading="lazy" src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/wrong-predictions-dogs-transfer-learning.png"></p>
<p><strong>Correct Predictions - Cats</strong>
<img loading="lazy" src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/correct-predictions-cats-transfer-learning.png"></p>
<p><strong>Wrong Predictions - Cats</strong>
<img loading="lazy" src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/wrong-predictions-cats-transfer-learning.png"></p>
<h2 id="acknowledgements">Acknowledgements<a hidden class="anchor" aria-hidden="true" href="#acknowledgements">#</a></h2>
<p>I would like to thank a few people to help me bring this out to the community. Thanks to <a href="https://github.com/ptrblck">Piotr</a> for his comments and answers in the PyTorch Discussion forum. Thanks to <a href="https://github.com/yf225">Will Feng</a> for reviewing the blog and the code and also his constant motivation to bring this out to you all. Would like to thank my constant motivation behind all my work, <a href="https://github.com/vishwesh5">Vishwesh Ravi Shrimali</a> for all his help to start with PyTorch C++ API and help the community. Special thanks to <a href="https://github.com/krutikabapat">Krutika Bapat</a> as well, for reviewing the Python equivalent code and suggesting modifications.</p>
<p>And shout out to all the readers, please share your feedback with me in the comments below. I would love to hear if this blog helped you!</p>
<p>In the upcoming blog, I&rsquo;ll be sharing something very exciting. Till then, happy learning!</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://krshrimali.github.io/tags/development/">Development</a></li>
      <li><a href="https://krshrimali.github.io/tags/coding/">Coding</a></li>
      <li><a href="https://krshrimali.github.io/tags/cpp/">Cpp</a></li>
      <li><a href="https://krshrimali.github.io/tags/notes/">Notes</a></li>
      <li><a href="https://krshrimali.github.io/tags/pytorch-cpp/">Pytorch-Cpp</a></li>
      <li><a href="https://krshrimali.github.io/tags/libtorch/">Libtorch</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://krshrimali.github.io/posts/2019/08/setting-up-jupyter-notebook-xeus-cling-for-libtorch-and-opencv-libraries/">
    <span class="title">« Prev</span>
    <br>
    <span>Setting up Jupyter Notebook (Xeus Cling) for Libtorch and OpenCV Libraries</span>
  </a>
  <a class="next" href="https://krshrimali.github.io/posts/2019/07/classifying-dogs-vs-cats-using-pytorch-c-part-2/">
    <span class="title">Next »</span>
    <br>
    <span>Classifying Dogs vs Cats using PyTorch C&#43;&#43;: Part 2</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C&#43;&#43; API on x"
            href="https://x.com/intent/tweet/?text=Applying%20Transfer%20Learning%20on%20Dogs%20vs%20Cats%20Dataset%20%28ResNet18%29%20using%20PyTorch%20C%2b%2b%20API&amp;url=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f08%2fapplying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api%2f&amp;hashtags=development%2ccoding%2ccpp%2cnotes%2cpytorch-cpp%2clibtorch">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C&#43;&#43; API on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f08%2fapplying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api%2f&amp;title=Applying%20Transfer%20Learning%20on%20Dogs%20vs%20Cats%20Dataset%20%28ResNet18%29%20using%20PyTorch%20C%2b%2b%20API&amp;summary=Applying%20Transfer%20Learning%20on%20Dogs%20vs%20Cats%20Dataset%20%28ResNet18%29%20using%20PyTorch%20C%2b%2b%20API&amp;source=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f08%2fapplying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C&#43;&#43; API on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f08%2fapplying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api%2f&title=Applying%20Transfer%20Learning%20on%20Dogs%20vs%20Cats%20Dataset%20%28ResNet18%29%20using%20PyTorch%20C%2b%2b%20API">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C&#43;&#43; API on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f08%2fapplying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C&#43;&#43; API on whatsapp"
            href="https://api.whatsapp.com/send?text=Applying%20Transfer%20Learning%20on%20Dogs%20vs%20Cats%20Dataset%20%28ResNet18%29%20using%20PyTorch%20C%2b%2b%20API%20-%20https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f08%2fapplying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C&#43;&#43; API on telegram"
            href="https://telegram.me/share/url?text=Applying%20Transfer%20Learning%20on%20Dogs%20vs%20Cats%20Dataset%20%28ResNet18%29%20using%20PyTorch%20C%2b%2b%20API&amp;url=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f08%2fapplying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C&#43;&#43; API on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Applying%20Transfer%20Learning%20on%20Dogs%20vs%20Cats%20Dataset%20%28ResNet18%29%20using%20PyTorch%20C%2b%2b%20API&u=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f08%2fapplying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
