<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author" content="map[name:Kushashwa Ravi Shrimali]">
<meta name="description" content="In the last blog, we had discussed all but training and results of our custom CNN network on Dogs vs Cats dataset. Today, we&rsquo;ll be making some small changes in the network and discussing training and results of the task.
I&rsquo;ll start with the network overview again, where we used a network similar to VGG-16 (with one extra Fully Connected Layer in the end). While there are absolutely no problems with that network, but since the dataset contains a lot of images (25000 in training dataset) and we were using (200x200x3) input shape to the network (which is 120,000 floating point numbers), this leads to high memory consumption. In short, I was out of RAM to store these many images during program execution.
" />
<meta name="keywords" content=", development, coding, cpp, notes, pytorch-cpp, libtorch" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="#252627" />
<link rel="canonical" href="https://krshrimali.github.io/posts/2019/07/classifying-dogs-vs-cats-using-pytorch-c-part-2/" />


    <title>
        
            Classifying Dogs vs Cats using PyTorch C&#43;&#43;: Part 2 :: Kushashwa Ravi Shrimali (Kush)  — Learning never stops!
        
    </title>





  <link rel="stylesheet" href="https://krshrimali.github.io/main.min.244183cde1a38e0b08f82c11791181288f9aac1cc9618cd6f4e9e7710c5768ba.css" integrity="sha256-JEGDzeGjjgsI&#43;CwReRGBKI&#43;arBzJYYzW9OnncQxXaLo=" crossorigin="anonymous">





    <link rel="apple-touch-icon" sizes="180x180" href="https://krshrimali.github.io/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://krshrimali.github.io/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://krshrimali.github.io/favicon-16x16.png">
    <link rel="manifest" href="https://krshrimali.github.io/site.webmanifest">
    <link rel="mask-icon" href="https://krshrimali.github.io/safari-pinned-tab.svg" color="">
    <link rel="shortcut icon" href="https://krshrimali.github.io/favicon.ico">
    <meta name="msapplication-TileColor" content="">



  <meta itemprop="name" content="Classifying Dogs vs Cats using PyTorch C&#43;&#43;: Part 2">
  <meta itemprop="description" content="In the last blog, we had discussed all but training and results of our custom CNN network on Dogs vs Cats dataset. Today, we’ll be making some small changes in the network and discussing training and results of the task.
I’ll start with the network overview again, where we used a network similar to VGG-16 (with one extra Fully Connected Layer in the end). While there are absolutely no problems with that network, but since the dataset contains a lot of images (25000 in training dataset) and we were using (200x200x3) input shape to the network (which is 120,000 floating point numbers), this leads to high memory consumption. In short, I was out of RAM to store these many images during program execution.">
  <meta itemprop="datePublished" content="2019-07-31T00:00:00+00:00">
  <meta itemprop="dateModified" content="2019-07-31T00:00:00+00:00">
  <meta itemprop="wordCount" content="1385">
  <meta itemprop="image" content="https://krshrimali.github.io/">
  <meta itemprop="keywords" content="Development,Coding,Cpp,Notes,Pytorch-Cpp,Libtorch">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="https://krshrimali.github.io/">
  <meta name="twitter:title" content="Classifying Dogs vs Cats using PyTorch C&#43;&#43;: Part 2">
  <meta name="twitter:description" content="In the last blog, we had discussed all but training and results of our custom CNN network on Dogs vs Cats dataset. Today, we’ll be making some small changes in the network and discussing training and results of the task.
I’ll start with the network overview again, where we used a network similar to VGG-16 (with one extra Fully Connected Layer in the end). While there are absolutely no problems with that network, but since the dataset contains a lot of images (25000 in training dataset) and we were using (200x200x3) input shape to the network (which is 120,000 floating point numbers), this leads to high memory consumption. In short, I was out of RAM to store these many images during program execution.">





    <meta property="article:section" content="pytorch" />

    <meta property="article:section" content="deep learning" />



    <meta property="article:published_time" content="2019-07-31 00:00:00 &#43;0000 UTC" />









    



    </head>

    
        <body>
    
    
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="https://krshrimali.github.io/" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">></span>
            <span class="logo__text ">
                $ cd /home/</span>
            <span class="logo__cursor" style=
                  "
                   
                   ">
            </span>
        
    </div>
</a>


        <span class="header__right">
                <nav class="menu">
    <ul class="menu__inner"><li><a href="https://krshrimali.github.io/about">About</a></li><li><a href="https://krshrimali.github.io/posts">Blog</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
        </span>
    </span>
</header>


            <div class="content">
                
  <main class="post">

    <div class="post-info">
      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock">
          <circle cx="12" cy="12" r="10"></circle>
          <polyline points="12 6 12 12 16 14"></polyline>
        </svg>
        7 minutes

        
      </p>
    </div>

    <article>
      <h1 class="post-title">
        <a href="https://krshrimali.github.io/posts/2019/07/classifying-dogs-vs-cats-using-pytorch-c-part-2/">Classifying Dogs vs Cats using PyTorch C++: Part 2</a>
      </h1>

      

      
        <hr />
        <aside id="toc">
          <div class="toc-title">Table of Contents</div>
          <nav id="TableOfContents">
  <ul>
    <li><a href="#network-overview">Network Overview</a></li>
    <li><a href="#training">Training</a></li>
    <li><a href="#results">Results</a></li>
    <li><a href="#correct-predictions-dogs">Correct Predictions (Dogs)</a></li>
    <li><a href="#correct-predictions-cats">Correct Predictions (Cats)</a></li>
    <li><a href="#wrong-predictions-dogs">Wrong Predictions (Dogs)</a></li>
    <li><a href="#wrong-predictions-cats">Wrong Predictions (Cats)</a></li>
  </ul>
</nav>
        </aside>
        <hr />

      

      <div class="post-content">
        <p>In the last blog, we had discussed all but training and results of our custom CNN network on Dogs vs Cats dataset. Today, we&rsquo;ll be making some small changes in the network and discussing training and results of the task.</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Classify-Dogs-Cats-Blog-05.jpg"></p>
<p>I&rsquo;ll start with the network overview again, where we used a network similar to VGG-16 (with one extra Fully Connected Layer in the end). While there are absolutely no problems with that network, but since the dataset contains a lot of images (25000 in training dataset) and we were using (200x200x3) input shape to the network (which is 120,000 floating point numbers), this leads to high memory consumption. In short, I was out of RAM to store these many images during program execution.</p>
<p>So, I decided to change some minute things:</p>
<ol>
<li>Input Shape to the network is now <code>64x64x3</code> (12,288 parameters - around 10 times lesser than for <code>200x200x3</code>). So, all the images are now resized to <code>64x64x3</code>.</li>
<li>Now, we only use 2 Convolutional Layers and 2 Max Pooling Layers to train our dataset. This helps to reduce the parameters for training, and also fastens the training process.</li>
</ol>
<p>But this comes with a tradeoff in accuracy, which will suffice for now as our target is not to get some X accuracy, but to learn how to train the network on our dataset using PyTorch C++ API.</p>
<p><strong>Question</strong>: Does reducing input resolution, affects accuracy?
<strong>Answer</strong>: In this case, it will. The objects in our dataset (dogs and cats) have both high level and low level features, which are visible (provides more details) more to the network with high resolution. In this way, the network is allowed to learn more features out of the dataset. However, in cases like of MNIST, it&rsquo;s just fine to use <code>64x64</code> input resolution as it still allows the network to look at details of a digit and learn robust features.</p>
<p>Let&rsquo;s go ahead and see what has changed in the Network.</p>
<h2 id="network-overview">Network Overview</h2>
<p>If you don&rsquo;t remember from the last time, this is how our network looked.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">NetImpl</span><span style="color:#f92672">:</span> <span style="color:#66d9ef">public</span> torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Module {
</span></span><span style="display:flex;"><span>    NetImpl() {
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Initialize the network
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#75715e">// On how to pass strides and padding: https://github.com/pytorch/pytorch/issues/12649#issuecomment-430156160
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv1_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv1_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv1_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv1_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv2_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv2_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">30</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv2_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv2_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">30</span>, <span style="color:#ae81ff">40</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv3_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv3_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">40</span>, <span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv3_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv3_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">60</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv3_3 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv3_3&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">60</span>, <span style="color:#ae81ff">70</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv4_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv4_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">70</span>, <span style="color:#ae81ff">80</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv4_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv4_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">80</span>, <span style="color:#ae81ff">90</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv4_3 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv4_3&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">90</span>, <span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv5_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv5_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">110</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv5_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv5_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">110</span>, <span style="color:#ae81ff">120</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv5_3 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv5_3&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">120</span>, <span style="color:#ae81ff">130</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        fc1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">130</span><span style="color:#f92672">*</span><span style="color:#ae81ff">6</span><span style="color:#f92672">*</span><span style="color:#ae81ff">6</span>, <span style="color:#ae81ff">2000</span>));
</span></span><span style="display:flex;"><span>        fc2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">2000</span>, <span style="color:#ae81ff">1000</span>));
</span></span><span style="display:flex;"><span>        fc3 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc3&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">1000</span>, <span style="color:#ae81ff">100</span>));
</span></span><span style="display:flex;"><span>        fc4 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc4&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">2</span>));
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Implement Algorithm
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    torch<span style="color:#f92672">::</span>Tensor forward(torch<span style="color:#f92672">::</span>Tensor x) {
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv1_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv1_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv2_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv2_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv3_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv3_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv3_3<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv4_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv4_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv4_3<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv5_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv5_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv5_3<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> x.view({<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">130</span><span style="color:#f92672">*</span><span style="color:#ae81ff">6</span><span style="color:#f92672">*</span><span style="color:#ae81ff">6</span>});
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(fc1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(fc2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(fc3<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> fc4<span style="color:#f92672">-&gt;</span>forward(x);
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> torch<span style="color:#f92672">::</span>log_softmax(x, <span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Declare layers
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv1_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv1_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv2_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv2_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv3_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv3_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv3_3{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv4_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv4_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv4_3{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv5_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv5_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv5_3{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear fc1{<span style="color:#66d9ef">nullptr</span>}, fc2{<span style="color:#66d9ef">nullptr</span>}, fc3{<span style="color:#66d9ef">nullptr</span>}, fc4{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p>As it&rsquo;s visible, we had 13 Convolutional Layers, 5 Max Pooling Layers and 4 Fully Connected Layers. This leads of a lot of parameters to be trained.</p>
<p>Therefore, our new network for experimentation purposes will be:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">NetworkImpl</span> <span style="color:#f92672">:</span> <span style="color:#66d9ef">public</span> torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Module {
</span></span><span style="display:flex;"><span>	NetImpl(<span style="color:#66d9ef">int64_t</span> channels, <span style="color:#66d9ef">int64_t</span> height, <span style="color:#66d9ef">int64_t</span> width) {
</span></span><span style="display:flex;"><span>		conv1_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">5</span>).stride(<span style="color:#ae81ff">2</span>)));
</span></span><span style="display:flex;"><span>		conv2_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">7</span>).stride(<span style="color:#ae81ff">2</span>)));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		<span style="color:#75715e">// Used to find the output size till previous convolutional layers
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>		n(get_output_shape(channels, height, width));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		fc1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(n, <span style="color:#ae81ff">120</span>));
</span></span><span style="display:flex;"><span>		fc2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">120</span>, <span style="color:#ae81ff">100</span>));
</span></span><span style="display:flex;"><span>		fc3 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc3&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">2</span>));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		register_module(<span style="color:#e6db74">&#34;conv1&#34;</span>, conv1);
</span></span><span style="display:flex;"><span>		register_module(<span style="color:#e6db74">&#34;conv2&#34;</span>, conv2);
</span></span><span style="display:flex;"><span>		register_module(<span style="color:#e6db74">&#34;fc1&#34;</span>, fc1);
</span></span><span style="display:flex;"><span>		register_module(<span style="color:#e6db74">&#34;fc2&#34;</span>, fc2);
</span></span><span style="display:flex;"><span>		register_module(<span style="color:#e6db74">&#34;fc3&#34;</span>, fc3);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Implement forward pass of each batch to the network
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    torch<span style="color:#f92672">::</span>Tensor forward(torch<span style="color:#f92672">::</span>Tensor x) {
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(torch<span style="color:#f92672">::</span>max_pool2d(conv1(x), <span style="color:#ae81ff">2</span>));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(torch<span style="color:#f92672">::</span>max_pool2d(conv2(x), <span style="color:#ae81ff">2</span>));
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Flatten
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        x <span style="color:#f92672">=</span> x.view({<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, n});
</span></span><span style="display:flex;"><span>		
</span></span><span style="display:flex;"><span>		x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(fc1(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(fc2(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>log_softmax(fc3(x), <span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x;
</span></span><span style="display:flex;"><span>    };
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Function to calculate output size of input tensor after Convolutional layers
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">int64_t</span> <span style="color:#a6e22e">get_output_shape</span>(<span style="color:#66d9ef">int64_t</span> channels, <span style="color:#66d9ef">int64_t</span> height, <span style="color:#66d9ef">int64_t</span> width) {
</span></span><span style="display:flex;"><span>    	<span style="color:#75715e">// Initialize a Tensor with zeros of input shape
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    	torch<span style="color:#f92672">::</span>Tensor x_sample <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>zeros({<span style="color:#ae81ff">1</span>, channels, height, width});
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    	x_sample <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(conv1(x_sample), <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>        x_sample <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(conv2(x_sample), <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Return batch_size (here, 1) * channels * height * width of x_sample
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#66d9ef">return</span> x_sample.numel();
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p>In our new network, we use 2 Convolutional Layers with Max Pooling and ReLU Activation, and 3 Fully Connected Layers. This, as we mentioned above, reduces the number of parameters for training.</p>
<p>Let us train our network on the dataset now.</p>
<h2 id="training">Training</h2>
<p>Let&rsquo;s discuss steps of training a CNN on our dataset:</p>
<ol>
<li>Set network to training mode using <code>net-&gt;train()</code>.</li>
<li>Iterate through every batch of our data loader:
<ol>
<li>Extract data and labels using:
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> data <span style="color:#f92672">=</span> batch.data;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> target <span style="color:#f92672">=</span> batch.target.squeeze();
</span></span></code></pre></div></li>
<li>Clear gradients of optimizer: <code>optimizer.zero_grad()</code></li>
<li>Forward pass the batch of data to the network: <code>auto output = net-&gt;forward(data);</code></li>
<li>Calculate Negative Log Likelihood loss (since we use <code>log_softmax()</code> layer at the end): <code>auto loss = torch::nll_loss(output, target);</code></li>
<li>Backpropagate Loss: <code>auto loss = loss.backward()</code></li>
<li>Update the weights: <code>optimizer.step();</code></li>
<li>Calculate Training Accuracy and Mean Squared Error:
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> acc <span style="color:#f92672">=</span> output.argmax(<span style="color:#ae81ff">1</span>).eq(target).sum();
</span></span><span style="display:flex;"><span>mse <span style="color:#f92672">+=</span> loss.<span style="color:#66d9ef">template</span> item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>();
</span></span></code></pre></div></li>
</ol>
</li>
<li>Save the model using <code>torch::save(net, &quot;model.pt&quot;);</code>.</li>
</ol>
<p>Let&rsquo;s try to convert the above steps to a <code>train()</code> function.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">train</span>(ConvNet<span style="color:#f92672">&amp;</span> net, DataLoader<span style="color:#f92672">&amp;</span> data_loader, torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>Optimizer<span style="color:#f92672">&amp;</span> optimizer, size_t dataset_size, <span style="color:#66d9ef">int</span> epoch) {
</span></span><span style="display:flex;"><span>	<span style="color:#75715e">/*
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	This function trains the network on our data loader using optimizer for given number of epochs.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	Parameters
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	==================
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	ConvNet&amp; net: Network struct
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	DataLoader&amp; data_loader: Training data loader
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	torch::optim::Optimizer&amp; optimizer: Optimizer like Adam, SGD etc.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	size_t dataset_size: Size of training dataset
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	int epoch: Number of epoch for training
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	*/</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	net<span style="color:#f92672">-&gt;</span>train();
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    size_t batch_index <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> mse <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> Acc <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">auto</span><span style="color:#f92672">&amp;</span> batch: <span style="color:#f92672">*</span>data_loader) {
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">auto</span> data <span style="color:#f92672">=</span> batch.data;
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">auto</span> target <span style="color:#f92672">=</span> batch.target.squeeze();
</span></span><span style="display:flex;"><span>      
</span></span><span style="display:flex;"><span>      <span style="color:#75715e">// Should be of length: batch_size
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>      data <span style="color:#f92672">=</span> data.to(torch<span style="color:#f92672">::</span>kF32);
</span></span><span style="display:flex;"><span>      target <span style="color:#f92672">=</span> target.to(torch<span style="color:#f92672">::</span>kInt64);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      optimizer.zero_grad();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">auto</span> output <span style="color:#f92672">=</span> net<span style="color:#f92672">-&gt;</span>forward(data);
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">auto</span> loss <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>nll_loss(output, target);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      loss.backward();
</span></span><span style="display:flex;"><span>      optimizer.step();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">auto</span> acc <span style="color:#f92672">=</span> output.argmax(<span style="color:#ae81ff">1</span>).eq(target).sum();
</span></span><span style="display:flex;"><span>      Acc <span style="color:#f92672">+=</span> acc.<span style="color:#66d9ef">template</span> item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>();
</span></span><span style="display:flex;"><span>      mse <span style="color:#f92672">+=</span> loss.<span style="color:#66d9ef">template</span> item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      batch_index <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>;
</span></span><span style="display:flex;"><span>      count<span style="color:#f92672">++</span>;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    mse <span style="color:#f92672">=</span> mse<span style="color:#f92672">/</span><span style="color:#66d9ef">float</span>(batch_index); <span style="color:#75715e">// Take mean of loss
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Epoch: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> epoch <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;, &#34;</span> <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Accuracy: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> Acc<span style="color:#f92672">/</span>dataset_size <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;, &#34;</span> <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;MSE: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> mse <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>save(net, <span style="color:#e6db74">&#34;best_model_try.pt&#34;</span>);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Similarly, we also define a Test Function to test our network on the test dataset. The steps include:</p>
<ol>
<li>Set network to <code>eval</code> mode: <code>network-&gt;eval()</code>.</li>
<li>Iterate through every batch of test data.
<ol>
<li>Extract data and labels.</li>
<li>Forward pass the batch of data to the network.</li>
<li>Calculate NLL Loss and Accuracy</li>
</ol>
</li>
<li>Print test loss and accuracy.</li>
</ol>
<p>The code for the <code>test()</code> function is below:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">test</span>(ConvNet<span style="color:#f92672">&amp;</span> network, DataLoader<span style="color:#f92672">&amp;</span> loader, size_t data_size) {
</span></span><span style="display:flex;"><span>  size_t batch_index <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  network<span style="color:#f92672">-&gt;</span>eval();
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">float</span> Loss <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>, Acc <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span> (<span style="color:#66d9ef">const</span> <span style="color:#66d9ef">auto</span><span style="color:#f92672">&amp;</span> batch : <span style="color:#f92672">*</span>loader) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> data <span style="color:#f92672">=</span> batch.data;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> targets <span style="color:#f92672">=</span> batch.target.view({<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>});
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    data <span style="color:#f92672">=</span> data.to(torch<span style="color:#f92672">::</span>kF32);
</span></span><span style="display:flex;"><span>	targets <span style="color:#f92672">=</span> targets.to(torch<span style="color:#f92672">::</span>kInt64);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> output <span style="color:#f92672">=</span> network<span style="color:#f92672">-&gt;</span>forward(data);
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> loss <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>nll_loss(output, targets);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> acc <span style="color:#f92672">=</span> output.argmax(<span style="color:#ae81ff">1</span>).eq(targets).sum();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    Loss <span style="color:#f92672">+=</span> loss.<span style="color:#66d9ef">template</span> item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>();
</span></span><span style="display:flex;"><span>    Acc <span style="color:#f92672">+=</span> acc.<span style="color:#66d9ef">template</span> item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>();
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Test Loss: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> Loss<span style="color:#f92672">/</span>data_size <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;, Acc:&#34;</span> <span style="color:#f92672">&lt;&lt;</span> Acc<span style="color:#f92672">/</span>data_size <span style="color:#f92672">&lt;&lt;</span> endl;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h2 id="results">Results</h2>
<p>I trained my network on the dataset for 100 Epochs.</p>
<p>The best training and testing accuracies are given below:</p>
<ol>
<li><strong>Best Training Accuracy:</strong> 99.82%</li>
<li><strong>Best Testing Accuracy:</strong> 82.43%</li>
</ol>
<p>Let&rsquo;s look at some of the correct and wrong predictions.</p>
<h2 id="correct-predictions-dogs">Correct Predictions (Dogs)</h2>
<p><img alt="Correct Predictions of Dogs" src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Correct-Predictions-Dogs.png"></p>
<h2 id="correct-predictions-cats">Correct Predictions (Cats)</h2>
<p><img alt="Correct Predictions of Cats" src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Correct-Predictions-Cats.png">
<img alt="Correct Predictions of Cats" src="https://krshrimali.github.io/assets/Correct-Predictions-Cats.png"></p>
<h2 id="wrong-predictions-dogs">Wrong Predictions (Dogs)</h2>
<p><img alt="Wrong Predictions of Dogs" src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Wrong-Predictions-Dog.png"></p>
<h2 id="wrong-predictions-cats">Wrong Predictions (Cats)</h2>
<p><img alt="Wrong Predictions of Cats" src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Wrong-Predictions-Cats.png"></p>
<p>Clearly, the network has done well for just a 2 Convolutional and 3 FC Layer Network. It seems to have focused more on the posture of the animal (and body). We can make the network learn more robust features, with a more deeper CNN (like VGG-16). We&rsquo;ll be discussing on using pretrained weights on Dogs vs Cats Dataset using PyTorch C++ API and also Transfer Learning Approach in C++.</p>
<p>Happy Learning!</p>

      </div>
    </article>

    <hr />

    <div class="post-info">
      
    <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg>

        <span class="tag"><a href="https://krshrimali.github.io/tags/development/">development</a></span>
        <span class="tag"><a href="https://krshrimali.github.io/tags/coding/">coding</a></span>
        <span class="tag"><a href="https://krshrimali.github.io/tags/cpp/">cpp</a></span>
        <span class="tag"><a href="https://krshrimali.github.io/tags/notes/">notes</a></span>
        <span class="tag"><a href="https://krshrimali.github.io/tags/pytorch-cpp/">pytorch-cpp</a></span>
        <span class="tag"><a href="https://krshrimali.github.io/tags/libtorch/">libtorch</a></span>
        
    </p>

      
    <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-folder meta-icon"><path d="M22 19a2 2 0 0 1-2 2H4a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h5l2 3h9a2 2 0 0 1 2 2z"></path></svg>

        <span class="tag"><a href="https://krshrimali.github.io/categories/pytorch/">pytorch</a></span>
        <span class="tag"><a href="https://krshrimali.github.io/categories/deep-learning/">deep learning</a></span>
        
    </p>


      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text">
          <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path>
          <polyline points="14 2 14 8 20 8"></polyline>
          <line x1="16" y1="13" x2="8" y2="13"></line>
          <line x1="16" y1="17" x2="8" y2="17"></line>
          <polyline points="10 9 9 9 8 9"></polyline>
        </svg>
        1385 Words
      </p>

      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar">
          <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect>
          <line x1="16" y1="2" x2="16" y2="6"></line>
          <line x1="8" y1="2" x2="8" y2="6"></line>
          <line x1="3" y1="10" x2="21" y2="10"></line>
        </svg>
        
          2019-07-31 05:30 &#43;0530
        

         
          
        
      </p>
    </div>

    
    <div class="pagination">
        

        <div class="pagination__buttons">
            
            <span class="button previous">
                <a href="https://krshrimali.github.io/posts/2019/08/applying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api/">
                    <span class="button__icon">←</span>
                    <span class="button__text">Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C&#43;&#43; API</span>
                </a>
            </span>
            

            
            <span class="button next">
                <a href="https://krshrimali.github.io/posts/2019/07/classifying-dogs-vs-cats-using-pytorch-c-api-part-1/">
                    <span class="button__text">Classifying Dogs vs Cats using PyTorch C&#43;&#43; API: Part-1</span>
                    <span class="button__icon">→</span>
                </a>
            </span>
            
        </div>
    </div>


    

    

    

  </main>

            </div>

            
                <footer class="footer">
    
    
</footer>

            
        </div>

        



<script type="text/javascript" src="https://krshrimali.github.io/bundle.min.e89fda0f29b95d33f6f4224dd9e5cf69d84aff3818be2b0d73e731689cc374261b016d17d46f8381962fb4a1577ba3017b1f23509d894f6e66431f988c00889e.js" integrity="sha512-6J/aDym5XTP29CJN2eXPadhK/zgYvisNc&#43;cxaJzDdCYbAW0X1G&#43;DgZYvtKFXe6MBex8jUJ2JT25mQx&#43;YjACIng=="></script>




    </body>
</html>
