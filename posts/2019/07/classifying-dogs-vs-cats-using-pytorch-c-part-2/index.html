<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Classifying Dogs vs Cats using PyTorch C&#43;&#43;: Part 2 | Kushashwa Ravi Shrimali (Kush)</title>
<meta name="keywords" content="development, coding, cpp, notes, pytorch-cpp, libtorch">
<meta name="description" content="In the last blog, we had discussed all but training and results of our custom CNN network on Dogs vs Cats dataset. Today, we&rsquo;ll be making some small changes in the network and discussing training and results of the task.

I&rsquo;ll start with the network overview again, where we used a network similar to VGG-16 (with one extra Fully Connected Layer in the end). While there are absolutely no problems with that network, but since the dataset contains a lot of images (25000 in training dataset) and we were using (200x200x3) input shape to the network (which is 120,000 floating point numbers), this leads to high memory consumption. In short, I was out of RAM to store these many images during program execution.">
<meta name="author" content="map[name:Kushashwa Ravi Shrimali]">
<link rel="canonical" href="https://krshrimali.github.io/posts/2019/07/classifying-dogs-vs-cats-using-pytorch-c-part-2/">
<link crossorigin="anonymous" href="https://krshrimali.github.io/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css" integrity="sha256-j&#43;ECM6cGvIfy4Is8&#43;XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://krshrimali.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://krshrimali.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://krshrimali.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://krshrimali.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://krshrimali.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://krshrimali.github.io/posts/2019/07/classifying-dogs-vs-cats-using-pytorch-c-part-2/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="https://krshrimali.github.io/posts/2019/07/classifying-dogs-vs-cats-using-pytorch-c-part-2/">
  <meta property="og:site_name" content="Kushashwa Ravi Shrimali (Kush)">
  <meta property="og:title" content="Classifying Dogs vs Cats using PyTorch C&#43;&#43;: Part 2">
  <meta property="og:description" content="In the last blog, we had discussed all but training and results of our custom CNN network on Dogs vs Cats dataset. Today, we’ll be making some small changes in the network and discussing training and results of the task.
I’ll start with the network overview again, where we used a network similar to VGG-16 (with one extra Fully Connected Layer in the end). While there are absolutely no problems with that network, but since the dataset contains a lot of images (25000 in training dataset) and we were using (200x200x3) input shape to the network (which is 120,000 floating point numbers), this leads to high memory consumption. In short, I was out of RAM to store these many images during program execution.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2019-07-31T00:00:00+00:00">
    <meta property="article:modified_time" content="2019-07-31T00:00:00+00:00">
    <meta property="article:tag" content="Development">
    <meta property="article:tag" content="Coding">
    <meta property="article:tag" content="Cpp">
    <meta property="article:tag" content="Notes">
    <meta property="article:tag" content="Pytorch-Cpp">
    <meta property="article:tag" content="Libtorch">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Classifying Dogs vs Cats using PyTorch C&#43;&#43;: Part 2">
<meta name="twitter:description" content="In the last blog, we had discussed all but training and results of our custom CNN network on Dogs vs Cats dataset. Today, we&rsquo;ll be making some small changes in the network and discussing training and results of the task.

I&rsquo;ll start with the network overview again, where we used a network similar to VGG-16 (with one extra Fully Connected Layer in the end). While there are absolutely no problems with that network, but since the dataset contains a lot of images (25000 in training dataset) and we were using (200x200x3) input shape to the network (which is 120,000 floating point numbers), this leads to high memory consumption. In short, I was out of RAM to store these many images during program execution.">


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [
    {
      "@type": "ListItem",
      "position":  1 ,
      "name": "Posts",
      "item": "https://krshrimali.github.io/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Classifying Dogs vs Cats using PyTorch C++: Part 2",
      "item": "https://krshrimali.github.io/posts/2019/07/classifying-dogs-vs-cats-using-pytorch-c-part-2/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Classifying Dogs vs Cats using PyTorch C++: Part 2",
  "name": "Classifying Dogs vs Cats using PyTorch C\u002b\u002b: Part 2",
  "description": "In the last blog, we had discussed all but training and results of our custom CNN network on Dogs vs Cats dataset. Today, we\u0026rsquo;ll be making some small changes in the network and discussing training and results of the task.\nI\u0026rsquo;ll start with the network overview again, where we used a network similar to VGG-16 (with one extra Fully Connected Layer in the end). While there are absolutely no problems with that network, but since the dataset contains a lot of images (25000 in training dataset) and we were using (200x200x3) input shape to the network (which is 120,000 floating point numbers), this leads to high memory consumption. In short, I was out of RAM to store these many images during program execution.\n",
  "keywords": [
    "development", "coding", "cpp", "notes", "pytorch-cpp", "libtorch"
  ],
  "articleBody": "In the last blog, we had discussed all but training and results of our custom CNN network on Dogs vs Cats dataset. Today, we’ll be making some small changes in the network and discussing training and results of the task.\nI’ll start with the network overview again, where we used a network similar to VGG-16 (with one extra Fully Connected Layer in the end). While there are absolutely no problems with that network, but since the dataset contains a lot of images (25000 in training dataset) and we were using (200x200x3) input shape to the network (which is 120,000 floating point numbers), this leads to high memory consumption. In short, I was out of RAM to store these many images during program execution.\nSo, I decided to change some minute things:\nInput Shape to the network is now 64x64x3 (12,288 parameters - around 10 times lesser than for 200x200x3). So, all the images are now resized to 64x64x3. Now, we only use 2 Convolutional Layers and 2 Max Pooling Layers to train our dataset. This helps to reduce the parameters for training, and also fastens the training process. But this comes with a tradeoff in accuracy, which will suffice for now as our target is not to get some X accuracy, but to learn how to train the network on our dataset using PyTorch C++ API.\nQuestion: Does reducing input resolution, affects accuracy? Answer: In this case, it will. The objects in our dataset (dogs and cats) have both high level and low level features, which are visible (provides more details) more to the network with high resolution. In this way, the network is allowed to learn more features out of the dataset. However, in cases like of MNIST, it’s just fine to use 64x64 input resolution as it still allows the network to look at details of a digit and learn robust features.\nLet’s go ahead and see what has changed in the Network.\nNetwork Overview If you don’t remember from the last time, this is how our network looked.\nstruct NetImpl: public torch::nn::Module { NetImpl() { // Initialize the network // On how to pass strides and padding: https://github.com/pytorch/pytorch/issues/12649#issuecomment-430156160 conv1_1 = register_module(\"conv1_1\", torch::nn::Conv2d(torch::nn::Conv2dOptions(1, 10, 3).padding(1))); conv1_2 = register_module(\"conv1_2\", torch::nn::Conv2d(torch::nn::Conv2dOptions(10, 20, 3).padding(1))); // Insert pool layer conv2_1 = register_module(\"conv2_1\", torch::nn::Conv2d(torch::nn::Conv2dOptions(20, 30, 3).padding(1))); conv2_2 = register_module(\"conv2_2\", torch::nn::Conv2d(torch::nn::Conv2dOptions(30, 40, 3).padding(1))); // Insert pool layer conv3_1 = register_module(\"conv3_1\", torch::nn::Conv2d(torch::nn::Conv2dOptions(40, 50, 3).padding(1))); conv3_2 = register_module(\"conv3_2\", torch::nn::Conv2d(torch::nn::Conv2dOptions(50, 60, 3).padding(1))); conv3_3 = register_module(\"conv3_3\", torch::nn::Conv2d(torch::nn::Conv2dOptions(60, 70, 3).padding(1))); // Insert pool layer conv4_1 = register_module(\"conv4_1\", torch::nn::Conv2d(torch::nn::Conv2dOptions(70, 80, 3).padding(1))); conv4_2 = register_module(\"conv4_2\", torch::nn::Conv2d(torch::nn::Conv2dOptions(80, 90, 3).padding(1))); conv4_3 = register_module(\"conv4_3\", torch::nn::Conv2d(torch::nn::Conv2dOptions(90, 100, 3).padding(1))); // Insert pool layer conv5_1 = register_module(\"conv5_1\", torch::nn::Conv2d(torch::nn::Conv2dOptions(100, 110, 3).padding(1))); conv5_2 = register_module(\"conv5_2\", torch::nn::Conv2d(torch::nn::Conv2dOptions(110, 120, 3).padding(1))); conv5_3 = register_module(\"conv5_3\", torch::nn::Conv2d(torch::nn::Conv2dOptions(120, 130, 3).padding(1))); // Insert pool layer fc1 = register_module(\"fc1\", torch::nn::Linear(130*6*6, 2000)); fc2 = register_module(\"fc2\", torch::nn::Linear(2000, 1000)); fc3 = register_module(\"fc3\", torch::nn::Linear(1000, 100)); fc4 = register_module(\"fc4\", torch::nn::Linear(100, 2)); } // Implement Algorithm torch::Tensor forward(torch::Tensor x) { x = torch::relu(conv1_1-\u003eforward(x)); x = torch::relu(conv1_2-\u003eforward(x)); x = torch::max_pool2d(x, 2); x = torch::relu(conv2_1-\u003eforward(x)); x = torch::relu(conv2_2-\u003eforward(x)); x = torch::max_pool2d(x, 2); x = torch::relu(conv3_1-\u003eforward(x)); x = torch::relu(conv3_2-\u003eforward(x)); x = torch::relu(conv3_3-\u003eforward(x)); x = torch::max_pool2d(x, 2); x = torch::relu(conv4_1-\u003eforward(x)); x = torch::relu(conv4_2-\u003eforward(x)); x = torch::relu(conv4_3-\u003eforward(x)); x = torch::max_pool2d(x, 2); x = torch::relu(conv5_1-\u003eforward(x)); x = torch::relu(conv5_2-\u003eforward(x)); x = torch::relu(conv5_3-\u003eforward(x)); x = torch::max_pool2d(x, 2); x = x.view({-1, 130*6*6}); x = torch::relu(fc1-\u003eforward(x)); x = torch::relu(fc2-\u003eforward(x)); x = torch::relu(fc3-\u003eforward(x)); x = fc4-\u003eforward(x); return torch::log_softmax(x, 1); } // Declare layers torch::nn::Conv2d conv1_1{nullptr}; torch::nn::Conv2d conv1_2{nullptr}; torch::nn::Conv2d conv2_1{nullptr}; torch::nn::Conv2d conv2_2{nullptr}; torch::nn::Conv2d conv3_1{nullptr}; torch::nn::Conv2d conv3_2{nullptr}; torch::nn::Conv2d conv3_3{nullptr}; torch::nn::Conv2d conv4_1{nullptr}; torch::nn::Conv2d conv4_2{nullptr}; torch::nn::Conv2d conv4_3{nullptr}; torch::nn::Conv2d conv5_1{nullptr}; torch::nn::Conv2d conv5_2{nullptr}; torch::nn::Conv2d conv5_3{nullptr}; torch::nn::Linear fc1{nullptr}, fc2{nullptr}, fc3{nullptr}, fc4{nullptr}; }; As it’s visible, we had 13 Convolutional Layers, 5 Max Pooling Layers and 4 Fully Connected Layers. This leads of a lot of parameters to be trained.\nTherefore, our new network for experimentation purposes will be:\nstruct NetworkImpl : public torch::nn::Module { NetImpl(int64_t channels, int64_t height, int64_t width) { conv1_1 = register_module(\"conv1\", torch::nn::Conv2d(torch::nn::Conv2dOptions(3, 50, 5).stride(2))); conv2_1 = register_module(\"conv2\", torch::nn::Conv2d(torch::nn::Conv2dOptions(50, 100, 7).stride(2))); // Used to find the output size till previous convolutional layers n(get_output_shape(channels, height, width)); fc1 = register_module(\"fc1\", torch::nn::Linear(n, 120)); fc2 = register_module(\"fc2\", torch::nn::Linear(120, 100)); fc3 = register_module(\"fc3\", torch::nn::Linear(100, 2)); register_module(\"conv1\", conv1); register_module(\"conv2\", conv2); register_module(\"fc1\", fc1); register_module(\"fc2\", fc2); register_module(\"fc3\", fc3); } // Implement forward pass of each batch to the network torch::Tensor forward(torch::Tensor x) { x = torch::relu(torch::max_pool2d(conv1(x), 2)); x = torch::relu(torch::max_pool2d(conv2(x), 2)); // Flatten x = x.view({-1, n}); x = torch::relu(fc1(x)); x = torch::relu(fc2(x)); x = torch::log_softmax(fc3(x), 1); return x; }; // Function to calculate output size of input tensor after Convolutional layers int64_t get_output_shape(int64_t channels, int64_t height, int64_t width) { // Initialize a Tensor with zeros of input shape torch::Tensor x_sample = torch::zeros({1, channels, height, width}); x_sample = torch::max_pool2d(conv1(x_sample), 2); x_sample = torch::max_pool2d(conv2(x_sample), 2); // Return batch_size (here, 1) * channels * height * width of x_sample return x_sample.numel(); } }; In our new network, we use 2 Convolutional Layers with Max Pooling and ReLU Activation, and 3 Fully Connected Layers. This, as we mentioned above, reduces the number of parameters for training.\nLet us train our network on the dataset now.\nTraining Let’s discuss steps of training a CNN on our dataset:\nSet network to training mode using net-\u003etrain(). Iterate through every batch of our data loader: Extract data and labels using: auto data = batch.data; auto target = batch.target.squeeze(); Clear gradients of optimizer: optimizer.zero_grad() Forward pass the batch of data to the network: auto output = net-\u003eforward(data); Calculate Negative Log Likelihood loss (since we use log_softmax() layer at the end): auto loss = torch::nll_loss(output, target); Backpropagate Loss: auto loss = loss.backward() Update the weights: optimizer.step(); Calculate Training Accuracy and Mean Squared Error: auto acc = output.argmax(1).eq(target).sum(); mse += loss.template item\u003cfloat\u003e(); Save the model using torch::save(net, \"model.pt\");. Let’s try to convert the above steps to a train() function.\nvoid train(ConvNet\u0026 net, DataLoader\u0026 data_loader, torch::optim::Optimizer\u0026 optimizer, size_t dataset_size, int epoch) { /* This function trains the network on our data loader using optimizer for given number of epochs. Parameters ================== ConvNet\u0026 net: Network struct DataLoader\u0026 data_loader: Training data loader torch::optim::Optimizer\u0026 optimizer: Optimizer like Adam, SGD etc. size_t dataset_size: Size of training dataset int epoch: Number of epoch for training */ net-\u003etrain(); size_t batch_index = 0; float mse = 0; float Acc = 0.0; for(auto\u0026 batch: *data_loader) { auto data = batch.data; auto target = batch.target.squeeze(); // Should be of length: batch_size data = data.to(torch::kF32); target = target.to(torch::kInt64); optimizer.zero_grad(); auto output = net-\u003eforward(data); auto loss = torch::nll_loss(output, target); loss.backward(); optimizer.step(); auto acc = output.argmax(1).eq(target).sum(); Acc += acc.template item\u003cfloat\u003e(); mse += loss.template item\u003cfloat\u003e(); batch_index += 1; count++; } mse = mse/float(batch_index); // Take mean of loss std::cout \u003c\u003c \"Epoch: \" \u003c\u003c epoch \u003c\u003c \", \" \u003c\u003c \"Accuracy: \" \u003c\u003c Acc/dataset_size \u003c\u003c \", \" \u003c\u003c \"MSE: \" \u003c\u003c mse \u003c\u003c std::endl; torch::save(net, \"best_model_try.pt\"); } Similarly, we also define a Test Function to test our network on the test dataset. The steps include:\nSet network to eval mode: network-\u003eeval(). Iterate through every batch of test data. Extract data and labels. Forward pass the batch of data to the network. Calculate NLL Loss and Accuracy Print test loss and accuracy. The code for the test() function is below:\nvoid test(ConvNet\u0026 network, DataLoader\u0026 loader, size_t data_size) { size_t batch_index = 0; network-\u003eeval(); float Loss = 0, Acc = 0; for (const auto\u0026 batch : *loader) { auto data = batch.data; auto targets = batch.target.view({-1}); data = data.to(torch::kF32); targets = targets.to(torch::kInt64); auto output = network-\u003eforward(data); auto loss = torch::nll_loss(output, targets); auto acc = output.argmax(1).eq(targets).sum(); Loss += loss.template item\u003cfloat\u003e(); Acc += acc.template item\u003cfloat\u003e(); } cout \u003c\u003c \"Test Loss: \" \u003c\u003c Loss/data_size \u003c\u003c \", Acc:\" \u003c\u003c Acc/data_size \u003c\u003c endl; } Results I trained my network on the dataset for 100 Epochs.\nThe best training and testing accuracies are given below:\nBest Training Accuracy: 99.82% Best Testing Accuracy: 82.43% Let’s look at some of the correct and wrong predictions.\nCorrect Predictions (Dogs) Correct Predictions (Cats) Wrong Predictions (Dogs) Wrong Predictions (Cats) Clearly, the network has done well for just a 2 Convolutional and 3 FC Layer Network. It seems to have focused more on the posture of the animal (and body). We can make the network learn more robust features, with a more deeper CNN (like VGG-16). We’ll be discussing on using pretrained weights on Dogs vs Cats Dataset using PyTorch C++ API and also Transfer Learning Approach in C++.\nHappy Learning!\n",
  "wordCount" : "1385",
  "inLanguage": "en",
  "datePublished": "2019-07-31T00:00:00Z",
  "dateModified": "2019-07-31T00:00:00Z",
  "author":{
    "@type": "Person",
    "name": {"name":"Kushashwa Ravi Shrimali"}
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://krshrimali.github.io/posts/2019/07/classifying-dogs-vs-cats-using-pytorch-c-part-2/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Kushashwa Ravi Shrimali (Kush)",
    "logo": {
      "@type": "ImageObject",
      "url": "https://krshrimali.github.io/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://krshrimali.github.io/" accesskey="h" title="Kushashwa Ravi Shrimali (Kush) (Alt + H)">Kushashwa Ravi Shrimali (Kush)</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://krshrimali.github.io/search/" title="Search">
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://krshrimali.github.io/about" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://krshrimali.github.io/posts" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://krshrimali.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://krshrimali.github.io/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Classifying Dogs vs Cats using PyTorch C&#43;&#43;: Part 2
    </h1>
    <div class="post-meta"><span title='2019-07-31 00:00:00 +0000 UTC'>July 31, 2019</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;map[name:Kushashwa Ravi Shrimali]

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#network-overview" aria-label="Network Overview">Network Overview</a></li>
                <li>
                    <a href="#training" aria-label="Training">Training</a></li>
                <li>
                    <a href="#results" aria-label="Results">Results</a></li>
                <li>
                    <a href="#correct-predictions-dogs" aria-label="Correct Predictions (Dogs)">Correct Predictions (Dogs)</a></li>
                <li>
                    <a href="#correct-predictions-cats" aria-label="Correct Predictions (Cats)">Correct Predictions (Cats)</a></li>
                <li>
                    <a href="#wrong-predictions-dogs" aria-label="Wrong Predictions (Dogs)">Wrong Predictions (Dogs)</a></li>
                <li>
                    <a href="#wrong-predictions-cats" aria-label="Wrong Predictions (Cats)">Wrong Predictions (Cats)</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>In the last blog, we had discussed all but training and results of our custom CNN network on Dogs vs Cats dataset. Today, we&rsquo;ll be making some small changes in the network and discussing training and results of the task.</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Classify-Dogs-Cats-Blog-05.jpg"></p>
<p>I&rsquo;ll start with the network overview again, where we used a network similar to VGG-16 (with one extra Fully Connected Layer in the end). While there are absolutely no problems with that network, but since the dataset contains a lot of images (25000 in training dataset) and we were using (200x200x3) input shape to the network (which is 120,000 floating point numbers), this leads to high memory consumption. In short, I was out of RAM to store these many images during program execution.</p>
<p>So, I decided to change some minute things:</p>
<ol>
<li>Input Shape to the network is now <code>64x64x3</code> (12,288 parameters - around 10 times lesser than for <code>200x200x3</code>). So, all the images are now resized to <code>64x64x3</code>.</li>
<li>Now, we only use 2 Convolutional Layers and 2 Max Pooling Layers to train our dataset. This helps to reduce the parameters for training, and also fastens the training process.</li>
</ol>
<p>But this comes with a tradeoff in accuracy, which will suffice for now as our target is not to get some X accuracy, but to learn how to train the network on our dataset using PyTorch C++ API.</p>
<p><strong>Question</strong>: Does reducing input resolution, affects accuracy?
<strong>Answer</strong>: In this case, it will. The objects in our dataset (dogs and cats) have both high level and low level features, which are visible (provides more details) more to the network with high resolution. In this way, the network is allowed to learn more features out of the dataset. However, in cases like of MNIST, it&rsquo;s just fine to use <code>64x64</code> input resolution as it still allows the network to look at details of a digit and learn robust features.</p>
<p>Let&rsquo;s go ahead and see what has changed in the Network.</p>
<h2 id="network-overview">Network Overview<a hidden class="anchor" aria-hidden="true" href="#network-overview">#</a></h2>
<p>If you don&rsquo;t remember from the last time, this is how our network looked.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">NetImpl</span><span style="color:#f92672">:</span> <span style="color:#66d9ef">public</span> torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Module {
</span></span><span style="display:flex;"><span>    NetImpl() {
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Initialize the network
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#75715e">// On how to pass strides and padding: https://github.com/pytorch/pytorch/issues/12649#issuecomment-430156160
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv1_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv1_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv1_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv1_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv2_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv2_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">30</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv2_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv2_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">30</span>, <span style="color:#ae81ff">40</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv3_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv3_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">40</span>, <span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv3_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv3_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">60</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv3_3 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv3_3&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">60</span>, <span style="color:#ae81ff">70</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv4_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv4_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">70</span>, <span style="color:#ae81ff">80</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv4_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv4_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">80</span>, <span style="color:#ae81ff">90</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv4_3 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv4_3&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">90</span>, <span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv5_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv5_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">110</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv5_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv5_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">110</span>, <span style="color:#ae81ff">120</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv5_3 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv5_3&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">120</span>, <span style="color:#ae81ff">130</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        fc1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">130</span><span style="color:#f92672">*</span><span style="color:#ae81ff">6</span><span style="color:#f92672">*</span><span style="color:#ae81ff">6</span>, <span style="color:#ae81ff">2000</span>));
</span></span><span style="display:flex;"><span>        fc2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">2000</span>, <span style="color:#ae81ff">1000</span>));
</span></span><span style="display:flex;"><span>        fc3 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc3&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">1000</span>, <span style="color:#ae81ff">100</span>));
</span></span><span style="display:flex;"><span>        fc4 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc4&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">2</span>));
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Implement Algorithm
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    torch<span style="color:#f92672">::</span>Tensor forward(torch<span style="color:#f92672">::</span>Tensor x) {
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv1_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv1_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv2_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv2_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv3_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv3_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv3_3<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv4_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv4_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv4_3<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv5_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv5_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv5_3<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> x.view({<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">130</span><span style="color:#f92672">*</span><span style="color:#ae81ff">6</span><span style="color:#f92672">*</span><span style="color:#ae81ff">6</span>});
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(fc1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(fc2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(fc3<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> fc4<span style="color:#f92672">-&gt;</span>forward(x);
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> torch<span style="color:#f92672">::</span>log_softmax(x, <span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Declare layers
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv1_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv1_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv2_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv2_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv3_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv3_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv3_3{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv4_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv4_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv4_3{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv5_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv5_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv5_3{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear fc1{<span style="color:#66d9ef">nullptr</span>}, fc2{<span style="color:#66d9ef">nullptr</span>}, fc3{<span style="color:#66d9ef">nullptr</span>}, fc4{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p>As it&rsquo;s visible, we had 13 Convolutional Layers, 5 Max Pooling Layers and 4 Fully Connected Layers. This leads of a lot of parameters to be trained.</p>
<p>Therefore, our new network for experimentation purposes will be:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">NetworkImpl</span> <span style="color:#f92672">:</span> <span style="color:#66d9ef">public</span> torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Module {
</span></span><span style="display:flex;"><span>	NetImpl(<span style="color:#66d9ef">int64_t</span> channels, <span style="color:#66d9ef">int64_t</span> height, <span style="color:#66d9ef">int64_t</span> width) {
</span></span><span style="display:flex;"><span>		conv1_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">5</span>).stride(<span style="color:#ae81ff">2</span>)));
</span></span><span style="display:flex;"><span>		conv2_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">7</span>).stride(<span style="color:#ae81ff">2</span>)));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		<span style="color:#75715e">// Used to find the output size till previous convolutional layers
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>		n(get_output_shape(channels, height, width));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		fc1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(n, <span style="color:#ae81ff">120</span>));
</span></span><span style="display:flex;"><span>		fc2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">120</span>, <span style="color:#ae81ff">100</span>));
</span></span><span style="display:flex;"><span>		fc3 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc3&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">2</span>));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		register_module(<span style="color:#e6db74">&#34;conv1&#34;</span>, conv1);
</span></span><span style="display:flex;"><span>		register_module(<span style="color:#e6db74">&#34;conv2&#34;</span>, conv2);
</span></span><span style="display:flex;"><span>		register_module(<span style="color:#e6db74">&#34;fc1&#34;</span>, fc1);
</span></span><span style="display:flex;"><span>		register_module(<span style="color:#e6db74">&#34;fc2&#34;</span>, fc2);
</span></span><span style="display:flex;"><span>		register_module(<span style="color:#e6db74">&#34;fc3&#34;</span>, fc3);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Implement forward pass of each batch to the network
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    torch<span style="color:#f92672">::</span>Tensor forward(torch<span style="color:#f92672">::</span>Tensor x) {
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(torch<span style="color:#f92672">::</span>max_pool2d(conv1(x), <span style="color:#ae81ff">2</span>));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(torch<span style="color:#f92672">::</span>max_pool2d(conv2(x), <span style="color:#ae81ff">2</span>));
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Flatten
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        x <span style="color:#f92672">=</span> x.view({<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, n});
</span></span><span style="display:flex;"><span>		
</span></span><span style="display:flex;"><span>		x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(fc1(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(fc2(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>log_softmax(fc3(x), <span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x;
</span></span><span style="display:flex;"><span>    };
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Function to calculate output size of input tensor after Convolutional layers
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">int64_t</span> <span style="color:#a6e22e">get_output_shape</span>(<span style="color:#66d9ef">int64_t</span> channels, <span style="color:#66d9ef">int64_t</span> height, <span style="color:#66d9ef">int64_t</span> width) {
</span></span><span style="display:flex;"><span>    	<span style="color:#75715e">// Initialize a Tensor with zeros of input shape
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    	torch<span style="color:#f92672">::</span>Tensor x_sample <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>zeros({<span style="color:#ae81ff">1</span>, channels, height, width});
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    	x_sample <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(conv1(x_sample), <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>        x_sample <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(conv2(x_sample), <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Return batch_size (here, 1) * channels * height * width of x_sample
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#66d9ef">return</span> x_sample.numel();
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p>In our new network, we use 2 Convolutional Layers with Max Pooling and ReLU Activation, and 3 Fully Connected Layers. This, as we mentioned above, reduces the number of parameters for training.</p>
<p>Let us train our network on the dataset now.</p>
<h2 id="training">Training<a hidden class="anchor" aria-hidden="true" href="#training">#</a></h2>
<p>Let&rsquo;s discuss steps of training a CNN on our dataset:</p>
<ol>
<li>Set network to training mode using <code>net-&gt;train()</code>.</li>
<li>Iterate through every batch of our data loader:
<ol>
<li>Extract data and labels using:
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> data <span style="color:#f92672">=</span> batch.data;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> target <span style="color:#f92672">=</span> batch.target.squeeze();
</span></span></code></pre></div></li>
<li>Clear gradients of optimizer: <code>optimizer.zero_grad()</code></li>
<li>Forward pass the batch of data to the network: <code>auto output = net-&gt;forward(data);</code></li>
<li>Calculate Negative Log Likelihood loss (since we use <code>log_softmax()</code> layer at the end): <code>auto loss = torch::nll_loss(output, target);</code></li>
<li>Backpropagate Loss: <code>auto loss = loss.backward()</code></li>
<li>Update the weights: <code>optimizer.step();</code></li>
<li>Calculate Training Accuracy and Mean Squared Error:
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> acc <span style="color:#f92672">=</span> output.argmax(<span style="color:#ae81ff">1</span>).eq(target).sum();
</span></span><span style="display:flex;"><span>mse <span style="color:#f92672">+=</span> loss.<span style="color:#66d9ef">template</span> item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>();
</span></span></code></pre></div></li>
</ol>
</li>
<li>Save the model using <code>torch::save(net, &quot;model.pt&quot;);</code>.</li>
</ol>
<p>Let&rsquo;s try to convert the above steps to a <code>train()</code> function.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">train</span>(ConvNet<span style="color:#f92672">&amp;</span> net, DataLoader<span style="color:#f92672">&amp;</span> data_loader, torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>Optimizer<span style="color:#f92672">&amp;</span> optimizer, size_t dataset_size, <span style="color:#66d9ef">int</span> epoch) {
</span></span><span style="display:flex;"><span>	<span style="color:#75715e">/*
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	This function trains the network on our data loader using optimizer for given number of epochs.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	Parameters
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	==================
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	ConvNet&amp; net: Network struct
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	DataLoader&amp; data_loader: Training data loader
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	torch::optim::Optimizer&amp; optimizer: Optimizer like Adam, SGD etc.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	size_t dataset_size: Size of training dataset
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	int epoch: Number of epoch for training
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	*/</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	net<span style="color:#f92672">-&gt;</span>train();
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    size_t batch_index <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> mse <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> Acc <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">auto</span><span style="color:#f92672">&amp;</span> batch: <span style="color:#f92672">*</span>data_loader) {
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">auto</span> data <span style="color:#f92672">=</span> batch.data;
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">auto</span> target <span style="color:#f92672">=</span> batch.target.squeeze();
</span></span><span style="display:flex;"><span>      
</span></span><span style="display:flex;"><span>      <span style="color:#75715e">// Should be of length: batch_size
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>      data <span style="color:#f92672">=</span> data.to(torch<span style="color:#f92672">::</span>kF32);
</span></span><span style="display:flex;"><span>      target <span style="color:#f92672">=</span> target.to(torch<span style="color:#f92672">::</span>kInt64);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      optimizer.zero_grad();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">auto</span> output <span style="color:#f92672">=</span> net<span style="color:#f92672">-&gt;</span>forward(data);
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">auto</span> loss <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>nll_loss(output, target);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      loss.backward();
</span></span><span style="display:flex;"><span>      optimizer.step();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">auto</span> acc <span style="color:#f92672">=</span> output.argmax(<span style="color:#ae81ff">1</span>).eq(target).sum();
</span></span><span style="display:flex;"><span>      Acc <span style="color:#f92672">+=</span> acc.<span style="color:#66d9ef">template</span> item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>();
</span></span><span style="display:flex;"><span>      mse <span style="color:#f92672">+=</span> loss.<span style="color:#66d9ef">template</span> item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      batch_index <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>;
</span></span><span style="display:flex;"><span>      count<span style="color:#f92672">++</span>;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    mse <span style="color:#f92672">=</span> mse<span style="color:#f92672">/</span><span style="color:#66d9ef">float</span>(batch_index); <span style="color:#75715e">// Take mean of loss
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Epoch: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> epoch <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;, &#34;</span> <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Accuracy: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> Acc<span style="color:#f92672">/</span>dataset_size <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;, &#34;</span> <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;MSE: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> mse <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>save(net, <span style="color:#e6db74">&#34;best_model_try.pt&#34;</span>);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Similarly, we also define a Test Function to test our network on the test dataset. The steps include:</p>
<ol>
<li>Set network to <code>eval</code> mode: <code>network-&gt;eval()</code>.</li>
<li>Iterate through every batch of test data.
<ol>
<li>Extract data and labels.</li>
<li>Forward pass the batch of data to the network.</li>
<li>Calculate NLL Loss and Accuracy</li>
</ol>
</li>
<li>Print test loss and accuracy.</li>
</ol>
<p>The code for the <code>test()</code> function is below:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">test</span>(ConvNet<span style="color:#f92672">&amp;</span> network, DataLoader<span style="color:#f92672">&amp;</span> loader, size_t data_size) {
</span></span><span style="display:flex;"><span>  size_t batch_index <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  network<span style="color:#f92672">-&gt;</span>eval();
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">float</span> Loss <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>, Acc <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span> (<span style="color:#66d9ef">const</span> <span style="color:#66d9ef">auto</span><span style="color:#f92672">&amp;</span> batch : <span style="color:#f92672">*</span>loader) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> data <span style="color:#f92672">=</span> batch.data;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> targets <span style="color:#f92672">=</span> batch.target.view({<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>});
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    data <span style="color:#f92672">=</span> data.to(torch<span style="color:#f92672">::</span>kF32);
</span></span><span style="display:flex;"><span>	targets <span style="color:#f92672">=</span> targets.to(torch<span style="color:#f92672">::</span>kInt64);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> output <span style="color:#f92672">=</span> network<span style="color:#f92672">-&gt;</span>forward(data);
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> loss <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>nll_loss(output, targets);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> acc <span style="color:#f92672">=</span> output.argmax(<span style="color:#ae81ff">1</span>).eq(targets).sum();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    Loss <span style="color:#f92672">+=</span> loss.<span style="color:#66d9ef">template</span> item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>();
</span></span><span style="display:flex;"><span>    Acc <span style="color:#f92672">+=</span> acc.<span style="color:#66d9ef">template</span> item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>();
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Test Loss: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> Loss<span style="color:#f92672">/</span>data_size <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;, Acc:&#34;</span> <span style="color:#f92672">&lt;&lt;</span> Acc<span style="color:#f92672">/</span>data_size <span style="color:#f92672">&lt;&lt;</span> endl;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h2 id="results">Results<a hidden class="anchor" aria-hidden="true" href="#results">#</a></h2>
<p>I trained my network on the dataset for 100 Epochs.</p>
<p>The best training and testing accuracies are given below:</p>
<ol>
<li><strong>Best Training Accuracy:</strong> 99.82%</li>
<li><strong>Best Testing Accuracy:</strong> 82.43%</li>
</ol>
<p>Let&rsquo;s look at some of the correct and wrong predictions.</p>
<h2 id="correct-predictions-dogs">Correct Predictions (Dogs)<a hidden class="anchor" aria-hidden="true" href="#correct-predictions-dogs">#</a></h2>
<p><img alt="Correct Predictions of Dogs" loading="lazy" src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Correct-Predictions-Dogs.png"></p>
<h2 id="correct-predictions-cats">Correct Predictions (Cats)<a hidden class="anchor" aria-hidden="true" href="#correct-predictions-cats">#</a></h2>
<p><img alt="Correct Predictions of Cats" loading="lazy" src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Correct-Predictions-Cats.png">
<img alt="Correct Predictions of Cats" loading="lazy" src="https://krshrimali.github.io/assets/Correct-Predictions-Cats.png"></p>
<h2 id="wrong-predictions-dogs">Wrong Predictions (Dogs)<a hidden class="anchor" aria-hidden="true" href="#wrong-predictions-dogs">#</a></h2>
<p><img alt="Wrong Predictions of Dogs" loading="lazy" src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Wrong-Predictions-Dog.png"></p>
<h2 id="wrong-predictions-cats">Wrong Predictions (Cats)<a hidden class="anchor" aria-hidden="true" href="#wrong-predictions-cats">#</a></h2>
<p><img alt="Wrong Predictions of Cats" loading="lazy" src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Wrong-Predictions-Cats.png"></p>
<p>Clearly, the network has done well for just a 2 Convolutional and 3 FC Layer Network. It seems to have focused more on the posture of the animal (and body). We can make the network learn more robust features, with a more deeper CNN (like VGG-16). We&rsquo;ll be discussing on using pretrained weights on Dogs vs Cats Dataset using PyTorch C++ API and also Transfer Learning Approach in C++.</p>
<p>Happy Learning!</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://krshrimali.github.io/tags/development/">Development</a></li>
      <li><a href="https://krshrimali.github.io/tags/coding/">Coding</a></li>
      <li><a href="https://krshrimali.github.io/tags/cpp/">Cpp</a></li>
      <li><a href="https://krshrimali.github.io/tags/notes/">Notes</a></li>
      <li><a href="https://krshrimali.github.io/tags/pytorch-cpp/">Pytorch-Cpp</a></li>
      <li><a href="https://krshrimali.github.io/tags/libtorch/">Libtorch</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://krshrimali.github.io/posts/2019/08/applying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api/">
    <span class="title">« Prev</span>
    <br>
    <span>Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C&#43;&#43; API</span>
  </a>
  <a class="next" href="https://krshrimali.github.io/posts/2019/07/classifying-dogs-vs-cats-using-pytorch-c-api-part-1/">
    <span class="title">Next »</span>
    <br>
    <span>Classifying Dogs vs Cats using PyTorch C&#43;&#43; API: Part-1</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Classifying Dogs vs Cats using PyTorch C&#43;&#43;: Part 2 on x"
            href="https://x.com/intent/tweet/?text=Classifying%20Dogs%20vs%20Cats%20using%20PyTorch%20C%2b%2b%3a%20Part%202&amp;url=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f07%2fclassifying-dogs-vs-cats-using-pytorch-c-part-2%2f&amp;hashtags=development%2ccoding%2ccpp%2cnotes%2cpytorch-cpp%2clibtorch">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Classifying Dogs vs Cats using PyTorch C&#43;&#43;: Part 2 on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f07%2fclassifying-dogs-vs-cats-using-pytorch-c-part-2%2f&amp;title=Classifying%20Dogs%20vs%20Cats%20using%20PyTorch%20C%2b%2b%3a%20Part%202&amp;summary=Classifying%20Dogs%20vs%20Cats%20using%20PyTorch%20C%2b%2b%3a%20Part%202&amp;source=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f07%2fclassifying-dogs-vs-cats-using-pytorch-c-part-2%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Classifying Dogs vs Cats using PyTorch C&#43;&#43;: Part 2 on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f07%2fclassifying-dogs-vs-cats-using-pytorch-c-part-2%2f&title=Classifying%20Dogs%20vs%20Cats%20using%20PyTorch%20C%2b%2b%3a%20Part%202">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Classifying Dogs vs Cats using PyTorch C&#43;&#43;: Part 2 on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f07%2fclassifying-dogs-vs-cats-using-pytorch-c-part-2%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Classifying Dogs vs Cats using PyTorch C&#43;&#43;: Part 2 on whatsapp"
            href="https://api.whatsapp.com/send?text=Classifying%20Dogs%20vs%20Cats%20using%20PyTorch%20C%2b%2b%3a%20Part%202%20-%20https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f07%2fclassifying-dogs-vs-cats-using-pytorch-c-part-2%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Classifying Dogs vs Cats using PyTorch C&#43;&#43;: Part 2 on telegram"
            href="https://telegram.me/share/url?text=Classifying%20Dogs%20vs%20Cats%20using%20PyTorch%20C%2b%2b%3a%20Part%202&amp;url=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f07%2fclassifying-dogs-vs-cats-using-pytorch-c-part-2%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Classifying Dogs vs Cats using PyTorch C&#43;&#43;: Part 2 on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Classifying%20Dogs%20vs%20Cats%20using%20PyTorch%20C%2b%2b%3a%20Part%202&u=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f07%2fclassifying-dogs-vs-cats-using-pytorch-c-part-2%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
