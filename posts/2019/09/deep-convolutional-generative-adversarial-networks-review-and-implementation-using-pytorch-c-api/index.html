<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author" content="map[name:Kushashwa Ravi Shrimali]">
<meta name="description" content="I&rsquo;m pleased to start a series of blogs on GANs and their implementation with PyTorch C&#43;&#43; API. We&rsquo;ll be starting with one of the initial GANs - DCGANs (Deep Convolutional Generative Adversarial Networks).
The authors (Soumith Chintala, Radford and Luke Metz) in this Seminal Paper on DCGANs introduced DCGANs to the world like this:
We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.
" />
<meta name="keywords" content=", development, coding, cpp, notes, pytorch-cpp, libtorch" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="#252627" />
<link rel="canonical" href="https://krshrimali.github.io/posts/2019/09/deep-convolutional-generative-adversarial-networks-review-and-implementation-using-pytorch-c-api/" />


    <title>
        
            Deep Convolutional Generative Adversarial Networks: Review and Implementation using PyTorch C&#43;&#43; API :: Kushashwa Ravi Shrimali (Kush)  — Learning never stops!
        
    </title>





  <link rel="stylesheet" href="https://krshrimali.github.io/main.min.244183cde1a38e0b08f82c11791181288f9aac1cc9618cd6f4e9e7710c5768ba.css" integrity="sha256-JEGDzeGjjgsI&#43;CwReRGBKI&#43;arBzJYYzW9OnncQxXaLo=" crossorigin="anonymous">





    <link rel="apple-touch-icon" sizes="180x180" href="https://krshrimali.github.io/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://krshrimali.github.io/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://krshrimali.github.io/favicon-16x16.png">
    <link rel="manifest" href="https://krshrimali.github.io/site.webmanifest">
    <link rel="mask-icon" href="https://krshrimali.github.io/safari-pinned-tab.svg" color="">
    <link rel="shortcut icon" href="https://krshrimali.github.io/favicon.ico">
    <meta name="msapplication-TileColor" content="">



  <meta itemprop="name" content="Deep Convolutional Generative Adversarial Networks: Review and Implementation using PyTorch C&#43;&#43; API">
  <meta itemprop="description" content="I’m pleased to start a series of blogs on GANs and their implementation with PyTorch C&#43;&#43; API. We’ll be starting with one of the initial GANs - DCGANs (Deep Convolutional Generative Adversarial Networks).
The authors (Soumith Chintala, Radford and Luke Metz) in this Seminal Paper on DCGANs introduced DCGANs to the world like this:
We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.">
  <meta itemprop="datePublished" content="2019-09-15T00:00:00+00:00">
  <meta itemprop="dateModified" content="2019-09-15T00:00:00+00:00">
  <meta itemprop="wordCount" content="2053">
  <meta itemprop="image" content="https://krshrimali.github.io/">
  <meta itemprop="keywords" content="Development,Coding,Cpp,Notes,Pytorch-Cpp,Libtorch">

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:image" content="https://krshrimali.github.io/">
  <meta name="twitter:title" content="Deep Convolutional Generative Adversarial Networks: Review and Implementation using PyTorch C&#43;&#43; API">
  <meta name="twitter:description" content="I’m pleased to start a series of blogs on GANs and their implementation with PyTorch C&#43;&#43; API. We’ll be starting with one of the initial GANs - DCGANs (Deep Convolutional Generative Adversarial Networks).
The authors (Soumith Chintala, Radford and Luke Metz) in this Seminal Paper on DCGANs introduced DCGANs to the world like this:
We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.">





    <meta property="article:section" content="pytorch" />

    <meta property="article:section" content="deep learning" />



    <meta property="article:published_time" content="2019-09-15 00:00:00 &#43;0000 UTC" />









    



    </head>

    
        <body>
    
    
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="https://krshrimali.github.io/" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">></span>
            <span class="logo__text ">
                $ cd /home/</span>
            <span class="logo__cursor" style=
                  "
                   
                   ">
            </span>
        
    </div>
</a>


        <span class="header__right">
                <nav class="menu">
    <ul class="menu__inner"><li><a href="https://krshrimali.github.io/about">About</a></li><li><a href="https://krshrimali.github.io/posts">Blog</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
        </span>
    </span>
</header>


            <div class="content">
                
  <main class="post">

    <div class="post-info">
      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock">
          <circle cx="12" cy="12" r="10"></circle>
          <polyline points="12 6 12 12 16 14"></polyline>
        </svg>
        10 minutes

        
      </p>
    </div>

    <article>
      <h1 class="post-title">
        <a href="https://krshrimali.github.io/posts/2019/09/deep-convolutional-generative-adversarial-networks-review-and-implementation-using-pytorch-c-api/">Deep Convolutional Generative Adversarial Networks: Review and Implementation using PyTorch C++ API</a>
      </h1>

      

      
        <hr />
        <aside id="toc">
          <div class="toc-title">Table of Contents</div>
          <nav id="TableOfContents">
  <ul>
    <li><a href="#introduction-to-dcgan">Introduction to DCGAN</a></li>
    <li><a href="#acknowledgement-and-references">Acknowledgement and References</a></li>
  </ul>
</nav>
        </aside>
        <hr />

      

      <div class="post-content">
        <p>I&rsquo;m pleased to start a series of blogs on GANs and their implementation with PyTorch C++ API. We&rsquo;ll be starting with one of the initial GANs - DCGANs (Deep Convolutional Generative Adversarial Networks).</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Cover-DCGAN.jpg"></p>
<p>The authors (Soumith Chintala, Radford and Luke Metz) in <a href="https://arxiv.org/pdf/1511.06434.pdf">this</a> Seminal Paper on DCGANs introduced DCGANs to the world like this:</p>
<blockquote>
<p>We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.</p>
</blockquote>
<p>Even though, the introduction to DCGANs is quite lucid, but here are some points to note:</p>
<ol>
<li>DCGANs are a class of Convolutional Neural Networks.</li>
<li>They are a strong candidate for Unsupervised Learning.</li>
<li>They are applicable as general image representations as well.</li>
</ol>
<p>Let&rsquo;s go ahead and see what exactly is DCGAN?</p>
<h2 id="introduction-to-dcgan">Introduction to DCGAN</h2>
<p>At the time when this paper was released, there was quite a focus on Supervised Learning. The paper aimed at bridging the gap between Unsupervised Learning and Supervised Learning. DCGANs are a way to understand and extract important feature representations from a dataset and generate good image representations by training.</p>
<p>Any Generative Adversarial Network has 2 major components: a Generator and a Discriminator. The tasks for both of them are simple.</p>
<ol>
<li><strong>Generator</strong>: Generates Images similar to the data distribution such that Discriminator can not distinguish it with the original data.</li>
<li><strong>Discriminator</strong>: Discriminator has a task on accurately distinguishing between the image from the generator and from the data distribution. It basically has to recognize an image as fake or real, correctly.</li>
</ol>
<p>Both Generator and Discriminator tasks can be represented beautifully with the following equation:</p>
<!-- raw HTML omitted -->
<p>The above equation, shows how the Generator and Discriminator plays min-max game.</p>
<ol>
<li>The <strong>Generator tries to minimize the loss function.</strong> It follows up with two cases:
<ol>
<li><strong>When the data is from the data distribution:</strong> Generator has a task of forcing the Discriminator to predict the data as fake.</li>
<li><strong>When data is from the Generator:</strong> Generator has a task of forcing the Discriminator to predict the data as real.</li>
</ol>
</li>
<li>The <strong>Discriminator tries to maximize the loss function.</strong> It follows up with two cases:
<ol>
<li><strong>When the data is from the data distribution:</strong> Discriminator tries to predict the data as real.</li>
<li><strong>When the data is from the Generator:</strong> Discriminator tries to predict the data as fake.</li>
</ol>
</li>
</ol>
<p>Fundamentally, the Generator is trying to fool the Discriminator and the Discriminator is trying not to get fooled with. Because of it&rsquo;s analogy, it&rsquo;s also called a police-thief game. (Police is the Discriminator and thief is the Generator).</p>
<p>We have good enough discussion on GANs, to kickstart discussion on DCGANs. Let&rsquo;s go ahead and see what changes they proposed on common CNNs:</p>
<p>Changes in the <strong>Generator</strong>:</p>
<ol>
<li>Spatial Pooling Layers such as MaxPool Layers were replaced with Fractional-Strided Convolutions (a.k.a Transposed Convolutions). This allows the network to learn it&rsquo;s own spatial downsampling, instead of explicitly mentioning the downsampling parameters by Max Pooling.</li>
<li>Use BatchNorm in the Generator.</li>
<li>Remove Fully Connected layers for deeper architectures.</li>
<li>Use ReLU activation function for all the layers except the output layer (which uses Tanh activation function).</li>
</ol>
<p>Changes in the <strong>Discriminator</strong>:</p>
<ol>
<li>Spatial Pooling Layers such as MaxPool layers were replaced with Strided Convolutions.</li>
<li>Use BatchNorm in the Discriminator.</li>
<li>Remove FC layers for deeper architectures.</li>
<li>Use LeakyReLU activation function for all the layers in the Discriminator.</li>
</ol>
<p><!-- raw HTML omitted --><!-- raw HTML omitted -->Generator of the DCGAN used for LSUN scene modeling. Source: <a href="https://arxiv.org/pdf/1511.06434.pdf">https://arxiv.org/pdf/1511.06434.pdf</a><!-- raw HTML omitted --></p>
<p>As you would note in the above architecture, there is absence of spatial pooling layers and fully connected layers.</p>
<p><!-- raw HTML omitted --><!-- raw HTML omitted -->Discriminator of the DCGAN used for LSUN scene modeling. Source: <a href="https://github.com/ChengBinJin/DCGAN-TensorFlow">https://github.com/ChengBinJin/DCGAN-TensorFlow</a><!-- raw HTML omitted --></p>
<p>Notably again, there are no pooling and fully connected layers (except the last layer).</p>
<p>Let&rsquo;s start with defining the architectures of both Generators and Discriminators using PyTorch C++ API. I used the Object Oriented approach by making class, each for Generator and Discriminator. Note that each of them are a type of CNNs, and also inherit functions (or methods) from <code>torch::nn::Module</code> class.</p>
<p>As mentioned before, Generator uses Transposed Convolutional Layers and has no pooling and FC layers. It also uses ReLU Activation Function (except the last layer). The parameters used for the Generator include:</p>
<ol>
<li><code>dataroot</code>: (type: <code>std::string</code>) Path of the dataset&rsquo;s root directory.</li>
<li><code>workers</code>: (type: <code>int</code>) Having more <code>workers</code> will increase CPU memory usage. (Check this link <a href="https://discuss.pytorch.org/t/guidelines-for-assigning-num-workers-to-dataloader/813/2">for more details</a>)</li>
<li><code>batch_size</code>: (type: <code>int</code>) Batch Size to consider.</li>
<li><code>image_size</code>: (type: <code>int</code>) Size of the image to resize it to.</li>
<li><code>nc</code>: (type: <code>int</code>) Number of channels in the Input Image.</li>
<li><code>nz</code>: (type: <code>int</code>) Length of latent vector, from which the input image is taken.</li>
<li><code>ngf</code>: (type <code>int</code>) Depth of feature maps carried through the generator.</li>
<li><code>num_epochs</code>: (type <code>int</code>) Number of epochs for which the model is trained.</li>
<li><code>lr</code>: (type <code>float</code>) Learning Rate for training. Authors described it to be 0.0002</li>
<li><code>beta1</code>: (type: <code>float</code>) Hyperparameter for Optimizer used (Adam).</li>
<li><code>ngpu</code>: (type: <code>int</code>) Number of GPUs available to use. (use <code>0</code> if no GPU available)</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Generator</span> <span style="color:#f92672">:</span> <span style="color:#66d9ef">public</span> torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Module {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">private</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>string dataroot;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> workers;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> batch_size;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> image_size;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> nc;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> nz;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> ngf;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> num_epochs;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> lr;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> beta1;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> ngpu;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential main;
</span></span><span style="display:flex;"><span>    Generator(std<span style="color:#f92672">::</span>string dataroot_ <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;data/celeba&#34;</span>, <span style="color:#66d9ef">int</span> workers_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>, <span style="color:#66d9ef">int</span> batch_size_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">128</span>, <span style="color:#66d9ef">int</span> image_size_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">64</span>, <span style="color:#66d9ef">int</span> nc_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>, <span style="color:#66d9ef">int</span> nz_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>, <span style="color:#66d9ef">int</span> ngf_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">64</span>, <span style="color:#66d9ef">int</span> ndf_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">64</span>, <span style="color:#66d9ef">int</span> num_epochs_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span>, <span style="color:#66d9ef">float</span> lr_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0002</span>, <span style="color:#66d9ef">float</span> beta1_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.5</span>, <span style="color:#66d9ef">int</span> ngpu_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>) {
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Set the arguments
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        dataroot <span style="color:#f92672">=</span> dataroot_;
</span></span><span style="display:flex;"><span>        workers <span style="color:#f92672">=</span> workers_;
</span></span><span style="display:flex;"><span>        batch_size <span style="color:#f92672">=</span> batch_size_;
</span></span><span style="display:flex;"><span>        image_size <span style="color:#f92672">=</span> image_size_;
</span></span><span style="display:flex;"><span>        nc <span style="color:#f92672">=</span> nc_;
</span></span><span style="display:flex;"><span>        nz <span style="color:#f92672">=</span> nz_;
</span></span><span style="display:flex;"><span>        ngf <span style="color:#f92672">=</span> ngf_;
</span></span><span style="display:flex;"><span>        ndf <span style="color:#f92672">=</span> ndf_;
</span></span><span style="display:flex;"><span>        num_epochs <span style="color:#f92672">=</span> num_epochs_;
</span></span><span style="display:flex;"><span>        lr <span style="color:#f92672">=</span> lr_;
</span></span><span style="display:flex;"><span>        beta1 <span style="color:#f92672">=</span> beta1_;
</span></span><span style="display:flex;"><span>        ngpu <span style="color:#f92672">=</span> ngpu_;
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        main <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential(
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(nz, ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">1</span>).padding(<span style="color:#ae81ff">0</span>).with_bias(false).transposed(true)),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>BatchNorm(ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">8</span>),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>relu),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">8</span>, ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false).transposed(true)),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>BatchNorm(ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>relu),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>, ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false).transposed(true)),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>BatchNorm(ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>relu),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">2</span>, ngf, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false).transposed(true)),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>BatchNorm(ngf),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>relu),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ngf, nc, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false).transposed(true)),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>tanh)
</span></span><span style="display:flex;"><span>        );
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential main_func() {
</span></span><span style="display:flex;"><span>    	<span style="color:#75715e">// Returns Sequential Model of the Generator
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#66d9ef">return</span> main;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p>Note how we used Transposed Convolution, by passing <code>.transposed(true)</code>.</p>
<p>Similarly, we define the class for Discriminator.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Discriminator</span> <span style="color:#f92672">:</span> <span style="color:#66d9ef">public</span> torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Module {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">private</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>string dataroot;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> workers;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> batch_size;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> image_size;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> nc;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> nz;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> ndf;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> num_epochs;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> lr;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> beta1;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> ngpu;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential main;
</span></span><span style="display:flex;"><span>    Discriminator(std<span style="color:#f92672">::</span>string dataroot_ <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;data/celeba&#34;</span>, <span style="color:#66d9ef">int</span> workers_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>, <span style="color:#66d9ef">int</span> batch_size_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">128</span>, <span style="color:#66d9ef">int</span> image_size_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">64</span>, <span style="color:#66d9ef">int</span> nc_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>, <span style="color:#66d9ef">int</span> nz_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>, <span style="color:#66d9ef">int</span> ngf_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">64</span>, <span style="color:#66d9ef">int</span> ndf_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">64</span>, <span style="color:#66d9ef">int</span> num_epochs_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span>, <span style="color:#66d9ef">float</span> lr_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0002</span>, <span style="color:#66d9ef">float</span> beta1_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.5</span>, <span style="color:#66d9ef">int</span> ngpu_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>) {
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        dataroot <span style="color:#f92672">=</span> dataroot_;
</span></span><span style="display:flex;"><span>        workers <span style="color:#f92672">=</span> workers_;
</span></span><span style="display:flex;"><span>        batch_size <span style="color:#f92672">=</span> batch_size_;
</span></span><span style="display:flex;"><span>        image_size <span style="color:#f92672">=</span> image_size_;
</span></span><span style="display:flex;"><span>        nc <span style="color:#f92672">=</span> nc_;
</span></span><span style="display:flex;"><span>        nz <span style="color:#f92672">=</span> nz_;
</span></span><span style="display:flex;"><span>        ngf <span style="color:#f92672">=</span> ngf_;
</span></span><span style="display:flex;"><span>        ndf <span style="color:#f92672">=</span> ndf_;
</span></span><span style="display:flex;"><span>        num_epochs <span style="color:#f92672">=</span> num_epochs_;
</span></span><span style="display:flex;"><span>        lr <span style="color:#f92672">=</span> lr_;
</span></span><span style="display:flex;"><span>        beta1 <span style="color:#f92672">=</span> beta1_;
</span></span><span style="display:flex;"><span>        ngpu <span style="color:#f92672">=</span> ngpu_;
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        main <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential(
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(nc, ndf, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false)),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>leaky_relu, <span style="color:#ae81ff">0.2</span>),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ndf, ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false)),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>BatchNorm(ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>leaky_relu, <span style="color:#ae81ff">0.2</span>),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">2</span>, ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false)),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>BatchNorm(ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>leaky_relu, <span style="color:#ae81ff">0.2</span>),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>, ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false)),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>BatchNorm(ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">8</span>),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>leaky_relu, <span style="color:#ae81ff">0.2</span>),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">1</span>).padding(<span style="color:#ae81ff">0</span>).with_bias(false)),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>sigmoid)
</span></span><span style="display:flex;"><span>        );
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential main_func() {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> main;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p>We can initialize these networks as shown below:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Uses default arguments if no args passed
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>Generator gen <span style="color:#f92672">=</span> Generator()
</span></span><span style="display:flex;"><span>Discriminator dis <span style="color:#f92672">=</span> Discriminator()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential gen_model <span style="color:#f92672">=</span> gen.main_func()
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential dis_model <span style="color:#f92672">=</span> dis.main_func()
</span></span></code></pre></div><p>In case you are using a GPU, you can convert the models:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>Device device <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>kCPU;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span>(torch<span style="color:#f92672">::</span>cuda<span style="color:#f92672">::</span>is_available()) {
</span></span><span style="display:flex;"><span>    device <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>kCUDA;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>gen_model<span style="color:#f92672">-&gt;</span>to(device);
</span></span><span style="display:flex;"><span>dis_model<span style="color:#f92672">-&gt;</span>to(device);
</span></span></code></pre></div><p><strong>Note on Data Loading</strong>: In the past blogs, I&rsquo;ve discussed on loading custom data. Please refer to the previous blogs for a quick review on loading data.</p>
<p>Let&rsquo;s go ahead and define optimizers and train our model. We use the parameters defined by the authors, for optimizer (Adam, <code>beta</code> = 0.5) and learning rate of <code>2e-4</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>Adam gen_optimizer(gen_model<span style="color:#f92672">-&gt;</span>parameters(), torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>AdamOptions(<span style="color:#ae81ff">2e-4</span>).beta1(<span style="color:#ae81ff">0.5</span>));
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>Adam dis_optimizer(dis_model<span style="color:#f92672">-&gt;</span>parameters(), torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>AdamOptions(<span style="color:#ae81ff">2e-4</span>).beta1(<span style="color:#ae81ff">0.5</span>));
</span></span></code></pre></div><p>Time to write our training code. We are using <code>CelebA</code> dataset which looks like this:</p>
<!-- raw HTML omitted -->
<p>The dataset is huge, and contains 10,177 number of identities and around ~200k number of face images. It also contains annotations, but since GANs are a way of unsupervised learning, so they don&rsquo;t actually consider annotations. Before we move on, we&rsquo;ll see a quick step by step review on training the Discriminator and Generator simultaneously:</p>
<ol>
<li><strong>Step-1: Train Discriminator</strong>. Remember from above, the discriminator tries to maximize the loss function such that it predicts the fake images as fake and real images as real.
<ol>
<li>As the first step for every training process, we set the gradients to zero. This helps in calculating correct gradients, and not getting confused with gradients stored in the previous iteration.</li>
<li>First calculate <strong>discriminator loss on real images</strong> (that is, data from our dataset). We do this by getting data from the batch and labels as anything between 0.8 and 1.0 (since it&rsquo;s real, we approximate it from 0.8 to 1.0).</li>
<li>Do a forward pass to the discriminator network, and calculate output on the batch of data from our dataset.</li>
<li>Calculate loss by using <code>torch::binary_cross_entropy</code> and backpropagate the loss.</li>
<li>We now calculate <strong>discriminator loss on fake images</strong> (that is, data from the generator). For this, we take a noise of shape similar to the batch of data, and pass that noise to the generator.</li>
<li>The labels are given zero values (as the images are fake).</li>
<li>Again, calculate the loss by using <code>torch::binary_cross_entropy</code> and backpropagate the loss.</li>
<li>Sum both the losses, <strong>discriminator loss on real images</strong> + <strong>discriminator loss on fake images</strong>. This will be our discriminator loss.</li>
<li>We then update our parameters using the optimizer.</li>
</ol>
</li>
<li><strong>Step-2: Train Generator</strong>. The task of a Generator is to minimize the loss function. Since it has to produce images which can fool the discriminator, so it only has to consider fake images.
<ol>
<li>As the first step for every training process, we set the gradients to zero. This helps in calculating correct gradients, and not getting confused with gradients stored in the previous iteration.</li>
<li>We use the fake images produced in the Step-1 and pass it to the discriminator.</li>
<li>Fill the labels with 1. (since generator wants to fool the discriminator, by making it predict as real images).</li>
<li>Calculate loss, by using <code>torch::binary_cross_entropy</code> and backpropagate the loss.</li>
<li>Update the parameters using optimizer of the Generator.</li>
</ol>
</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">int</span> epoch<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; epoch<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">10</span>; epoch<span style="color:#f92672">++</span>) {
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Store batch count in a variable
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">int</span> batch_count <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// You can use torch::data::Example&lt;&gt;&amp; batch: *data_loader
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">auto</span><span style="color:#f92672">&amp;</span> batch: <span style="color:#f92672">*</span>data_loader) {
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Step-1: Train the Discriminator
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#75715e">// Set gradients to zero
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        netD<span style="color:#f92672">-&gt;</span>zero_grad();
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Calculating discriminator loss on real images
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor images_real <span style="color:#f92672">=</span> batch.data.to(device);
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">::</span>Tensor labels_real <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>empty(batch.data.size(<span style="color:#ae81ff">0</span>), device).uniform_(<span style="color:#ae81ff">0.8</span>, <span style="color:#ae81ff">1.0</span>));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Do a forward pass to the Discriminator network
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor output_D_real <span style="color:#f92672">=</span> netD<span style="color:#f92672">-&gt;</span>forward(images_real);
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Calculate the loss
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor loss_real_D <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>binary_cross_entropy(output_D_real, labels_real);
</span></span><span style="display:flex;"><span>        loss_real_D.backward();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Calculate discriminator loss on fake images
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#75715e">// Generate noise and do forward pass to generate fake images
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch:Tensor fake_random <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>randn({batch.data.size(<span style="color:#ae81ff">0</span>), args.nz, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>}, device);
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">::</span>Tensor images_fake <span style="color:#f92672">=</span> netG<span style="color:#f92672">-&gt;</span>forward(images_fake);
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">::</span>Tensor labels_fake <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>zeros(batch.data.size(<span style="color:#ae81ff">0</span>), device);
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Do a forward pass to the Discriminator network
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor output_D_fake <span style="color:#f92672">=</span> netD<span style="color:#f92672">-&gt;</span>forward(images_fake);
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Calculate the loss
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor loss_fake_D <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>binary_cross_entropy(output_D_fake, labels_fake);
</span></span><span style="display:flex;"><span>        loss_fake_D.backward();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Total discriminator loss
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor loss_discriminator <span style="color:#f92672">=</span> loss_real_D <span style="color:#f92672">+</span> loss_fake_D;
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Update the parameters
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        dis_optimizer.step();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Step-2: Train the Generator
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#75715e">// Set gradients to zero
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        netG<span style="color:#f92672">-&gt;</span>zero_grad();
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// calculating generator loss on fake images
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#75715e">// Change labels_fake from all zeros to all ones
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        labels_fake.fill_(<span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Do forward pass to the Discriminator on the fake images generated above
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor output_G_fake <span style="color:#f92672">=</span> netD<span style="color:#f92672">-&gt;</span>forward(images_fake);
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Calculate loss
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor loss_generator <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>binary_cross_entropy(output_G_fake, labels_fake);
</span></span><span style="display:flex;"><span>        loss_generator.backward();
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Update the parameters
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        gen_optimizer.step();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Epoch: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> epoch <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;, Batch: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> batch_count <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;, Gen Loss: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> loss_generator.item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>() <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;, Discriminator Loss: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> loss_discriminator.item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>() <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>	
</span></span><span style="display:flex;"><span>        batch_count<span style="color:#f92672">++</span>;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>We are all set to train our first DCGAN in C++ using Libtorch. How amazing it is?</p>
<p>In the coming blog, I&rsquo;ll share the results and answer a few common questions on the architecture of DCGAN.</p>
<h2 id="acknowledgement-and-references">Acknowledgement and References</h2>
<p>I would like to thank <a href="https://github.com/yf225">Will Feng</a> and <a href="https://discuss.pytorch.org/u/ptrblck/summary">Piotr</a> for their useful suggestions. The code used in this blog, is partially analogous to the official <a href="https://github.com/pytorch/examples/tree/master/cpp/dcgan">PyTorch examples repo on DCGAN using LibTorch</a>. I&rsquo;ve also referred the original paper by <a href="https://twitter.com/soumithchintala">Soumith Chintala</a> and others. The sources of reference images (for Network architectures) have been acknowledged in the captions of respective images.</p>

      </div>
    </article>

    <hr />

    <div class="post-info">
      
    <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg>

        <span class="tag"><a href="https://krshrimali.github.io/tags/development/">development</a></span>
        <span class="tag"><a href="https://krshrimali.github.io/tags/coding/">coding</a></span>
        <span class="tag"><a href="https://krshrimali.github.io/tags/cpp/">cpp</a></span>
        <span class="tag"><a href="https://krshrimali.github.io/tags/notes/">notes</a></span>
        <span class="tag"><a href="https://krshrimali.github.io/tags/pytorch-cpp/">pytorch-cpp</a></span>
        <span class="tag"><a href="https://krshrimali.github.io/tags/libtorch/">libtorch</a></span>
        
    </p>

      
    <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-folder meta-icon"><path d="M22 19a2 2 0 0 1-2 2H4a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h5l2 3h9a2 2 0 0 1 2 2z"></path></svg>

        <span class="tag"><a href="https://krshrimali.github.io/categories/pytorch/">pytorch</a></span>
        <span class="tag"><a href="https://krshrimali.github.io/categories/deep-learning/">deep learning</a></span>
        
    </p>


      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text">
          <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path>
          <polyline points="14 2 14 8 20 8"></polyline>
          <line x1="16" y1="13" x2="8" y2="13"></line>
          <line x1="16" y1="17" x2="8" y2="17"></line>
          <polyline points="10 9 9 9 8 9"></polyline>
        </svg>
        2053 Words
      </p>

      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar">
          <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect>
          <line x1="16" y1="2" x2="16" y2="6"></line>
          <line x1="8" y1="2" x2="8" y2="6"></line>
          <line x1="3" y1="10" x2="21" y2="10"></line>
        </svg>
        
          2019-09-15 05:30 &#43;0530
        

         
          
        
      </p>
    </div>

    
    <div class="pagination">
        

        <div class="pagination__buttons">
            
            <span class="button previous">
                <a href="https://krshrimali.github.io/posts/2020/02/training-and-results-deep-convolutional-generative-adversarial-networks-on-celeba-dataset-using-pytorch-c-api/">
                    <span class="button__icon">←</span>
                    <span class="button__text">[Training and Results] Deep Convolutional Generative Adversarial Networks on CelebA Dataset using PyTorch C&#43;&#43; API</span>
                </a>
            </span>
            

            
            <span class="button next">
                <a href="https://krshrimali.github.io/posts/2019/08/setting-up-jupyter-notebook-xeus-cling-for-libtorch-and-opencv-libraries/">
                    <span class="button__text">Setting up Jupyter Notebook (Xeus Cling) for Libtorch and OpenCV Libraries</span>
                    <span class="button__icon">→</span>
                </a>
            </span>
            
        </div>
    </div>


    

    

    

  </main>

            </div>

            
                <footer class="footer">
    
    
</footer>

            
        </div>

        



<script type="text/javascript" src="https://krshrimali.github.io/bundle.min.e89fda0f29b95d33f6f4224dd9e5cf69d84aff3818be2b0d73e731689cc374261b016d17d46f8381962fb4a1577ba3017b1f23509d894f6e66431f988c00889e.js" integrity="sha512-6J/aDym5XTP29CJN2eXPadhK/zgYvisNc&#43;cxaJzDdCYbAW0X1G&#43;DgZYvtKFXe6MBex8jUJ2JT25mQx&#43;YjACIng=="></script>




    </body>
</html>
