<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Deep Convolutional Generative Adversarial Networks: Review and Implementation using PyTorch C&#43;&#43; API | Kushashwa Ravi Shrimali (Kush)</title>
<meta name="keywords" content="development, coding, cpp, notes, pytorch-cpp, libtorch">
<meta name="description" content="I&rsquo;m pleased to start a series of blogs on GANs and their implementation with PyTorch C&#43;&#43; API. We&rsquo;ll be starting with one of the initial GANs - DCGANs (Deep Convolutional Generative Adversarial Networks).

The authors (Soumith Chintala, Radford and Luke Metz) in this Seminal Paper on DCGANs introduced DCGANs to the world like this:

We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.">
<meta name="author" content="Kushashwa Ravi Shrimali">
<link rel="canonical" href="https://krshrimali.github.io/posts/2019/09/deep-convolutional-generative-adversarial-networks-review-and-implementation-using-pytorch-c-api/">
<link crossorigin="anonymous" href="https://krshrimali.github.io/assets/css/stylesheet.2211ca3164be7830024f6aad2b3a2e520843a64f8f048445c3401c1249aa051d.css" integrity="sha256-IhHKMWS&#43;eDACT2qtKzouUghDpk&#43;PBIRFw0AcEkmqBR0=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://krshrimali.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://krshrimali.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://krshrimali.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://krshrimali.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://krshrimali.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="https://krshrimali.github.io/posts/2019/09/deep-convolutional-generative-adversarial-networks-review-and-implementation-using-pytorch-c-api/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><link rel="stylesheet" href="https://krshrimali.github.io/css/custom.css"><meta property="og:url" content="https://krshrimali.github.io/posts/2019/09/deep-convolutional-generative-adversarial-networks-review-and-implementation-using-pytorch-c-api/">
  <meta property="og:site_name" content="Kushashwa Ravi Shrimali (Kush)">
  <meta property="og:title" content="Deep Convolutional Generative Adversarial Networks: Review and Implementation using PyTorch C&#43;&#43; API">
  <meta property="og:description" content="I’m pleased to start a series of blogs on GANs and their implementation with PyTorch C&#43;&#43; API. We’ll be starting with one of the initial GANs - DCGANs (Deep Convolutional Generative Adversarial Networks).
The authors (Soumith Chintala, Radford and Luke Metz) in this Seminal Paper on DCGANs introduced DCGANs to the world like this:
We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="article">
    <meta property="article:section" content="posts">
    <meta property="article:published_time" content="2019-09-15T00:00:00+00:00">
    <meta property="article:modified_time" content="2019-09-15T00:00:00+00:00">
    <meta property="article:tag" content="Development">
    <meta property="article:tag" content="Coding">
    <meta property="article:tag" content="Cpp">
    <meta property="article:tag" content="Notes">
    <meta property="article:tag" content="Pytorch-Cpp">
    <meta property="article:tag" content="Libtorch">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Deep Convolutional Generative Adversarial Networks: Review and Implementation using PyTorch C&#43;&#43; API">
<meta name="twitter:description" content="I&rsquo;m pleased to start a series of blogs on GANs and their implementation with PyTorch C&#43;&#43; API. We&rsquo;ll be starting with one of the initial GANs - DCGANs (Deep Convolutional Generative Adversarial Networks).

The authors (Soumith Chintala, Radford and Luke Metz) in this Seminal Paper on DCGANs introduced DCGANs to the world like this:

We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.">

</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://krshrimali.github.io/" accesskey="h" title="Kushashwa Ravi Shrimali (Kush) (Alt + H)">Kushashwa Ravi Shrimali (Kush)</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://krshrimali.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://krshrimali.github.io/about" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://krshrimali.github.io/posts" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://krshrimali.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://krshrimali.github.io/posts/">Posts</a></div>
    <h1 class="post-title entry-hint-parent">
      Deep Convolutional Generative Adversarial Networks: Review and Implementation using PyTorch C&#43;&#43; API
    </h1>
    <div class="post-meta"><span title='2019-09-15 00:00:00 +0000 UTC'>September 15, 2019</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;Kushashwa Ravi Shrimali

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#introduction-to-dcgan" aria-label="Introduction to DCGAN">Introduction to DCGAN</a></li>
                <li>
                    <a href="#acknowledgement-and-references" aria-label="Acknowledgement and References">Acknowledgement and References</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><p>I&rsquo;m pleased to start a series of blogs on GANs and their implementation with PyTorch C++ API. We&rsquo;ll be starting with one of the initial GANs - DCGANs (Deep Convolutional Generative Adversarial Networks).</p>
<p><img loading="lazy" src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Cover-DCGAN.jpg"></p>
<p>The authors (Soumith Chintala, Radford and Luke Metz) in <a href="https://arxiv.org/pdf/1511.06434.pdf">this</a> Seminal Paper on DCGANs introduced DCGANs to the world like this:</p>
<blockquote>
<p>We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.</p></blockquote>
<p>Even though, the introduction to DCGANs is quite lucid, but here are some points to note:</p>
<ol>
<li>DCGANs are a class of Convolutional Neural Networks.</li>
<li>They are a strong candidate for Unsupervised Learning.</li>
<li>They are applicable as general image representations as well.</li>
</ol>
<p>Let&rsquo;s go ahead and see what exactly is DCGAN?</p>
<h2 id="introduction-to-dcgan">Introduction to DCGAN<a hidden class="anchor" aria-hidden="true" href="#introduction-to-dcgan">#</a></h2>
<p>At the time when this paper was released, there was quite a focus on Supervised Learning. The paper aimed at bridging the gap between Unsupervised Learning and Supervised Learning. DCGANs are a way to understand and extract important feature representations from a dataset and generate good image representations by training.</p>
<p>Any Generative Adversarial Network has 2 major components: a Generator and a Discriminator. The tasks for both of them are simple.</p>
<ol>
<li><strong>Generator</strong>: Generates Images similar to the data distribution such that Discriminator can not distinguish it with the original data.</li>
<li><strong>Discriminator</strong>: Discriminator has a task on accurately distinguishing between the image from the generator and from the data distribution. It basically has to recognize an image as fake or real, correctly.</li>
</ol>
<p>Both Generator and Discriminator tasks can be represented beautifully with the following equation:</p>
<img src="https://krshrimali.github.io/assets/GANs-Equation.png"/>
<p>The above equation, shows how the Generator and Discriminator plays min-max game.</p>
<ol>
<li>The <strong>Generator tries to minimize the loss function.</strong> It follows up with two cases:
<ol>
<li><strong>When the data is from the data distribution:</strong> Generator has a task of forcing the Discriminator to predict the data as fake.</li>
<li><strong>When data is from the Generator:</strong> Generator has a task of forcing the Discriminator to predict the data as real.</li>
</ol>
</li>
<li>The <strong>Discriminator tries to maximize the loss function.</strong> It follows up with two cases:
<ol>
<li><strong>When the data is from the data distribution:</strong> Discriminator tries to predict the data as real.</li>
<li><strong>When the data is from the Generator:</strong> Discriminator tries to predict the data as fake.</li>
</ol>
</li>
</ol>
<p>Fundamentally, the Generator is trying to fool the Discriminator and the Discriminator is trying not to get fooled with. Because of it&rsquo;s analogy, it&rsquo;s also called a police-thief game. (Police is the Discriminator and thief is the Generator).</p>
<p>We have good enough discussion on GANs, to kickstart discussion on DCGANs. Let&rsquo;s go ahead and see what changes they proposed on common CNNs:</p>
<p>Changes in the <strong>Generator</strong>:</p>
<ol>
<li>Spatial Pooling Layers such as MaxPool Layers were replaced with Fractional-Strided Convolutions (a.k.a Transposed Convolutions). This allows the network to learn it&rsquo;s own spatial downsampling, instead of explicitly mentioning the downsampling parameters by Max Pooling.</li>
<li>Use BatchNorm in the Generator.</li>
<li>Remove Fully Connected layers for deeper architectures.</li>
<li>Use ReLU activation function for all the layers except the output layer (which uses Tanh activation function).</li>
</ol>
<p>Changes in the <strong>Discriminator</strong>:</p>
<ol>
<li>Spatial Pooling Layers such as MaxPool layers were replaced with Strided Convolutions.</li>
<li>Use BatchNorm in the Discriminator.</li>
<li>Remove FC layers for deeper architectures.</li>
<li>Use LeakyReLU activation function for all the layers in the Discriminator.</li>
</ol>
<p><img src="https://krshrimali.github.io/assets/DCGAN-Generator.png"/><center>Generator of the DCGAN used for LSUN scene modeling. Source: <a href="https://arxiv.org/pdf/1511.06434.pdf">https://arxiv.org/pdf/1511.06434.pdf</a></center></p>
<p>As you would note in the above architecture, there is absence of spatial pooling layers and fully connected layers.</p>
<p><img src="https://krshrimali.github.io/assets/DCGAN-Discriminator.png"/><center>Discriminator of the DCGAN used for LSUN scene modeling. Source: <a href="https://github.com/ChengBinJin/DCGAN-TensorFlow">https://github.com/ChengBinJin/DCGAN-TensorFlow</a></center></p>
<p>Notably again, there are no pooling and fully connected layers (except the last layer).</p>
<p>Let&rsquo;s start with defining the architectures of both Generators and Discriminators using PyTorch C++ API. I used the Object Oriented approach by making class, each for Generator and Discriminator. Note that each of them are a type of CNNs, and also inherit functions (or methods) from <code>torch::nn::Module</code> class.</p>
<p>As mentioned before, Generator uses Transposed Convolutional Layers and has no pooling and FC layers. It also uses ReLU Activation Function (except the last layer). The parameters used for the Generator include:</p>
<ol>
<li><code>dataroot</code>: (type: <code>std::string</code>) Path of the dataset&rsquo;s root directory.</li>
<li><code>workers</code>: (type: <code>int</code>) Having more <code>workers</code> will increase CPU memory usage. (Check this link <a href="https://discuss.pytorch.org/t/guidelines-for-assigning-num-workers-to-dataloader/813/2">for more details</a>)</li>
<li><code>batch_size</code>: (type: <code>int</code>) Batch Size to consider.</li>
<li><code>image_size</code>: (type: <code>int</code>) Size of the image to resize it to.</li>
<li><code>nc</code>: (type: <code>int</code>) Number of channels in the Input Image.</li>
<li><code>nz</code>: (type: <code>int</code>) Length of latent vector, from which the input image is taken.</li>
<li><code>ngf</code>: (type <code>int</code>) Depth of feature maps carried through the generator.</li>
<li><code>num_epochs</code>: (type <code>int</code>) Number of epochs for which the model is trained.</li>
<li><code>lr</code>: (type <code>float</code>) Learning Rate for training. Authors described it to be 0.0002</li>
<li><code>beta1</code>: (type: <code>float</code>) Hyperparameter for Optimizer used (Adam).</li>
<li><code>ngpu</code>: (type: <code>int</code>) Number of GPUs available to use. (use <code>0</code> if no GPU available)</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Generator</span> <span style="color:#f92672">:</span> <span style="color:#66d9ef">public</span> torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Module {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">private</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>string dataroot;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> workers;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> batch_size;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> image_size;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> nc;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> nz;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> ngf;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> num_epochs;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> lr;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> beta1;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> ngpu;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential main;
</span></span><span style="display:flex;"><span>    Generator(std<span style="color:#f92672">::</span>string dataroot_ <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;data/celeba&#34;</span>, <span style="color:#66d9ef">int</span> workers_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>, <span style="color:#66d9ef">int</span> batch_size_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">128</span>, <span style="color:#66d9ef">int</span> image_size_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">64</span>, <span style="color:#66d9ef">int</span> nc_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>, <span style="color:#66d9ef">int</span> nz_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>, <span style="color:#66d9ef">int</span> ngf_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">64</span>, <span style="color:#66d9ef">int</span> ndf_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">64</span>, <span style="color:#66d9ef">int</span> num_epochs_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span>, <span style="color:#66d9ef">float</span> lr_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0002</span>, <span style="color:#66d9ef">float</span> beta1_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.5</span>, <span style="color:#66d9ef">int</span> ngpu_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>) {
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Set the arguments
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        dataroot <span style="color:#f92672">=</span> dataroot_;
</span></span><span style="display:flex;"><span>        workers <span style="color:#f92672">=</span> workers_;
</span></span><span style="display:flex;"><span>        batch_size <span style="color:#f92672">=</span> batch_size_;
</span></span><span style="display:flex;"><span>        image_size <span style="color:#f92672">=</span> image_size_;
</span></span><span style="display:flex;"><span>        nc <span style="color:#f92672">=</span> nc_;
</span></span><span style="display:flex;"><span>        nz <span style="color:#f92672">=</span> nz_;
</span></span><span style="display:flex;"><span>        ngf <span style="color:#f92672">=</span> ngf_;
</span></span><span style="display:flex;"><span>        ndf <span style="color:#f92672">=</span> ndf_;
</span></span><span style="display:flex;"><span>        num_epochs <span style="color:#f92672">=</span> num_epochs_;
</span></span><span style="display:flex;"><span>        lr <span style="color:#f92672">=</span> lr_;
</span></span><span style="display:flex;"><span>        beta1 <span style="color:#f92672">=</span> beta1_;
</span></span><span style="display:flex;"><span>        ngpu <span style="color:#f92672">=</span> ngpu_;
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        main <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential(
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(nz, ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">1</span>).padding(<span style="color:#ae81ff">0</span>).with_bias(false).transposed(true)),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>BatchNorm(ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">8</span>),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>relu),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">8</span>, ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false).transposed(true)),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>BatchNorm(ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>relu),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>, ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false).transposed(true)),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>BatchNorm(ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>relu),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">2</span>, ngf, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false).transposed(true)),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>BatchNorm(ngf),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>relu),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ngf, nc, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false).transposed(true)),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>tanh)
</span></span><span style="display:flex;"><span>        );
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential main_func() {
</span></span><span style="display:flex;"><span>    	<span style="color:#75715e">// Returns Sequential Model of the Generator
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#66d9ef">return</span> main;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p>Note how we used Transposed Convolution, by passing <code>.transposed(true)</code>.</p>
<p>Similarly, we define the class for Discriminator.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Discriminator</span> <span style="color:#f92672">:</span> <span style="color:#66d9ef">public</span> torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Module {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">private</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>string dataroot;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> workers;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> batch_size;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> image_size;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> nc;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> nz;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> ndf;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> num_epochs;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> lr;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> beta1;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> ngpu;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential main;
</span></span><span style="display:flex;"><span>    Discriminator(std<span style="color:#f92672">::</span>string dataroot_ <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;data/celeba&#34;</span>, <span style="color:#66d9ef">int</span> workers_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>, <span style="color:#66d9ef">int</span> batch_size_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">128</span>, <span style="color:#66d9ef">int</span> image_size_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">64</span>, <span style="color:#66d9ef">int</span> nc_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>, <span style="color:#66d9ef">int</span> nz_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>, <span style="color:#66d9ef">int</span> ngf_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">64</span>, <span style="color:#66d9ef">int</span> ndf_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">64</span>, <span style="color:#66d9ef">int</span> num_epochs_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span>, <span style="color:#66d9ef">float</span> lr_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0002</span>, <span style="color:#66d9ef">float</span> beta1_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.5</span>, <span style="color:#66d9ef">int</span> ngpu_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>) {
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        dataroot <span style="color:#f92672">=</span> dataroot_;
</span></span><span style="display:flex;"><span>        workers <span style="color:#f92672">=</span> workers_;
</span></span><span style="display:flex;"><span>        batch_size <span style="color:#f92672">=</span> batch_size_;
</span></span><span style="display:flex;"><span>        image_size <span style="color:#f92672">=</span> image_size_;
</span></span><span style="display:flex;"><span>        nc <span style="color:#f92672">=</span> nc_;
</span></span><span style="display:flex;"><span>        nz <span style="color:#f92672">=</span> nz_;
</span></span><span style="display:flex;"><span>        ngf <span style="color:#f92672">=</span> ngf_;
</span></span><span style="display:flex;"><span>        ndf <span style="color:#f92672">=</span> ndf_;
</span></span><span style="display:flex;"><span>        num_epochs <span style="color:#f92672">=</span> num_epochs_;
</span></span><span style="display:flex;"><span>        lr <span style="color:#f92672">=</span> lr_;
</span></span><span style="display:flex;"><span>        beta1 <span style="color:#f92672">=</span> beta1_;
</span></span><span style="display:flex;"><span>        ngpu <span style="color:#f92672">=</span> ngpu_;
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        main <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential(
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(nc, ndf, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false)),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>leaky_relu, <span style="color:#ae81ff">0.2</span>),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ndf, ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false)),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>BatchNorm(ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>leaky_relu, <span style="color:#ae81ff">0.2</span>),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">2</span>, ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false)),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>BatchNorm(ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>leaky_relu, <span style="color:#ae81ff">0.2</span>),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>, ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false)),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>BatchNorm(ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">8</span>),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>leaky_relu, <span style="color:#ae81ff">0.2</span>),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">1</span>).padding(<span style="color:#ae81ff">0</span>).with_bias(false)),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>sigmoid)
</span></span><span style="display:flex;"><span>        );
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential main_func() {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> main;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p>We can initialize these networks as shown below:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Uses default arguments if no args passed
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>Generator gen <span style="color:#f92672">=</span> Generator()
</span></span><span style="display:flex;"><span>Discriminator dis <span style="color:#f92672">=</span> Discriminator()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential gen_model <span style="color:#f92672">=</span> gen.main_func()
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential dis_model <span style="color:#f92672">=</span> dis.main_func()
</span></span></code></pre></div><p>In case you are using a GPU, you can convert the models:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>Device device <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>kCPU;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span>(torch<span style="color:#f92672">::</span>cuda<span style="color:#f92672">::</span>is_available()) {
</span></span><span style="display:flex;"><span>    device <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>kCUDA;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>gen_model<span style="color:#f92672">-&gt;</span>to(device);
</span></span><span style="display:flex;"><span>dis_model<span style="color:#f92672">-&gt;</span>to(device);
</span></span></code></pre></div><p><strong>Note on Data Loading</strong>: In the past blogs, I&rsquo;ve discussed on loading custom data. Please refer to the previous blogs for a quick review on loading data.</p>
<p>Let&rsquo;s go ahead and define optimizers and train our model. We use the parameters defined by the authors, for optimizer (Adam, <code>beta</code> = 0.5) and learning rate of <code>2e-4</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>Adam gen_optimizer(gen_model<span style="color:#f92672">-&gt;</span>parameters(), torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>AdamOptions(<span style="color:#ae81ff">2e-4</span>).beta1(<span style="color:#ae81ff">0.5</span>));
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>Adam dis_optimizer(dis_model<span style="color:#f92672">-&gt;</span>parameters(), torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>AdamOptions(<span style="color:#ae81ff">2e-4</span>).beta1(<span style="color:#ae81ff">0.5</span>));
</span></span></code></pre></div><p>Time to write our training code. We are using <code>CelebA</code> dataset which looks like this:</p>
<img src="https://krshrimali.github.io/assets/celebA-sample.png"/>
<center>Source: http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html</center>
<p>The dataset is huge, and contains 10,177 number of identities and around ~200k number of face images. It also contains annotations, but since GANs are a way of unsupervised learning, so they don&rsquo;t actually consider annotations. Before we move on, we&rsquo;ll see a quick step by step review on training the Discriminator and Generator simultaneously:</p>
<ol>
<li><strong>Step-1: Train Discriminator</strong>. Remember from above, the discriminator tries to maximize the loss function such that it predicts the fake images as fake and real images as real.
<ol>
<li>As the first step for every training process, we set the gradients to zero. This helps in calculating correct gradients, and not getting confused with gradients stored in the previous iteration.</li>
<li>First calculate <strong>discriminator loss on real images</strong> (that is, data from our dataset). We do this by getting data from the batch and labels as anything between 0.8 and 1.0 (since it&rsquo;s real, we approximate it from 0.8 to 1.0).</li>
<li>Do a forward pass to the discriminator network, and calculate output on the batch of data from our dataset.</li>
<li>Calculate loss by using <code>torch::binary_cross_entropy</code> and backpropagate the loss.</li>
<li>We now calculate <strong>discriminator loss on fake images</strong> (that is, data from the generator). For this, we take a noise of shape similar to the batch of data, and pass that noise to the generator.</li>
<li>The labels are given zero values (as the images are fake).</li>
<li>Again, calculate the loss by using <code>torch::binary_cross_entropy</code> and backpropagate the loss.</li>
<li>Sum both the losses, <strong>discriminator loss on real images</strong> + <strong>discriminator loss on fake images</strong>. This will be our discriminator loss.</li>
<li>We then update our parameters using the optimizer.</li>
</ol>
</li>
<li><strong>Step-2: Train Generator</strong>. The task of a Generator is to minimize the loss function. Since it has to produce images which can fool the discriminator, so it only has to consider fake images.
<ol>
<li>As the first step for every training process, we set the gradients to zero. This helps in calculating correct gradients, and not getting confused with gradients stored in the previous iteration.</li>
<li>We use the fake images produced in the Step-1 and pass it to the discriminator.</li>
<li>Fill the labels with 1. (since generator wants to fool the discriminator, by making it predict as real images).</li>
<li>Calculate loss, by using <code>torch::binary_cross_entropy</code> and backpropagate the loss.</li>
<li>Update the parameters using optimizer of the Generator.</li>
</ol>
</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">int</span> epoch<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; epoch<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">10</span>; epoch<span style="color:#f92672">++</span>) {
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Store batch count in a variable
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">int</span> batch_count <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// You can use torch::data::Example&lt;&gt;&amp; batch: *data_loader
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">auto</span><span style="color:#f92672">&amp;</span> batch: <span style="color:#f92672">*</span>data_loader) {
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Step-1: Train the Discriminator
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#75715e">// Set gradients to zero
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        netD<span style="color:#f92672">-&gt;</span>zero_grad();
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Calculating discriminator loss on real images
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor images_real <span style="color:#f92672">=</span> batch.data.to(device);
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">::</span>Tensor labels_real <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>empty(batch.data.size(<span style="color:#ae81ff">0</span>), device).uniform_(<span style="color:#ae81ff">0.8</span>, <span style="color:#ae81ff">1.0</span>));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Do a forward pass to the Discriminator network
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor output_D_real <span style="color:#f92672">=</span> netD<span style="color:#f92672">-&gt;</span>forward(images_real);
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Calculate the loss
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor loss_real_D <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>binary_cross_entropy(output_D_real, labels_real);
</span></span><span style="display:flex;"><span>        loss_real_D.backward();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Calculate discriminator loss on fake images
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#75715e">// Generate noise and do forward pass to generate fake images
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch:Tensor fake_random <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>randn({batch.data.size(<span style="color:#ae81ff">0</span>), args.nz, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>}, device);
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">::</span>Tensor images_fake <span style="color:#f92672">=</span> netG<span style="color:#f92672">-&gt;</span>forward(images_fake);
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">::</span>Tensor labels_fake <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>zeros(batch.data.size(<span style="color:#ae81ff">0</span>), device);
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Do a forward pass to the Discriminator network
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor output_D_fake <span style="color:#f92672">=</span> netD<span style="color:#f92672">-&gt;</span>forward(images_fake);
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Calculate the loss
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor loss_fake_D <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>binary_cross_entropy(output_D_fake, labels_fake);
</span></span><span style="display:flex;"><span>        loss_fake_D.backward();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Total discriminator loss
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor loss_discriminator <span style="color:#f92672">=</span> loss_real_D <span style="color:#f92672">+</span> loss_fake_D;
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Update the parameters
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        dis_optimizer.step();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Step-2: Train the Generator
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#75715e">// Set gradients to zero
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        netG<span style="color:#f92672">-&gt;</span>zero_grad();
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// calculating generator loss on fake images
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#75715e">// Change labels_fake from all zeros to all ones
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        labels_fake.fill_(<span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Do forward pass to the Discriminator on the fake images generated above
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor output_G_fake <span style="color:#f92672">=</span> netD<span style="color:#f92672">-&gt;</span>forward(images_fake);
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Calculate loss
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor loss_generator <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>binary_cross_entropy(output_G_fake, labels_fake);
</span></span><span style="display:flex;"><span>        loss_generator.backward();
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Update the parameters
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        gen_optimizer.step();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Epoch: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> epoch <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;, Batch: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> batch_count <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;, Gen Loss: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> loss_generator.item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>() <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;, Discriminator Loss: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> loss_discriminator.item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>() <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>	
</span></span><span style="display:flex;"><span>        batch_count<span style="color:#f92672">++</span>;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>We are all set to train our first DCGAN in C++ using Libtorch. How amazing it is?</p>
<p>In the coming blog, I&rsquo;ll share the results and answer a few common questions on the architecture of DCGAN.</p>
<h2 id="acknowledgement-and-references">Acknowledgement and References<a hidden class="anchor" aria-hidden="true" href="#acknowledgement-and-references">#</a></h2>
<p>I would like to thank <a href="https://github.com/yf225">Will Feng</a> and <a href="https://discuss.pytorch.org/u/ptrblck/summary">Piotr</a> for their useful suggestions. The code used in this blog, is partially analogous to the official <a href="https://github.com/pytorch/examples/tree/master/cpp/dcgan">PyTorch examples repo on DCGAN using LibTorch</a>. I&rsquo;ve also referred the original paper by <a href="https://twitter.com/soumithchintala">Soumith Chintala</a> and others. The sources of reference images (for Network architectures) have been acknowledged in the captions of respective images.</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://krshrimali.github.io/tags/development/">Development</a></li>
      <li><a href="https://krshrimali.github.io/tags/coding/">Coding</a></li>
      <li><a href="https://krshrimali.github.io/tags/cpp/">Cpp</a></li>
      <li><a href="https://krshrimali.github.io/tags/notes/">Notes</a></li>
      <li><a href="https://krshrimali.github.io/tags/pytorch-cpp/">Pytorch-Cpp</a></li>
      <li><a href="https://krshrimali.github.io/tags/libtorch/">Libtorch</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://krshrimali.github.io/posts/2020/02/training-and-results-deep-convolutional-generative-adversarial-networks-on-celeba-dataset-using-pytorch-c-api/">
    <span class="title">« Prev</span>
    <br>
    <span>[Training and Results] Deep Convolutional Generative Adversarial Networks on CelebA Dataset using PyTorch C&#43;&#43; API</span>
  </a>
  <a class="next" href="https://krshrimali.github.io/posts/2019/08/setting-up-jupyter-notebook-xeus-cling-for-libtorch-and-opencv-libraries/">
    <span class="title">Next »</span>
    <br>
    <span>Setting up Jupyter Notebook (Xeus Cling) for Libtorch and OpenCV Libraries</span>
  </a>
</nav>


<ul class="share-buttons">
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Deep Convolutional Generative Adversarial Networks: Review and Implementation using PyTorch C&#43;&#43; API on x"
            href="https://x.com/intent/tweet/?text=Deep%20Convolutional%20Generative%20Adversarial%20Networks%3a%20Review%20and%20Implementation%20using%20PyTorch%20C%2b%2b%20API&amp;url=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f09%2fdeep-convolutional-generative-adversarial-networks-review-and-implementation-using-pytorch-c-api%2f&amp;hashtags=development%2ccoding%2ccpp%2cnotes%2cpytorch-cpp%2clibtorch">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M512 62.554 L 512 449.446 C 512 483.97 483.97 512 449.446 512 L 62.554 512 C 28.03 512 0 483.97 0 449.446 L 0 62.554 C 0 28.03 28.029 0 62.554 0 L 449.446 0 C 483.971 0 512 28.03 512 62.554 Z M 269.951 190.75 L 182.567 75.216 L 56 75.216 L 207.216 272.95 L 63.9 436.783 L 125.266 436.783 L 235.9 310.383 L 332.567 436.783 L 456 436.783 L 298.367 228.367 L 432.367 75.216 L 371.033 75.216 Z M 127.633 110 L 164.101 110 L 383.481 400.065 L 349.5 400.065 Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Deep Convolutional Generative Adversarial Networks: Review and Implementation using PyTorch C&#43;&#43; API on linkedin"
            href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f09%2fdeep-convolutional-generative-adversarial-networks-review-and-implementation-using-pytorch-c-api%2f&amp;title=Deep%20Convolutional%20Generative%20Adversarial%20Networks%3a%20Review%20and%20Implementation%20using%20PyTorch%20C%2b%2b%20API&amp;summary=Deep%20Convolutional%20Generative%20Adversarial%20Networks%3a%20Review%20and%20Implementation%20using%20PyTorch%20C%2b%2b%20API&amp;source=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f09%2fdeep-convolutional-generative-adversarial-networks-review-and-implementation-using-pytorch-c-api%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-288.985,423.278l0,-225.717l-75.04,0l0,225.717l75.04,0Zm270.539,0l0,-129.439c0,-69.333 -37.018,-101.586 -86.381,-101.586c-39.804,0 -57.634,21.891 -67.617,37.266l0,-31.958l-75.021,0c0.995,21.181 0,225.717 0,225.717l75.02,0l0,-126.056c0,-6.748 0.486,-13.492 2.474,-18.315c5.414,-13.475 17.767,-27.434 38.494,-27.434c27.135,0 38.007,20.707 38.007,51.037l0,120.768l75.024,0Zm-307.552,-334.556c-25.674,0 -42.448,16.879 -42.448,39.002c0,21.658 16.264,39.002 41.455,39.002l0.484,0c26.165,0 42.452,-17.344 42.452,-39.002c-0.485,-22.092 -16.241,-38.954 -41.943,-39.002Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Deep Convolutional Generative Adversarial Networks: Review and Implementation using PyTorch C&#43;&#43; API on reddit"
            href="https://reddit.com/submit?url=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f09%2fdeep-convolutional-generative-adversarial-networks-review-and-implementation-using-pytorch-c-api%2f&title=Deep%20Convolutional%20Generative%20Adversarial%20Networks%3a%20Review%20and%20Implementation%20using%20PyTorch%20C%2b%2b%20API">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-3.446,265.638c0,-22.964 -18.616,-41.58 -41.58,-41.58c-11.211,0 -21.361,4.457 -28.841,11.666c-28.424,-20.508 -67.586,-33.757 -111.204,-35.278l18.941,-89.121l61.884,13.157c0.756,15.734 13.642,28.29 29.56,28.29c16.407,0 29.706,-13.299 29.706,-29.701c0,-16.403 -13.299,-29.702 -29.706,-29.702c-11.666,0 -21.657,6.792 -26.515,16.578l-69.105,-14.69c-1.922,-0.418 -3.939,-0.042 -5.585,1.036c-1.658,1.073 -2.811,2.761 -3.224,4.686l-21.152,99.438c-44.258,1.228 -84.046,14.494 -112.837,35.232c-7.468,-7.164 -17.589,-11.591 -28.757,-11.591c-22.965,0 -41.585,18.616 -41.585,41.58c0,16.896 10.095,31.41 24.568,37.918c-0.639,4.135 -0.99,8.328 -0.99,12.576c0,63.977 74.469,115.836 166.33,115.836c91.861,0 166.334,-51.859 166.334,-115.836c0,-4.218 -0.347,-8.387 -0.977,-12.493c14.564,-6.47 24.735,-21.034 24.735,-38.001Zm-119.474,108.193c-20.27,20.241 -59.115,21.816 -70.534,21.816c-11.428,0 -50.277,-1.575 -70.522,-21.82c-3.007,-3.008 -3.007,-7.882 0,-10.889c3.003,-2.999 7.882,-3.003 10.885,0c12.777,12.781 40.11,17.317 59.637,17.317c19.522,0 46.86,-4.536 59.657,-17.321c3.016,-2.999 7.886,-2.995 10.885,0.008c3.008,3.011 3.003,7.882 -0.008,10.889Zm-5.23,-48.781c-16.373,0 -29.701,-13.324 -29.701,-29.698c0,-16.381 13.328,-29.714 29.701,-29.714c16.378,0 29.706,13.333 29.706,29.714c0,16.374 -13.328,29.698 -29.706,29.698Zm-160.386,-29.702c0,-16.381 13.328,-29.71 29.714,-29.71c16.369,0 29.689,13.329 29.689,29.71c0,16.373 -13.32,29.693 -29.689,29.693c-16.386,0 -29.714,-13.32 -29.714,-29.693Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Deep Convolutional Generative Adversarial Networks: Review and Implementation using PyTorch C&#43;&#43; API on facebook"
            href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f09%2fdeep-convolutional-generative-adversarial-networks-review-and-implementation-using-pytorch-c-api%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-106.468,0l0,-192.915l66.6,0l12.672,-82.621l-79.272,0l0,-53.617c0,-22.603 11.073,-44.636 46.58,-44.636l36.042,0l0,-70.34c0,0 -32.71,-5.582 -63.982,-5.582c-65.288,0 -107.96,39.569 -107.96,111.204l0,62.971l-72.573,0l0,82.621l72.573,0l0,192.915l-191.104,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Deep Convolutional Generative Adversarial Networks: Review and Implementation using PyTorch C&#43;&#43; API on whatsapp"
            href="https://api.whatsapp.com/send?text=Deep%20Convolutional%20Generative%20Adversarial%20Networks%3a%20Review%20and%20Implementation%20using%20PyTorch%20C%2b%2b%20API%20-%20https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f09%2fdeep-convolutional-generative-adversarial-networks-review-and-implementation-using-pytorch-c-api%2f">
            <svg version="1.1" viewBox="0 0 512 512" xml:space="preserve" height="30px" width="30px" fill="currentColor">
                <path
                    d="M449.446,0c34.525,0 62.554,28.03 62.554,62.554l0,386.892c0,34.524 -28.03,62.554 -62.554,62.554l-386.892,0c-34.524,0 -62.554,-28.03 -62.554,-62.554l0,-386.892c0,-34.524 28.029,-62.554 62.554,-62.554l386.892,0Zm-58.673,127.703c-33.842,-33.881 -78.847,-52.548 -126.798,-52.568c-98.799,0 -179.21,80.405 -179.249,179.234c-0.013,31.593 8.241,62.428 23.927,89.612l-25.429,92.884l95.021,-24.925c26.181,14.28 55.659,21.807 85.658,21.816l0.074,0c98.789,0 179.206,-80.413 179.247,-179.243c0.018,-47.895 -18.61,-92.93 -52.451,-126.81Zm-126.797,275.782l-0.06,0c-26.734,-0.01 -52.954,-7.193 -75.828,-20.767l-5.441,-3.229l-56.386,14.792l15.05,-54.977l-3.542,-5.637c-14.913,-23.72 -22.791,-51.136 -22.779,-79.287c0.033,-82.142 66.867,-148.971 149.046,-148.971c39.793,0.014 77.199,15.531 105.329,43.692c28.128,28.16 43.609,65.592 43.594,105.4c-0.034,82.149 -66.866,148.983 -148.983,148.984Zm81.721,-111.581c-4.479,-2.242 -26.499,-13.075 -30.604,-14.571c-4.105,-1.495 -7.091,-2.241 -10.077,2.241c-2.986,4.483 -11.569,14.572 -14.182,17.562c-2.612,2.988 -5.225,3.364 -9.703,1.12c-4.479,-2.241 -18.91,-6.97 -36.017,-22.23c-13.314,-11.876 -22.304,-26.542 -24.916,-31.026c-2.612,-4.484 -0.279,-6.908 1.963,-9.14c2.016,-2.007 4.48,-5.232 6.719,-7.847c2.24,-2.615 2.986,-4.484 4.479,-7.472c1.493,-2.99 0.747,-5.604 -0.374,-7.846c-1.119,-2.241 -10.077,-24.288 -13.809,-33.256c-3.635,-8.733 -7.327,-7.55 -10.077,-7.688c-2.609,-0.13 -5.598,-0.158 -8.583,-0.158c-2.986,0 -7.839,1.121 -11.944,5.604c-4.105,4.484 -15.675,15.32 -15.675,37.364c0,22.046 16.048,43.342 18.287,46.332c2.24,2.99 31.582,48.227 76.511,67.627c10.685,4.615 19.028,7.371 25.533,9.434c10.728,3.41 20.492,2.929 28.209,1.775c8.605,-1.285 26.499,-10.833 30.231,-21.295c3.732,-10.464 3.732,-19.431 2.612,-21.298c-1.119,-1.869 -4.105,-2.99 -8.583,-5.232Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Deep Convolutional Generative Adversarial Networks: Review and Implementation using PyTorch C&#43;&#43; API on telegram"
            href="https://telegram.me/share/url?text=Deep%20Convolutional%20Generative%20Adversarial%20Networks%3a%20Review%20and%20Implementation%20using%20PyTorch%20C%2b%2b%20API&amp;url=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f09%2fdeep-convolutional-generative-adversarial-networks-review-and-implementation-using-pytorch-c-api%2f">
            <svg version="1.1" xml:space="preserve" viewBox="2 2 28 28" height="30px" width="30px" fill="currentColor">
                <path
                    d="M26.49,29.86H5.5a3.37,3.37,0,0,1-2.47-1,3.35,3.35,0,0,1-1-2.47V5.48A3.36,3.36,0,0,1,3,3,3.37,3.37,0,0,1,5.5,2h21A3.38,3.38,0,0,1,29,3a3.36,3.36,0,0,1,1,2.46V26.37a3.35,3.35,0,0,1-1,2.47A3.38,3.38,0,0,1,26.49,29.86Zm-5.38-6.71a.79.79,0,0,0,.85-.66L24.73,9.24a.55.55,0,0,0-.18-.46.62.62,0,0,0-.41-.17q-.08,0-16.53,6.11a.59.59,0,0,0-.41.59.57.57,0,0,0,.43.52l4,1.24,1.61,4.83a.62.62,0,0,0,.63.43.56.56,0,0,0,.4-.17L16.54,20l4.09,3A.9.9,0,0,0,21.11,23.15ZM13.8,20.71l-1.21-4q8.72-5.55,8.78-5.55c.15,0,.23,0,.23.16a.18.18,0,0,1,0,.06s-2.51,2.3-7.52,6.8Z" />
            </svg>
        </a>
    </li>
    <li>
        <a target="_blank" rel="noopener noreferrer" aria-label="share Deep Convolutional Generative Adversarial Networks: Review and Implementation using PyTorch C&#43;&#43; API on ycombinator"
            href="https://news.ycombinator.com/submitlink?t=Deep%20Convolutional%20Generative%20Adversarial%20Networks%3a%20Review%20and%20Implementation%20using%20PyTorch%20C%2b%2b%20API&u=https%3a%2f%2fkrshrimali.github.io%2fposts%2f2019%2f09%2fdeep-convolutional-generative-adversarial-networks-review-and-implementation-using-pytorch-c-api%2f">
            <svg version="1.1" xml:space="preserve" width="30px" height="30px" viewBox="0 0 512 512" fill="currentColor"
                xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape">
                <path
                    d="M449.446 0C483.971 0 512 28.03 512 62.554L512 449.446C512 483.97 483.97 512 449.446 512L62.554 512C28.03 512 0 483.97 0 449.446L0 62.554C0 28.03 28.029 0 62.554 0L449.446 0ZM183.8767 87.9921H121.8427L230.6673 292.4508V424.0079H281.3328V292.4508L390.1575 87.9921H328.1233L256 238.2489z" />
            </svg>
        </a>
    </li>
</ul>

  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
<script>
    document.querySelectorAll('pre > code').forEach((codeblock) => {
        const container = codeblock.parentNode.parentNode;

        const copybutton = document.createElement('button');
        copybutton.classList.add('copy-code');
        copybutton.innerHTML = 'copy';

        function copyingDone() {
            copybutton.innerHTML = 'copied!';
            setTimeout(() => {
                copybutton.innerHTML = 'copy';
            }, 2000);
        }

        copybutton.addEventListener('click', (cb) => {
            if ('clipboard' in navigator) {
                navigator.clipboard.writeText(codeblock.textContent);
                copyingDone();
                return;
            }

            const range = document.createRange();
            range.selectNodeContents(codeblock);
            const selection = window.getSelection();
            selection.removeAllRanges();
            selection.addRange(range);
            try {
                document.execCommand('copy');
                copyingDone();
            } catch (e) { };
            selection.removeRange(range);
        });

        if (container.classList.contains("highlight")) {
            container.appendChild(copybutton);
        } else if (container.parentNode.firstChild == container) {
            
        } else if (codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName == "TABLE") {
            
            codeblock.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(copybutton);
        } else {
            
            codeblock.parentNode.appendChild(copybutton);
        }
    });
</script>
</body>

</html>
