<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="ie=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="author" content="map[name:Kushashwa Ravi Shrimali]">
<meta name="description" content="OpenCV: Using face detection for Portrait Bokeh (Background Blur) (Part - 1) This blog discusses using Face Detection in OpenCV for Portrait Bokeh. We&amp;rsquo;ll be implementing Portrait Bokeh (blurring everything but faces) using 3 different methods in this series:
Using Face Detection (cropping a rectangle) Using Face Detection (cropping a circle) Using Facial Landmark Detection and Convex Hull Don&amp;rsquo;t lose hopes if you are confused. We will be going through each method one by one, and hopefully the road will be crearer from here." />
<meta name="keywords" content=", computer vision, python, portrait bokeh, image processing" />
<meta name="robots" content="noodp" />
<meta name="theme-color" content="#252627" />
<link rel="canonical" href="https://krshrimali.github.io/posts/2020/12/implementing-portrait-bokeh-in-opencv-using-face-detection-part-1/" />


    <title>
        
            Implementing Portrait Bokeh in OpenCV using Face Detection (Part-1) :: Kushashwa Ravi Shrimali (Kush)  — Learning never stops!
        
    </title>





<link rel="stylesheet" href="https://krshrimali.github.io/main.949191c1dcc9c4a887997048b240354e47152016d821198f89448496ba42e491.css" integrity="sha256-lJGRwdzJxKiHmXBIskA1TkcVIBbYIRmPiUSElrpC5JE=">



    <link rel="apple-touch-icon" sizes="180x180" href="https://krshrimali.github.io/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="https://krshrimali.github.io/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="https://krshrimali.github.io/favicon-16x16.png">
    <link rel="manifest" href="https://krshrimali.github.io/site.webmanifest">
    <link rel="mask-icon" href="https://krshrimali.github.io/safari-pinned-tab.svg" color="">
    <link rel="shortcut icon" href="https://krshrimali.github.io/favicon.ico">
    <meta name="msapplication-TileColor" content="">


<meta itemprop="name" content="Implementing Portrait Bokeh in OpenCV using Face Detection (Part-1)">
<meta itemprop="description" content="OpenCV: Using face detection for Portrait Bokeh (Background Blur) (Part - 1) This blog discusses using Face Detection in OpenCV for Portrait Bokeh. We&rsquo;ll be implementing Portrait Bokeh (blurring everything but faces) using 3 different methods in this series:
Using Face Detection (cropping a rectangle) Using Face Detection (cropping a circle) Using Facial Landmark Detection and Convex Hull Don&rsquo;t lose hopes if you are confused. We will be going through each method one by one, and hopefully the road will be crearer from here."><meta itemprop="datePublished" content="2020-12-07T00:00:00+00:00" />
<meta itemprop="dateModified" content="2020-12-07T00:00:00+00:00" />
<meta itemprop="wordCount" content="882"><meta itemprop="image" content="https://krshrimali.github.io" />
<meta itemprop="keywords" content="computer vision,python,portrait bokeh,image processing," />
<meta name="twitter:card" content="summary_large_image" />
<meta name="twitter:image" content="https://krshrimali.github.io" /><meta name="twitter:title" content="Implementing Portrait Bokeh in OpenCV using Face Detection (Part-1)"/>
<meta name="twitter:description" content="OpenCV: Using face detection for Portrait Bokeh (Background Blur) (Part - 1) This blog discusses using Face Detection in OpenCV for Portrait Bokeh. We&rsquo;ll be implementing Portrait Bokeh (blurring everything but faces) using 3 different methods in this series:
Using Face Detection (cropping a rectangle) Using Face Detection (cropping a circle) Using Facial Landmark Detection and Convex Hull Don&rsquo;t lose hopes if you are confused. We will be going through each method one by one, and hopefully the road will be crearer from here."/>





    <meta property="article:section" content="opencv" />



    <meta property="article:published_time" content="2020-12-07 00:00:00 &#43;0000 UTC" />









    
<script>
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-146662543-1', 'auto');
	
	ga('send', 'pageview');
}
</script>


    </head>

    
        <body>
    
    
        <div class="container">
            <header class="header">
    <span class="header__inner">
        <a href="https://krshrimali.github.io/" style="text-decoration: none;">
    <div class="logo">
        
            <span class="logo__mark">></span>
            <span class="logo__text ">
                $ cd /home/</span>
            <span class="logo__cursor" style=
                  "
                   
                   ">
            </span>
        
    </div>
</a>


        <span class="header__right">
            
                <nav class="menu">
    <ul class="menu__inner"><li><a href="https://krshrimali.github.io/about">About</a></li><li><a href="https://krshrimali.github.io/posts">Blog</a></li>
    </ul>
</nav>

                <span class="menu-trigger">
                    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
                        <path d="M0 0h24v24H0z" fill="none"/>
                        <path d="M3 18h18v-2H3v2zm0-5h18v-2H3v2zm0-7v2h18V6H3z"/>
                    </svg>
                </span>
            
        </span>
    </span>
</header>


            <div class="content">
                
  <main class="post">

    <div class="post-info">
      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock">
          <circle cx="12" cy="12" r="10"></circle>
          <polyline points="12 6 12 12 16 14"></polyline>
        </svg>
        5 minutes

        
      </p>
    </div>

    <article>
      <h1 class="post-title">
        <a href="https://krshrimali.github.io/posts/2020/12/implementing-portrait-bokeh-in-opencv-using-face-detection-part-1/">Implementing Portrait Bokeh in OpenCV using Face Detection (Part-1)</a>
      </h1>

      

      
        <hr />
        <aside id="toc">
          <div class="toc-title">Table of Contents</div>
          <nav id="TableOfContents">
  <ul>
    <li><a href="#portrait-bokeh-discussing-problem-statement">Portrait Bokeh: Discussing Problem Statement</a></li>
    <li><a href="#methodology-opted">Methodology opted</a></li>
    <li><a href="#video-tutorial">Video Tutorial</a></li>
    <li><a href="#step-1-detecting-faces-using-haarcascade">Step 1: Detecting Faces using Haarcascade</a></li>
    <li><a href="#step-2-crop-faces">Step 2: Crop faces</a></li>
    <li><a href="#step-3-and-step-4-blur-the-image-and-overlay-faces">Step 3 and Step 4: Blur the image and overlay faces</a></li>
  </ul>
</nav>
        </aside>
        <hr />

      

      <div class="post-content">
        <p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Dec_7_2020.jpg" alt=""></p>
<h1 id="opencv-using-face-detection-for-portrait-bokeh-background-blur-part---1">OpenCV: Using face detection for Portrait Bokeh (Background Blur) (Part - 1)</h1>
<p>This blog discusses using Face Detection in OpenCV for Portrait Bokeh. We&rsquo;ll be implementing Portrait Bokeh (blurring everything but faces) using 3 different methods in this series:</p>
<ol>
<li>Using Face Detection (cropping a rectangle)</li>
<li>Using Face Detection (cropping a circle)</li>
<li>Using Facial Landmark Detection and Convex Hull</li>
</ol>
<p>Don&rsquo;t lose hopes if you are confused. We will be going through each method one by one, and hopefully the road will be crearer from here.</p>
<h2 id="portrait-bokeh-discussing-problem-statement">Portrait Bokeh: Discussing Problem Statement</h2>
<p>Before moving ahead, let&rsquo;s talk about &ldquo;What is Portrait Bokeh?&rdquo;. It&rsquo;s important to talk about the problem before discussing solutions. Take a quick look at the two images below:</p>
<p><!-- raw HTML omitted --> <!-- raw HTML omitted --></p>
<p>As you might have spotted the difference already, the image on the left is our input (/original) image while the image on the right is our output image. If you haven&rsquo;t spotted the difference, everything except the face in the image on the right is blurred! This feature now comes in almost all smart phones, and is also termed as just Portrait mode. Whenever you want to highlight the people near to the camera (mostly you, your friends or anyone) and blur the background, this is the mode you will usually choose. While some blur everything except faces, others might choose to keep the body instead of just faces. Our problem statement will be limited to faces here.</p>
<h2 id="methodology-opted">Methodology opted</h2>
<p>Let&rsquo;s discuss on how we can go ahead to solve this problem. We surely need to know where the face is to avoid blurring it, so the first step has to be of face detection. And since we need to blur the background, so at some stage, we need to do blurring as well. Since this part is about the simplest step, we can just combine them and say:</p>
<ol>
<li>Detect face(s) from the given input image.</li>
<li>Crop the faces and store them as separate objects.</li>
<li>Blur the whole image.</li>
<li>Overlay the cropped faces from step-2 on the output from step-3.</li>
</ol>
<h2 id="video-tutorial">Video Tutorial</h2>
<p>I started a YouTube channel where I go live on the weekends, and upload videos on the week days (not so regularly) about Computer Vision, deploying models into production and more. If you haven&rsquo;t seen it before, please check it out <a href="https://youtube.com/c/kushashwaraviShrimali">here</a>. For this blog, I have already uploaded a detailed tutorial. Check it out <a href="https://www.youtube.com/watch?v=Nd3wFiSH-gw">here</a>.</p>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/Nd3wFiSH-gw" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<h2 id="step-1-detecting-faces-using-haarcascade">Step 1: Detecting Faces using Haarcascade</h2>
<p>We&rsquo;ll be using haarcascade model files to detect face in the image. To ease the computation and satisfy the input to the model, we need to first convert the image to GrayScale (if it&rsquo;s not already) - that is the image will now have only one channel instead of 3 (Blue, Green, Red). Download the model file to your directory from <a href="https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml">here</a>. Let&rsquo;s go ahead and initialize our Face Detector.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>model_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;haarcascade_frontalface_default.xml&#34;</span> <span style="color:#75715e"># Assuming this is in our current directory</span>
</span></span><span style="display:flex;"><span>face_detector <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>CascadeClassifier(model_path)
</span></span></code></pre></div><p>Once we have the model loaded, let&rsquo;s go ahead and detect faces from the given image. Remember, that we will also convert the image to grayscale.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Read input image (get image path first from command line, else take sample.png - default)</span>
</span></span><span style="display:flex;"><span>img_path <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>argv[<span style="color:#ae81ff">1</span>] <span style="color:#66d9ef">if</span> len(sys<span style="color:#f92672">.</span>argv) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">1</span> <span style="color:#66d9ef">else</span> <span style="color:#e6db74">&#34;sample.png&#34;</span>
</span></span><span style="display:flex;"><span>img <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>imread(img_path, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Convert the image to grayscale</span>
</span></span><span style="display:flex;"><span>gray <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>cvtColor(img, cv2<span style="color:#f92672">.</span>COLOR_BGR2GRAY)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Get faces</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Use default arguments, scaleFactor can be tweaked depending on the image</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># The output will be in format: [ [&lt;top left x coord&gt;, &lt;top left y&gt;, &lt;width&gt;, &lt;height&gt; : for face 1], [ ... : for face 2], ... ]</span>
</span></span><span style="display:flex;"><span>faces <span style="color:#f92672">=</span> face_detector<span style="color:#f92672">.</span>detectMultiScale(gray, scaleFactor<span style="color:#f92672">=</span><span style="color:#ae81ff">1.1</span>, minNeighbors<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)
</span></span></code></pre></div><p>Once we have the faces, we can crop them and use in the Step-4 again. The output from face detection should look like this:</p>
<!-- raw HTML omitted -->
<h2 id="step-2-crop-faces">Step 2: Crop faces</h2>
<p>To crop them and store in another object:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>cropped_faces <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> face <span style="color:#f92672">in</span> faces:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Get points: tlx (top left x), tly (top left y), w (width), h (height)</span>
</span></span><span style="display:flex;"><span>    tlx, tly, w, h <span style="color:#f92672">=</span> face[<span style="color:#ae81ff">0</span>], face[<span style="color:#ae81ff">1</span>], face[<span style="color:#ae81ff">2</span>], face[<span style="color:#ae81ff">3</span>]
</span></span><span style="display:flex;"><span>    cropped_faces<span style="color:#f92672">.</span>append(
</span></span><span style="display:flex;"><span>        face[tly:tly<span style="color:#f92672">+</span>h, tlx:tlx<span style="color:#f92672">+</span>w]
</span></span><span style="display:flex;"><span>    )
</span></span></code></pre></div><p>The list <code>cropped_faces</code> will now contain only faces. We can use this list again in Step-4!</p>
<h2 id="step-3-and-step-4-blur-the-image-and-overlay-faces">Step 3 and Step 4: Blur the image and overlay faces</h2>
<p>Let&rsquo;s blur the whole image, and then overlay the images on the top of it. To blur, we will be using Gaussian Blur which works just fine.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>blur <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>GaussianBlur(img, (<span style="color:#ae81ff">11</span>, <span style="color:#ae81ff">11</span>)) <span style="color:#75715e"># Here, (11, 11) is the kernel size</span>
</span></span></code></pre></div><p>Once the whole image has been blurred, let&rsquo;s overlay the cropped faces from <code>Step 2</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> face_index, cropped_face <span style="color:#f92672">in</span> enumerate(cropped_faces):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Get face coordinates, to get ROI</span>
</span></span><span style="display:flex;"><span>    face_coords <span style="color:#f92672">=</span> faces[face_index]
</span></span><span style="display:flex;"><span>    tlx, tly, w, h <span style="color:#f92672">=</span> face_coords[<span style="color:#ae81ff">0</span>], face_coords[<span style="color:#ae81ff">1</span>], face_coords[<span style="color:#ae81ff">2</span>], face_coords[<span style="color:#ae81ff">3</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Overlay the ROI of face to the cropped face</span>
</span></span><span style="display:flex;"><span>    blur[tly:tly<span style="color:#f92672">+</span>h, tlx:tlx<span style="color:#f92672">+</span>w] <span style="color:#f92672">=</span> cropped_face
</span></span></code></pre></div><p>Following image explains the procedure in details with visualization.</p>
<!-- raw HTML omitted -->
<p>And this is how the output (on the right) will look like (see below).</p>
<!-- raw HTML omitted -->
<p>While I know many of you will be thinking that it&rsquo;s not accurate at all (since we can see the rectangle there), and that will be a topic for the next blog where we will attempt to crop a circle. Make sure to leave a comment if you have any suggestions, feedback or if this blog helped you in any way - I would love to hear that!</p>

      </div>
    </article>

    <hr />

    <div class="post-info">
      
    <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-tag meta-icon"><path d="M20.59 13.41l-7.17 7.17a2 2 0 0 1-2.83 0L2 12V2h10l8.59 8.59a2 2 0 0 1 0 2.82z"></path><line x1="7" y1="7" x2="7" y2="7"></line></svg>

        <span class="tag"><a href="https://krshrimali.github.io/tags/computer-vision/">computer vision</a></span>
        <span class="tag"><a href="https://krshrimali.github.io/tags/python/">python</a></span>
        <span class="tag"><a href="https://krshrimali.github.io/tags/portrait-bokeh/">portrait bokeh</a></span>
        <span class="tag"><a href="https://krshrimali.github.io/tags/image-processing/">image processing</a></span>
        
    </p>

      
    <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-folder meta-icon"><path d="M22 19a2 2 0 0 1-2 2H4a2 2 0 0 1-2-2V5a2 2 0 0 1 2-2h5l2 3h9a2 2 0 0 1 2 2z"></path></svg>

        <span class="tag"><a href="https://krshrimali.github.io/categories/opencv/">opencv</a></span>
        
    </p>


      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-file-text">
          <path d="M14 2H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h12a2 2 0 0 0 2-2V8z"></path>
          <polyline points="14 2 14 8 20 8"></polyline>
          <line x1="16" y1="13" x2="8" y2="13"></line>
          <line x1="16" y1="17" x2="8" y2="17"></line>
          <polyline points="10 9 9 9 8 9"></polyline>
        </svg>
        882 Words
      </p>

      <p>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-calendar">
          <rect x="3" y="4" width="18" height="18" rx="2" ry="2"></rect>
          <line x1="16" y1="2" x2="16" y2="6"></line>
          <line x1="8" y1="2" x2="8" y2="6"></line>
          <line x1="3" y1="10" x2="21" y2="10"></line>
        </svg>
        
          2020-12-07 05:30 &#43;0530
        

         
          
        
      </p>
    </div>

    
    <div class="pagination">
        

        <div class="pagination__buttons">
            
            <span class="button previous">
                <a href="https://krshrimali.github.io/posts/2020/12/how-to-crop-a-circle-in-opencv-implementing-portrait-bokeh-part-2/">
                    <span class="button__icon">←</span>
                    <span class="button__text">How to crop a circle in OpenCV? Implementing Portrait Bokeh - Part 2</span>
                </a>
            </span>
            

            
            <span class="button next">
                <a href="https://krshrimali.github.io/posts/2020/09/releasing-docker-container-and-binder-for-using-xeus-cling-libtorch-and-opencv-in-c-/">
                    <span class="button__text">Releasing Docker Container and Binder for using Xeus-Cling, Libtorch and OpenCV in C&#43;&#43;</span>
                    <span class="button__icon">→</span>
                </a>
            </span>
            
        </div>
    </div>


    

    

    

  </main>

            </div>

            
                <footer class="footer">
    
    
</footer>

            
        </div>

        



<script type="text/javascript" src="https://krshrimali.github.io/bundle.min.46e438bd2eca7eb6358c700b40f6f56b22ab0b92503ecc11a2d8e4bcc610b8b4da83e5ea3d3e84fdb5f3c3c765744b9f5bbaf43cf5a027910be07ee39a9c12a1.js" integrity="sha512-RuQ4vS7KfrY1jHALQPb1ayKrC5JQPswRotjkvMYQuLTag&#43;XqPT6E/bXzw8dldEufW7r0PPWgJ5EL4H7jmpwSoQ=="></script>




    </body>
</html>
