<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Posts on Kushashwa Ravi Shrimali (Kush)</title>
        <link>https://krshrimali.github.io/posts/</link>
        <description>Recent content in Posts on Kushashwa Ravi Shrimali (Kush)</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>en</language>
        <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
        <lastBuildDate>Mon, 26 Feb 2024 00:00:00 +0000</lastBuildDate>
        <atom:link href="https://krshrimali.github.io/posts/index.xml" rel="self" type="application/rss+xml" />
        
        <item>
            <title>Building a ChatBot from your Documentation Website | DocsGPT</title>
            <link>https://krshrimali.github.io/posts/2024/02/building-a-chatbot-from-your-documentation-website-docsgpt/</link>
            <pubDate>Mon, 26 Feb 2024 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2024/02/building-a-chatbot-from-your-documentation-website-docsgpt/</guid>
            <description>Hi everyone! Been a long time, thought I should talk about an ongoing project I&amp;rsquo;m working on.
Introduction - What are we trying to do here? Lemme start with some context and disclaimer first:
This was a part of an interview process in one of the amazing startups, and I wanted to extend it to an end-to-end project (kinda out of scope from the requirement of that interview process). I won&amp;rsquo;t be naming the startup here to help keep them anonymous and candid for their future candidates.</description>
            <content type="html"><![CDATA[<p>Hi everyone! Been a long time, thought I should talk about an ongoing project I&rsquo;m working on.</p>
<h2 id="introduction---what-are-we-trying-to-do-here">Introduction - What are we trying to do here?</h2>
<p>Lemme start with some context and disclaimer first:</p>
<blockquote>
<p>This was a part of an interview process in one of the amazing startups, and I wanted to extend it to an end-to-end project (kinda out of scope from the requirement of that interview process). I won&rsquo;t be naming the startup here to help keep them anonymous and candid for their future candidates.</p>
</blockquote>
<p>Alright, so here it begins. Imagine having a documentation website, and you would like to finetune a ChatBot Model to help answer your questions. That&rsquo;s it, that&rsquo;s the problem. Let&rsquo;s break it down on why this is an interesting problem to solve:</p>
<p><strong>For learning?</strong></p>
<ol>
<li>It involves a lot of data preprocessing and cleaning. You&rsquo;ll also have to automate the data scraping and cleaning process.
<ul>
<li>It&rsquo;s probably safe to assume that generally all documentations are hosted somewhere on GitHub or any other platform, but to make it more complex - let&rsquo;s not use that assumption.</li>
<li>We&rsquo;ll have to scrape the data from the website, and clean it to make it ready for the model to consume.</li>
<li>Automating this process and by just using a single documentation link is a good challenge to solve.</li>
<li>A ChatBot Model takes an input of prompt and answer (kind of an <em>instruction dataset</em> format) and we&rsquo;ll have to convert the documentation into this format. This is not as straight forward as it sounds, specially when you want to have minimal human intervention. More on this later.</li>
</ul>
</li>
<li>Finetuning an LLM Model:
<ul>
<li>Always good to learn how to finetune an LLM model, because training it from scratch is never going to be <em>feasible</em> for all of us (this includes the constraint on lack of resources, motivation and time, oh and also <em>need</em>).</li>
<li>The choice we make for which model to use is going to teach us a lot. Just in the exploring phase, we&rsquo;ll be going through multiple models that exist and will try setting up priorities on the &ldquo;What works for us&rdquo; question.</li>
</ul>
</li>
</ol>
<p><strong>For the product?</strong></p>
<p>Very honestly, I don&rsquo;t think there is a <em>huge</em> product goal here. It&rsquo;s more of a learning project than a product project. But, if I were to think of a product goal, it would be to have a ChatBot Model that can answer questions from the documentation website. This can be used for customer support, or for internal documentation search, or for any other use case where you think a ChatBot can be helpful. In addition to this, I do think that this can be extended to something that is not just a documentation but a lot of text on websites.</p>
<p><strong>For fun?</strong></p>
<p>That&rsquo;s why I&rsquo;m using Rust here. I know this question is going to come up quite a lot, so lemme answer this first.</p>
<p><strong>WHY RUST?</strong></p>
<ul>
<li>I honestly would love to see the performance of Rust in the data preprocessing and cleaning phase.</li>
<li>It would be nice to see where does the data engineering ecosystem stand w.r.t Rust. We&rsquo;ve all (probably?) used beautifulsoup in Python to scrap data from websites, and data cleaning/preprocessing libraries, but I&rsquo;m excited to see where does Rust stand in this.</li>
<li>I&rsquo;ve been using Rust for some time now, and am pretty comfortable in <em>exploring</em> the ecosystem with this project.</li>
<li>Writing a ChatBot interface would be fun in Rust.</li>
<li>Finetuning a model in Rust&hellip; hmm, I&rsquo;m honestly not sure what&rsquo;s the state of [https://github.com/LaurentMazare/tch-rs](Rust bindings for PyTorch C++ API) - so it&rsquo;s something I&rsquo;m very much looking forward to. I&rsquo;m honestly nervous about this part, but let&rsquo;s see.</li>
<li>Using a single language for the whole end to end flow would make it easier for me to automate everything including testing and workflows.</li>
</ul>
<p>As always, I just want to point out that language you use isn&rsquo;t the topmost criteria of any project IMO. First should be, whether it got delivered to the users and if they are happy with it. So, yes, please feel free to port it to some other language of your choice and try out the ecosystem for yourself to learn and grow your confidence :)</p>
<h2 id="plan">Plan</h2>
<blockquote>
<p>I&rsquo;ve been live streaming my work on this project on my YouTube channel here: <a href="https://youtube.com/c/kushashwaraviShrimali">https://youtube.com/c/kushashwaraviShrimali</a>. Please feel free to check it out if you&rsquo;re interested.</p>
</blockquote>
<ol>
<li>Pick up a sample documentation website that we can use for this project. I&rsquo;m picking up <a href="https://pytorch.org/docs/stable/index.html">PyTorch docs website</a>, it&rsquo;s well maintained, and the format is tricky enough to automate things for other websites in the future.</li>
<li>Input to this flow is going to be a simple documentation website link (of the index page).
a. We&rsquo;ll have to fetch all the hyperlinks that are &ldquo;internal&rdquo; to the documentation website, and then fetch the content of those hyperlinks.
b. We&rsquo;ll have to skip fetching content for &ldquo;external&rdquo; hyperlinks for now to avoid a lot of unrelated data (not really unrelated, but we can enable it easily if someone wants it).
c. Output of this step should be: we have all the data in the text format from HTML webpages.</li>
<li>Convert this data into the format of ChatBot model.</li>
<li>Finetune the model by passing that data into a model of our choice.</li>
<li>Create a ChatBot interface to deploy the model (more like an API end-point for now).</li>
<li>Deploy the model to the ChatBot interface, or update the API end-point.</li>
</ol>
<p>The very tricky part is, Step 3 here. Ideally, a ChatBot model takes input of the following format:</p>
<pre tabindex="0"><code>prompt: &#34;What is the function of `torch.nn.functional.relu`?&#34;
answer: &#34;Applies the rectified linear unit function element-wise.&#34;
context: &lt;optional&gt;
... // other properties
</code></pre><p>The names (of the keys) can differ, but if you look at the format, it&rsquo;s more like an instruction dataset. We&rsquo;ll have to convert the documentation into this format.</p>
<p><strong>Question</strong>: How would you convert a given &ldquo;text&rdquo; into the format above?</p>
<p>Let&rsquo;s just say, your task is to convert &ldquo;this&rdquo; blog that you&rsquo;re reading right now (thank you for being here btw ‚ù§Ô∏è) into a prompt-answer format (can leave <code>context</code> for now for simplicity).</p>
<p>I&rsquo;m going to come back with another blog to discuss my solution, but for now, leaving this blog at this to let y&rsquo;all ponder over this and come up with some interesting approaches.</p>
<h2 id="youtube">YouTube!</h2>
<p>Sorry for the shameless plug here, I mean not really shameless since it&rsquo;s still my blog haha, but&hellip; I don&rsquo;t want to miss out on telling you that I&rsquo;ve been live streaming my work on this project on my YouTube channel here: <a href="https://youtube.com/c/kushashwaraviShrimali">https://youtube.com/c/kushashwaraviShrimali</a>. By the time I&rsquo;m writing this, there have been 2 videos out:</p>
<ul>
<li><a href="https://www.youtube.com/watch?v=-3Cy-IxvvdA">Let&rsquo;s finetune a model for a ChatBot</a></li>
<li><a href="https://www.youtube.com/watch?v=Dm7Dz_-yZss">Fetching dataset for finetuning a model for a ChatBot</a></li>
</ul>
<p>There are more videos coming, and I hope that they help you out with honest development views. We all fail, none of this happens in 5 minutes, 10 minutes and so on. I wanted to be candid with whatever I develop, and I hope that if nothing - it at least helps y&rsquo;all with some motivation to keep going on your projects.</p>
<p>I am grateful to you all for the love and support you&rsquo;ve shown me, and I hope that I can give back to the community in some way or the other. I&rsquo;m always open to feedback, and I hope that I can help you out with your projects in some way or the other. Feel free to reach out to me on <a href="https://twitter.com/kushashwa">Twitter</a>.</p>
<h2 id="discord">Discord!</h2>
<p>Yep, we also have an active discord channel, so please feel free to join and chat with all of us there. Link: <a href="https://discord.gg/nh2KuAX3V8">https://discord.gg/nh2KuAX3V8</a>.</p>
]]></content>
        </item>
        
        <item>
            <title>Bring back the old times - celebrate your wins!</title>
            <link>https://krshrimali.github.io/posts/2024/01/bring-back-the-old-times-celebrate-your-wins/</link>
            <pubDate>Sun, 14 Jan 2024 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2024/01/bring-back-the-old-times-celebrate-your-wins/</guid>
            <description>Hi everyone! Happy to be back, in case y&amp;rsquo;all have been wondering - where have you been Kush? Well, a lot of things have been happening on my YouTube channel and Twitch Channel - buffetcodes. But in any case, I wanted to write something out - so here it is.
Disclaimer: this is more on a personal level rather than on an educational level, I&amp;rsquo;m sorry to disappoint if you were expecting a detailed tech blog today.</description>
            <content type="html"><![CDATA[<p>Hi everyone! Happy to be back, in case y&rsquo;all have been wondering - where have you been Kush? Well, a lot of things have been happening on my <a href="https://youtube.com/c/kushashwaraviShrimali">YouTube channel</a> and <a href="https://twitch.tv/buffetcodes">Twitch Channel - buffetcodes</a>. But in any case, I wanted to write something out - so here it is.</p>
<p>Disclaimer: this is more on a personal level rather than on an educational level, I&rsquo;m sorry to disappoint if you were expecting a detailed tech blog today. I&rsquo;ll come up with something soon. :)</p>
<p>Alright, so&hellip; this thought came into my mind, probably it&rsquo;s just me but how easily do we forget good things, people and moments? You&rsquo;ll see people talking about their down moments, but why have we stopped appreciating and recognising the ups we have had in the past? While reading this, let&rsquo;s all think about the <em>good</em> moments you had in the past, and think about the people who contributed to your journey (irrespective of their presence in your life <em>right now</em>), maybe close your eyes - speak out loud - or write it down - do whatever that suits you, but let&rsquo;s do it together.</p>
<p>Make sure to include very small wins as well when you think about the moments! :) A win is a win. I&rsquo;ll write things down as I think, please note that I chose to not name people/companies to keep their privacy and my peace üòâ</p>
<ol>
<li>I interned at NTU Singapore, immensely grateful to the friends who contributed significantly in the journey. Also thankful to my mentors, colleagues at NTU and professor as well. My elder brother and parents supported significantly in this internship, as it wasn&rsquo;t fully funded. I remember my brother and my parents telling me, &ldquo;You go, we&rsquo;ll take care of the money part&rdquo;. Going to Singapore changed the course of my life&hellip;</li>
<li>Because of the time I spent in Singapore, I realised I absolutely love low level programming, I didn&rsquo;t know it all though (I still don&rsquo;t :)) but it fascinated me. I started writing blogs for PyTorch C++ API. Doing that while in the institute, it kept me focused on my goal.</li>
<li>I decided not to sit for on-campus placements, there are many reasons to it - probably good for another blog?</li>
<li>Many developers helped me in the journey while writing blogs, they weren&rsquo;t just a &ldquo;technical content&rdquo; writing gig, each blog took me a month to write and reproduce results - each blog was a project to me.</li>
<li>I travelled to the US, many may not know this but when my VISA got rejected (first try) - I talked to a few professors of my institute, and talking to them comforted me. I got the VISA eventually, but I was never nervous - even if I would have &ldquo;failed&rdquo; to not get a VISA to the US, I would have happily worked for any company who would give me a job at that time, and would have tried creating an impact.</li>
<li>I travelled back to India because of COVID pandemic, and worked for a few startups. No matter how the experience was, I had my learnings - and have fortunately not committed the same mistakes again.</li>
<li>Started my YouTube channel after hitting the rock bottom of my emotional state. Streaming my projects, talking about things openly, helped me a lot.</li>
<li>Continued contributing to Open Source, Got laid off once (no shame in admitting this) - ran 7 kms after that üèÉ- and got another job within a month - very grateful to the God and family.</li>
<li>Shifted to Bangalore, worked on a lot of projects, streamed a lot, did a lot of running and started playing badminton üè∏.</li>
</ol>
<p>Okay, now once all this is done, lemme ask you a simple question - How many times did you express your gratitude to the people who helped in your journey? Do you still value them like the way you should have&hellip;? Not all, maybe, I&rsquo;ll leave that decision to you, but think about it.</p>
<p>I&rsquo;ll be back with another blog after this, meanwhile&hellip; let&rsquo;s all take some time - and express our gratitude to the people who were in the journey and who deserve knowing that you&rsquo;re doing GREAT! ‚ù§Ô∏è</p>
<p>Until next time,</p>
<p>Namaste üôè
Kushashwa Ravi Shrimali</p>
]]></content>
        </item>
        
        <item>
            <title>Daily Update: 3rd May 2023</title>
            <link>https://krshrimali.github.io/posts/2023/05/daily-update-3rd-may-2023/</link>
            <pubDate>Wed, 03 May 2023 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2023/05/daily-update-3rd-may-2023/</guid>
            <description>Okay, I think I should just accept this, while at work, it will be very hard for me to go and actually code something. And it makes sense, honestly at this stage - I feel like giving 50% of the time to reading + thinking, and 20% to implementing + 30% on iterating and feedback. So you&amp;rsquo;ll see more links about reading etc. over here.
Design a basic search engine (Google or Bing) | System Design Interview Prep Design a Payment System - System Design Interview That would be it, to be honest - not a lot.</description>
            <content type="html"><![CDATA[<p>Okay, I think I should just accept this, while at work, it will be very hard for me to go and actually code something. And it makes sense, honestly at this stage - I feel like giving 50% of the time to reading + thinking, and 20% to implementing + 30% on iterating and feedback. So you&rsquo;ll see more links about reading etc. over here.</p>
<ol>
<li><a href="https://www.youtube.com/watch?v=0LTXCcVRQi0&amp;list=LL&amp;index=7">Design a basic search engine (Google or Bing) | System Design Interview Prep</a></li>
<li><a href="https://www.youtube.com/watch?v=olfaBgJrUBI&amp;list=LL&amp;index=6">Design a Payment System - System Design Interview</a></li>
</ol>
<p>That would be it, to be honest - not a lot. I&rsquo;ve started reading through fasterthanlime&rsquo;s videos on Silly Fast Fresh Deploys, I&rsquo;ll share progress on it soon once I&rsquo;ve some learnings.</p>
<p>TODOs:</p>
<ol>
<li>Explore HVM: <a href="https://github.com/HigherOrderCO/HVM">https://github.com/HigherOrderCO/HVM</a>, looks interesting at least.</li>
<li>Read through: <a href="https://hal.science/hal-03827702v2/document">Specifying and Verifying Higher-order Rust Iterators</a>.</li>
<li>Record a video for YouTube!</li>
<li><a href="https://blog.rust-lang.org/inside-rust/2023/05/03/stabilizing-async-fn-in-trait.html">Stabilizing async fn in traits in 2023</a></li>
</ol>
<p>Alright, thank you all for reading. :) See y&rsquo;all tomorrow!</p>
]]></content>
        </item>
        
        <item>
            <title>Daily Update: 2nd May 2023</title>
            <link>https://krshrimali.github.io/posts/2023/05/daily-update-2nd-may-2023/</link>
            <pubDate>Tue, 02 May 2023 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2023/05/daily-update-2nd-may-2023/</guid>
            <description>Today was more like a reading/learning day. Here are the things I&amp;rsquo;ve been watching:
Which Database Model to choose?: Why this? Going to be useful for the project I&amp;rsquo;ve been working on. Thinking on directions of storing in-memory, using key-value model but let&amp;rsquo;s see. I made every sentry page 300 ms faster (intermediate) anthony explains #540 Why this? Always enjoy watching Anthony. Came on my YT recommendation, thought I&amp;rsquo;ll watch. Looks like a CDN config fix, also learnt a few things on watching the type of network calls (cached or not) from this video.</description>
            <content type="html"><![CDATA[<p>Today was more like a reading/learning day. Here are the things I&rsquo;ve been watching:</p>
<ol>
<li><a href="https://www.youtube.com/watch?v=9mdadNspP_M">Which Database Model to choose?</a>:
<ul>
<li>Why this?
<ul>
<li>Going to be useful for the <a href="https://github.com/krshrimali/keystroke-store-rs">project</a> I&rsquo;ve been working on. Thinking on directions of storing in-memory, using key-value model but let&rsquo;s see.</li>
</ul>
</li>
</ul>
</li>
<li><a href="https://www.youtube.com/watch?v=FY7EQwT7QKU">I made every sentry page 300 ms faster (intermediate) anthony explains <code>#540</code></a>
<ul>
<li>Why this?
<ul>
<li>Always enjoy watching Anthony. Came on my YT recommendation, thought I&rsquo;ll watch. Looks like a CDN config fix, also learnt a few things on watching the type of network calls (cached or not) from this video.</li>
</ul>
</li>
</ul>
</li>
<li><a href="https://bertptrs.nl/2023/04/27/how-does-async-rust-work.html">How does async rust work</a>
<ul>
<li>Still reading, not done yet. Will update my learnings when done.</li>
</ul>
</li>
<li>Update NeoVim Config to use ruff-lsp instead of pyright for most except hover
<ul>
<li>Ruff has been there for long, boasts a lot of perf improvements as a linter. Good to see Ruff LSP growing.</li>
<li>NeoVim config repository: <a href="https://github.com/krshrimali/nvim">https://github.com/krshrimali/nvim</a></li>
<li>It&rsquo;s of course going to take a lot of efforts to catch up to pyright in terms of capabilities, but I&rsquo;m very positive.</li>
<li>I love to see code actions finally in my neovim + python code. üéâ</li>
<li>It&rsquo;s written in Rust, for those who don&rsquo;t know üòâ</li>
</ul>
</li>
</ol>
<p>TODOs:</p>
<ol>
<li>Explore HVM: <a href="https://github.com/HigherOrderCO/HVM">https://github.com/HigherOrderCO/HVM</a>, looks interesting at least.</li>
<li>Read through: <a href="https://hal.science/hal-03827702v2/document">Specifying and Verifying Higher-order Rust Iterators</a>.</li>
<li>Record a video for YouTube!</li>
</ol>
<p>Alright, thank you all for reading. :) See y&rsquo;all tomorrow!</p>
]]></content>
        </item>
        
        <item>
            <title>Daily Update: 1st May 2023</title>
            <link>https://krshrimali.github.io/posts/2023/05/daily-update-1st-may-2023/</link>
            <pubDate>Mon, 01 May 2023 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2023/05/daily-update-1st-may-2023/</guid>
            <description>Interesting day, lots of design stuff for the project we&amp;rsquo;ve been working on.
Designing flow for the word combinator service This is actually tricky, as we are figuring out how we&amp;rsquo;ll figure out the keystrokes into words/phrases (I&amp;rsquo;d like to call them entities at one point of time). The algorithm is close, and I&amp;rsquo;m particularly hopeful about it: It considers some edge cases of mouse events, sitting idle, and gives user the control what they would like to choose.</description>
            <content type="html"><![CDATA[<p>Interesting day, lots of design stuff for the <a href="https://github.com/krshrimali/keystroke-store-rs">project we&rsquo;ve been working on</a>.</p>
<ol>
<li>Designing flow for the word combinator service
<ul>
<li>This is actually tricky, as we are figuring out how we&rsquo;ll figure out the keystrokes into words/phrases (I&rsquo;d like to call them <em>entities</em> at one point of time).</li>
<li>The algorithm is close, and I&rsquo;m particularly hopeful about it:
<ul>
<li>It considers some edge cases of mouse events, sitting idle, and gives user the control what they would like to choose.</li>
<li>More on this very soon!</li>
</ul>
</li>
</ul>
</li>
<li>Boring nerdy stuff: Exploring fzf
<ul>
<li>I wanted to have fzf previews height changed to 100%, finally changed my zsh config for that. It looks much better now.</li>
<li>Then figured out that I&rsquo;m using outdated formula for fzf, and I&rsquo;ll end up going through fzf release notes to see what has changed over the last few releases.
<ul>
<li>It&rsquo;s usually a good practice I believe to go through the release notes, and be aware of the tools you use.</li>
</ul>
</li>
</ul>
</li>
<li>Work day tomorrow, so doing some early readings.
<ul>
<li>Of course can&rsquo;t share details, but yep, going to be more occupied now.</li>
</ul>
</li>
</ol>
<p>A lot of TODOs from ~yesterday~ day before yesterday are left ü•∫, I&rsquo;ll move them to tomorrow, yay! Procrastination, let&rsquo;s go üòÜüéâ</p>
<p>TODOs:</p>
<ol>
<li>Explore HVM: <a href="https://github.com/HigherOrderCO/HVM">https://github.com/HigherOrderCO/HVM</a>, looks interesting at least.</li>
<li>Read through: <a href="https://hal.science/hal-03827702v2/document">Specifying and Verifying Higher-order Rust Iterators</a>.</li>
<li>Read through: <a href="https://bertptrs.nl/2023/04/27/how-does-async-rust-work.html">How does async rust work</a></li>
<li>Record a video for YouTube!</li>
</ol>
<p>Alright, thank you all for reading. :) See y&rsquo;all tomorrow!</p>
]]></content>
        </item>
        
        <item>
            <title>Daily Update: 30th April 2023</title>
            <link>https://krshrimali.github.io/posts/2023/04/daily-update-30th-april-2023/</link>
            <pubDate>Sun, 30 Apr 2023 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2023/04/daily-update-30th-april-2023/</guid>
            <description>Lovely day, had my friend imsrbh come over and we were talking about the project I wanted to do. He had some ideas and of course some experience with Kafka, so he helped me setup Kafka and docker on my machine, and that&amp;rsquo;s how it all started.
Setting up Kafka and Docker on my machine: Refer to this blog for Kafka setup. We verified by running a sample producer-consumer app in Python and it worked.</description>
            <content type="html"><![CDATA[<p>Lovely day, had my friend <a href="https://github.com/imsrbh">imsrbh</a> come over and we were talking about the project I wanted to do. He had some ideas and of course some experience with Kafka, so he helped me setup Kafka and docker on my machine, and that&rsquo;s how it all started.</p>
<ol>
<li>Setting up Kafka and Docker on my machine:
<ul>
<li>Refer to <a href="https://medium.com/@fengliplatform/kafka-broker-setup-using-docker-image-33f7a8081a07#:~:text=1%20Setup%20Kafka%20cluster%20on%20Windows%20laptop%201,instance%20...%205%201.5%20Create%20Kafka%20topic%20">this blog</a> for Kafka setup.</li>
<li>We verified by running a sample producer-consumer app in Python and it worked.</li>
</ul>
</li>
<li><a href="https://github.com/krshrimali/keystroke-store-rs">Starting to implement the core logic of getting key strokes in Rust</a>
<ul>
<li>I&rsquo;m using <code>rdev</code> library for this, it was decent.</li>
<li>Was wondering how I can convert the keystrokes to strings, apparently it was a Rust Enum.</li>
<li>Fortunately, they had a feature <code>serialize</code> which would help me do just that. Now it&rsquo;s quite smooth.</li>
</ul>
</li>
<li>Implementing Kafka Producer-Consumer in Rust
<ul>
<li>Kafka has a client in Rust, <code>cargo add kafka</code> will help.</li>
<li>Wrote Kafka Producer and Consumer referring to their official documentation.</li>
<li>It works flawlessly.</li>
<li>We were sending the keys as <code>&amp;[u8]</code> and had to convert these to strings back at consumer (need to proper error checking there)</li>
<li>Producer repo: <a href="https://github.com/krshrimali/keystroke-store-rs">https://github.com/krshrimali/keystroke-store-rs</a></li>
<li>Consumer repo: <a href="https://github.com/krshrimali/keystroke-consumer-rs">https://github.com/krshrimali/keystroke-consumer-rs</a></li>
<li>Quick learning on why we didn&rsquo;t go for Redis (mostly because we wanted to learn Kafka in Rust lol, can try Redis one day but I like reliability of Kafka): <a href="https://stackoverflow.com/a/37993809">https://stackoverflow.com/a/37993809</a></li>
</ul>
</li>
</ol>
<p>A lot of TODOs from yesterday are left, I&rsquo;ll move them to tomorrow, yay! Procrastination, let&rsquo;s go üòÜüéâ</p>
<p>TODOs:</p>
<ol>
<li>Explore HVM: <a href="https://github.com/HigherOrderCO/HVM">https://github.com/HigherOrderCO/HVM</a>, looks interesting at least.</li>
<li>Read through: <a href="https://hal.science/hal-03827702v2/document">Specifying and Verifying Higher-order Rust Iterators</a>.</li>
<li>Read through: <a href="https://bertptrs.nl/2023/04/27/how-does-async-rust-work.html">How does async rust work</a></li>
<li>Record a video for YouTube!</li>
</ol>
<p>Alright, thank you all for reading. :) See y&rsquo;all tomorrow!</p>
]]></content>
        </item>
        
        <item>
            <title>Daily Update: 29th April 2023</title>
            <link>https://krshrimali.github.io/posts/2023/04/daily-update-29th-april-2023/</link>
            <pubDate>Sat, 29 Apr 2023 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2023/04/daily-update-29th-april-2023/</guid>
            <description>Alright, we are back. It&amp;rsquo;s Saturday, so I spent a lot of time cleaning up my flat and my setup. Bengaluru is quite a dusty city, so yep, gotta clean regularly. Anyways, in terms of learning, my goals of today were to read some source code and papers/official documentation. It&amp;rsquo;s been some time since I didn&amp;rsquo;t do any Rust, so today I&amp;rsquo;ll just touch upon that as well.
Rust - building a UI to plot a sensor in real time Why this?</description>
            <content type="html"><![CDATA[<p>Alright, we are back. It&rsquo;s Saturday, so I spent a lot of time cleaning up my flat and my setup. Bengaluru is quite a dusty city, so yep, gotta clean regularly. Anyways, in terms of learning, my goals of today were to read some source code and papers/official documentation. It&rsquo;s been some time since I didn&rsquo;t do any Rust, so today I&rsquo;ll just touch upon that as well.</p>
<ol>
<li><a href="https://www.youtube.com/watch?v=zUvHkkkrmIY">Rust - building a UI to plot a sensor in real time</a>
<ul>
<li>Why this?
<ul>
<li>I&rsquo;ve used Iced library quite a bit so far, so wanted to understand how other UI libraries look like.</li>
<li>I&rsquo;m not going for the &ldquo;famous&rdquo; libraries here, just wanted to experience any other library. Plus, this video seemed to be decent and technically focused enough on the implementation.</li>
</ul>
</li>
</ul>
</li>
<li>Setting up PostgreSQL server on my system:
<ul>
<li>Why this?
<ul>
<li>For me to start working on some projects of my own, it&rsquo;s important to setup stage for them.</li>
</ul>
</li>
<li>Notes:
<ul>
<li>I used <a href="https://www.digitalocean.com/community/tutorials/how-to-install-postgresql-on-ubuntu-20-04-quickstart">this blog by digital ocean</a> as reference.</li>
</ul>
</li>
</ul>
</li>
<li>Micro Project: Store all the key presses in a server
<ul>
<li>Notes:
<ul>
<li>Since I type a lot, everyone does, the DB will have to be good enough.</li>
<li>I wanted to see how I can enable indexing and searching, this will help give me an idea.</li>
<li>No UI stuff right now. Maybe one day.</li>
</ul>
</li>
</ul>
</li>
<li>NeoVim Config:
<ul>
<li>I was randomly trying a keymap, and I just remembered I had <code>&lt;leader&gt;nf</code> for <code>SnipRun</code>. And oh, wow - it finally made sense why it could be useful.</li>
<li>Selecting text, code block, displaying output in the command window or as virtual text (different highlight for errors) and even in a vertical split terminal, amazing stuff!</li>
<li>Something my <a href="https://github.com/krshrimali/nvim-autorunner">nvim-autorunner</a> was trying to do, cool stuff.</li>
</ul>
</li>
</ol>
<p>Oh, and on another note: I watched a movie (after a long long time). Had to find time to relax a bit.</p>
<p>(New section: TODOs for tomorrow)</p>
<p>TODOs:</p>
<ol>
<li>Explore HVM: <a href="https://github.com/HigherOrderCO/HVM">https://github.com/HigherOrderCO/HVM</a>, looks interesting at least.</li>
<li>Read through: <a href="https://hal.science/hal-03827702v2/document">Specifying and Verifying Higher-order Rust Iterators</a>.</li>
<li>Read through: <a href="https://bertptrs.nl/2023/04/27/how-does-async-rust-work.html">How does async rust work</a></li>
<li>Continue working on the micro project.</li>
<li>Record a video for YouTube!</li>
</ol>
<p>Alright, thank you all for reading. :) See y&rsquo;all tomorrow!</p>
]]></content>
        </item>
        
        <item>
            <title>Daily Update: 28th April 2023</title>
            <link>https://krshrimali.github.io/posts/2023/04/daily-update-28th-april-2023/</link>
            <pubDate>Fri, 28 Apr 2023 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2023/04/daily-update-28th-april-2023/</guid>
            <description>Started my day with talking to my family, and then kicking off work after getting ready. (Note: these blogs are mostly around my personal learning updates, so I&amp;rsquo;ll mostly miss anything that I do at work as that&amp;rsquo;s confidential)
What is OSI Model | Real World Examples Why this? The answer to: &amp;ldquo;How does the communication work from client to server&amp;rdquo; is very important in backend. I wanted to see if I missed anything from my graduate studies, but nothing much.</description>
            <content type="html"><![CDATA[<p>Started my day with talking to my family, and then kicking off work after getting ready. (Note: these blogs are mostly around my personal learning updates, so I&rsquo;ll mostly miss anything that I do at work as that&rsquo;s confidential)</p>
<ol>
<li><a href="https://www.youtube.com/watch?v=0y6FtKsg6J4">What is OSI Model | Real World Examples</a>
<ul>
<li>Why this?
<ul>
<li>The answer to: &ldquo;How does the communication work from client to server&rdquo; is very important in backend. I wanted to see if I missed anything from my graduate studies, but nothing much. This was more like a refresher.</li>
</ul>
</li>
<li>Notes:
<ul>
<li>Each operating system has their own implementation of TCP protocol. Linux has it&rsquo;s own for example, and it&rsquo;s open sourced.</li>
<li>Can take a look at TCP&rsquo;s source code in Linux source code to understand how checksum correction works.</li>
</ul>
</li>
<li>Cloud load balancers: L4 Load Balancer (operates at TCP Level), L7 Load Balnacer (operates at Application Protocol Layer - HTTP/HTTPS)</li>
</ul>
</li>
<li><a href="https://www.postgresql.org/docs/current/tutorial-arch.html">Postgres: Architectural Fundamentals</a>
<ul>
<li>Why this?
<ul>
<li>Going through database design and architectural fundamentals is helpful. I plan to explore CockroachDB soon, but wanted to get some idea about the ones I&rsquo;ve used so far (Postgres for example)</li>
</ul>
</li>
<li>Notes:
<ul>
<li>Uses client/server model.</li>
<li>PostgreSQL session consists following processes:
<ul>
<li>Server: manages DB files, accepts connections to the DB from client apps, performs DB actions on behalf of clients. DB server process is called postgres</li>
<li>Client (frontend): app that wants to perform DB operations.</li>
</ul>
</li>
<li>Client/server could be on diff hosts: communicate over TCP/IP n/w connection</li>
<li>postgres can handle multiple connections from clients:
<ul>
<li>Forks a new process for each connection
<ul>
<li>The new process and client directly communicate</li>
<li>No intervention of postgres server</li>
</ul>
</li>
<li>Supervisor server process is always running (daemon process), waiting for client connections
<ul>
<li>Client and child server process can come and go</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><a href="https://www.geeksforgeeks.org/postgresql-system-architecture/">PostgreSQL System Architecture</a>
<ul>
<li>Why this?
<ul>
<li>Just wanted to explore another blog on the same topic to see if I missed anything. Tbh, nothing much.</li>
</ul>
</li>
<li>Notes:
<ul>
<li>PostgreSQL: process-per-transaction model</li>
<li>postgres server process:
<ul>
<li>Managed by postmaster, central coordinating process</li>
<li>Responsibilities:
<ul>
<li>Initializing, terminating the server</li>
<li>Handling connection requests from the new clients</li>
<li>Recovery</li>
<li>Run background processes</li>
</ul>
</li>
<li>Shared Memory:
<ul>
<li>Reserved for DB caching and Transactional Log Caching</li>
<li>Shared Disk Buffer</li>
<li>Shared Tables
<ul>
<li>Uses same set of tables to host multiple client data (TODO: how?)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li>Backend Processes:
<ul>
<li>Client interacts with backend processes (submits queries and receiving queries result)</li>
<li>Multiple backend servers executing queries concurrently</li>
<li>Each backend server:
<ul>
<li>will handle only a single query at a time</li>
<li>access data from main memory buffer pool (placed in shared memory)</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>Thank you! :) See y&rsquo;all in the next blog.</p>
]]></content>
        </item>
        
        <item>
            <title>I started building an app using Rust and here is how it went...</title>
            <link>https://krshrimali.github.io/posts/2022/12/i-started-building-an-app-using-rust-and-here-is-how-it-went.../</link>
            <pubDate>Mon, 12 Dec 2022 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2022/12/i-started-building-an-app-using-rust-and-here-is-how-it-went.../</guid>
            <description>Hi everyone!! I&amp;rsquo;ve an update, on what I&amp;rsquo;ve been up to - and I&amp;rsquo;m excited. It&amp;rsquo;s a rusty update üòâ. As always, I would love to tell you a story (this will help set some context), but if you want to skip and go directly to the update, please scroll to: # THE Update section.
The Story I&amp;rsquo;ve been through, possibly, the best and the worst time of my life. I use these contrasting words because everything went wrong - and that&amp;rsquo;s where you get an opportunity to shine.</description>
            <content type="html"><![CDATA[<p>Hi everyone!! I&rsquo;ve an update, on what I&rsquo;ve been up to - and I&rsquo;m excited. It&rsquo;s a <em>rusty</em> update üòâ. As always, I would love to tell you a story (this will help set some context), but if you want to skip and go directly to the update, please scroll to: <code># THE Update</code> section.</p>
<h2 id="the-story">The Story</h2>
<p>I&rsquo;ve been through, possibly, the best and the worst time of my life. I use these contrasting words because everything went wrong - and that&rsquo;s where you get an opportunity to shine. I think I fairly enjoyed resisting the pain and fighting through the odds, hopefully you&rsquo;ll learn about it very soon on my blog (just need the courage to say it out loud :)).</p>
<p>Anyways, just when the life hit extreme low, I had two options:</p>
<ol>
<li>Cry about it, not for a day, but keep crying about it.</li>
<li>Accept, and do something that I enjoy.</li>
</ol>
<p>I chose a mix of both 1 and 2. Cried for a day or two, but then accepted and started diverting my energy to the things I imagined myself doing. One of those, which I can share here, was finishing up my dream side projects. To name a few:</p>
<ol>
<li><a href="https://github.com/krshrimali/interpreter-go">Completing the book: Writing Interpreter in Go</a>.</li>
<li><a href="https://github.com/krshrimali/rust-leetcode">Do some leetcode to gain confidence</a>.</li>
<li><a href="https://github.com/krshrimali/CPP-File-Manager">Release the next version of C++ File Manager</a>.</li>
<li><strong>Write an App in Rust</strong>
and more&hellip;</li>
</ol>
<p>The 4th point you&rsquo;re looking at, is exactly what we are going to cover today.</p>
<h2 id="the-update">THE Update</h2>
<p>Here it comes! For those who (very kindly) follow <a href="https://youtube.com/c/kushashwaraviShrimali">my YouTube channel</a>, know already that I&rsquo;ve been learning Rust for a while. And while I was at it, I found it a good time to start building something. Pop! OS, the best Linux distribution I&rsquo;ve ever come across, announced their new Cosmic Desktop Environment a while back (it&rsquo;s a work in progress). I like reading source codes, and have been following what they were doing with Cosmic and remembered that they were using <a href="https://github.com/iced-rs/iced">Iced Library</a> for the development (GUI). I thought to give it a try, and the best place to start with, was the <a href="https://github.com/krshrimali/youtuber-monitoring-app">YouTube Monitoring App</a> which I was building earlier with Python and Electron JS. Porting the idea to Rust was comparatively easier than to think of another project.</p>
<p>Before I proceed, feel free to check out the repository <a href="https://github.com/krshrimali/YouTube-Monitoring-App-Rust-Iced">here</a>. It would be already outdated for this blog, but nonetheless - I hope you like the work.</p>
<p>So the journey took off, started with going through the examples, and the <a href="https://github.com/iced-rs/iced/tree/master/examples/styling"><code>styling</code></a> example. Seeing how theme is switched, was mesmerizing.</p>
<p>That&rsquo;s where I started, taking the first steps, just replicating the <code>styling</code> example to see if I can reproduce and understand what they were doing. As the time passed by, things started to take a good look:</p>
<ol>
<li>Theme switching was enabled.</li>
<li>Each user had a card (but not aligned üò¢).</li>
</ol>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/rust_app_stage_first.png" alt="Stage - 1"></p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/rust_app_stage_first_light.png" alt="Stage - 1 (Light Theme)"></p>
<p>The ideal stage would be to see the YouTube API collect details, create the JSON file, and show it to the user. I knew I was not even close to the final goal, but why give up?</p>
<p>Anyways, my next target was to figure out having a grid - multiple rows and multiple columns. From what I know, there isn&rsquo;t a <code>grid</code> like implementation within Iced, so I had to use <code>Column</code> and <code>Row</code> classes from Iced. It was tricky, if I have to be very honest, but finally worked out. Had to ask a couple of questions on the discord channel of Iced, they were very kind and quick to help me with my queries.</p>
<p>I also had to choose an image for each user, as an avatar was necessary. Once added, I knew it will start looking better. A header and a footer were also required, to give the user some info about what they are seeing on the screen. However, when the grid wasn&rsquo;t full, the image wouldn&rsquo;t align and that was an issue to resolve for the next stage.</p>
<p>Adding the avatar was very interesting, I wanted a link to work (for the avatar). But for now, I thought I&rsquo;ll suffice to using an image path to see if it really works (spoiler: it did üòÑ):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">profile_pic</span><span style="color:#f92672">&lt;</span><span style="color:#a6e22e">&#39;a</span><span style="color:#f92672">&gt;</span>(width: <span style="color:#66d9ef">u16</span>) -&gt; <span style="color:#a6e22e">Container</span><span style="color:#f92672">&lt;</span><span style="color:#a6e22e">&#39;a</span>, Message<span style="color:#f92672">&gt;</span> {
</span></span><span style="display:flex;"><span>    container(
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// This should go away once we unify resource loading on native
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#75715e">// platforms
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#66d9ef">if</span> cfg!(target_arch <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;wasm32&#34;</span>) {
</span></span><span style="display:flex;"><span>            image(<span style="color:#e6db74">&#34;profile_images/Noddy.jpeg&#34;</span>)
</span></span><span style="display:flex;"><span>        } <span style="color:#66d9ef">else</span> {
</span></span><span style="display:flex;"><span>            image(format!(
</span></span><span style="display:flex;"><span>                <span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">/profile_images/Noddy.jpeg&#34;</span>,
</span></span><span style="display:flex;"><span>                env!(<span style="color:#e6db74">&#34;CARGO_MANIFEST_DIR&#34;</span>)
</span></span><span style="display:flex;"><span>            ))
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        .height(Length::Units(width))
</span></span><span style="display:flex;"><span>        .width(Length::Units(width)),
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    .width(Length::Fill)
</span></span><span style="display:flex;"><span>    .center_x()
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/rust_app_stage_second.png" alt="Stage - 2"></p>
<p>As I knew things were starting to take place, the next important step was to fix the alignment, and enable JSON parsing. Let me show you the issue we had with alignment:</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/rust_app_stage_second_alignment_issue.png" alt="Stage - 2 (alignment issue)"></p>
<p>The alignment issue was fixed with using <code>align_items</code> and also avoiding <code>width(Length::Fill)</code> with the user cards. We&rsquo;ll discuss these details in the next blog, for now, I just shared to give you a hint.</p>
<p>For JSON parsing, to start with, I created a <a href="https://github.com/krshrimali/YouTube-Monitoring-App-Rust-Iced/blob/main/list_users.json">sample JSON file</a>, and used <a href="https://github.com/serde-rs/json"><code>serde</code></a> crate to parse JSON file. The way a JSON can be deserialized into a JSON class, was amazing to see - very intuitive.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">pub</span> <span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">read_json</span>(file_path: <span style="color:#66d9ef">&amp;</span><span style="color:#66d9ef">str</span>) -&gt; Result<span style="color:#f92672">&lt;</span>YTCreator, Box<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">dyn</span> Error<span style="color:#f92672">&gt;&gt;</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> file <span style="color:#f92672">=</span> File::open(file_path)<span style="color:#f92672">?</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> reader <span style="color:#f92672">=</span> BufReader::new(file);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Read the JSON contents of the file as an instance of `YTCreator`.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">let</span> u: <span style="color:#a6e22e">YTCreator</span> <span style="color:#f92672">=</span> serde_json::from_reader(reader)<span style="color:#f92672">?</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> u.size() <span style="color:#f92672">&gt;</span> <span style="color:#66d9ef">MAX_EXPECTED_ITEMS</span> {
</span></span><span style="display:flex;"><span>        Ok(u.slice_to(<span style="color:#66d9ef">MAX_EXPECTED_ITEMS</span>))
</span></span><span style="display:flex;"><span>    } <span style="color:#66d9ef">else</span> {
</span></span><span style="display:flex;"><span>        Ok(u)
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The implementation of <code>YTCreator</code> had the fields that were useful for the user:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#75715e">#[derive(Deserialize, Debug, Default, Clone)]</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">pub</span> <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">YTCreator</span> {
</span></span><span style="display:flex;"><span>    names: Vec<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">&gt;</span>,
</span></span><span style="display:flex;"><span>    avatar_links: Vec<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">&gt;</span>,
</span></span><span style="display:flex;"><span>    descriptions: Vec<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">&gt;</span>,
</span></span><span style="display:flex;"><span>    is_live_status: Vec<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">&gt;</span>,
</span></span><span style="display:flex;"><span>    subscribers: Vec<span style="color:#f92672">&lt;</span>String<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>If you have not noticed already, focus on the <code>u.slice_to(MAX_EXPECTED_ITEMS)</code> expression. While this isn&rsquo;t really useful right now (more on this later), but it was a good practice to implement. This basically answers: &ldquo;What if there is more data then the grid limit?&rdquo;. Let&rsquo;s say the JSON file contains the data for 13 users, but our grid could only have 12 users&rsquo; data -&gt; in this case, <code>.slice_to</code> will make sure that we only use maximum of 12 users on the grid:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">slice_to</span>(<span style="color:#f92672">&amp;</span>self, count_items: <span style="color:#66d9ef">usize</span>) -&gt; <span style="color:#a6e22e">YTCreator</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> new_obj <span style="color:#f92672">=</span> YTCreator {
</span></span><span style="display:flex;"><span>        names: Vec::new(),
</span></span><span style="display:flex;"><span>        avatar_links: Vec::new(),
</span></span><span style="display:flex;"><span>        descriptions: Vec::new(),
</span></span><span style="display:flex;"><span>        is_live_status: Vec::new(),
</span></span><span style="display:flex;"><span>        subscribers: Vec::new(),
</span></span><span style="display:flex;"><span>    };
</span></span><span style="display:flex;"><span>    new_obj.names <span style="color:#f92672">=</span> self.names.get(<span style="color:#ae81ff">0</span><span style="color:#f92672">..</span>count_items).unwrap().to_vec();
</span></span><span style="display:flex;"><span>    new_obj.avatar_links <span style="color:#f92672">=</span> self.avatar_links.get(<span style="color:#ae81ff">0</span><span style="color:#f92672">..</span>count_items).unwrap().to_vec();
</span></span><span style="display:flex;"><span>    new_obj.descriptions <span style="color:#f92672">=</span> self.descriptions.get(<span style="color:#ae81ff">0</span><span style="color:#f92672">..</span>count_items).unwrap().to_vec();
</span></span><span style="display:flex;"><span>    new_obj.is_live_status <span style="color:#f92672">=</span> self.is_live_status.get(<span style="color:#ae81ff">0</span><span style="color:#f92672">..</span>count_items).unwrap().to_vec();
</span></span><span style="display:flex;"><span>    new_obj.subscribers <span style="color:#f92672">=</span> self.subscribers.get(<span style="color:#ae81ff">0</span><span style="color:#f92672">..</span>count_items).unwrap().to_vec();
</span></span><span style="display:flex;"><span>    new_obj
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The implementation of <code>slice_to</code> method is fairly simple, just creating another <code>YTCreator</code> object but with stripped count.</p>
<p>One of the very important step was to enable passing a link for the image/avatar. This was made possible using <code>reqwest</code> crate, getting the image in a form of bytes array and then converting it to an <code>image::Handle</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">profile_pic</span><span style="color:#f92672">&lt;</span><span style="color:#a6e22e">&#39;a</span><span style="color:#f92672">&gt;</span>(width: <span style="color:#66d9ef">u16</span>, link: String) -&gt; <span style="color:#a6e22e">Container</span><span style="color:#f92672">&lt;</span><span style="color:#a6e22e">&#39;a</span>, Message<span style="color:#f92672">&gt;</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> img_obj <span style="color:#f92672">=</span> reqwest::blocking::get(link).ok();
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> img_bytes <span style="color:#f92672">=</span> <span style="color:#66d9ef">match</span> img_obj {
</span></span><span style="display:flex;"><span>        Some(bytes) <span style="color:#f92672">=&gt;</span> {
</span></span><span style="display:flex;"><span>            bytes.bytes().ok()
</span></span><span style="display:flex;"><span>        },
</span></span><span style="display:flex;"><span>        None <span style="color:#f92672">=&gt;</span> None
</span></span><span style="display:flex;"><span>    }.unwrap();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> out_img: <span style="color:#a6e22e">image</span>::Handle <span style="color:#f92672">=</span> image::Handle::from_memory(img_bytes.to_vec());
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    container(
</span></span><span style="display:flex;"><span>        image(out_img)
</span></span><span style="display:flex;"><span>        .height(Length::Units(width))
</span></span><span style="display:flex;"><span>        .width(Length::Units(width)),
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    .width(Length::Fill)
</span></span><span style="display:flex;"><span>    .center_x()
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>While I was very happy that:</p>
<ul>
<li>The alignment was fixed</li>
<li>Image links were working</li>
<li>JSON parsing was done correctly</li>
</ul>
<p><strong>BUT</strong> there was a small but significantly major mistake I made. Let&rsquo;s keep it for later though, keep reading ‚ù§Ô∏è</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/rust_app_stage_third.png" alt="Stage - 3"></p>
<p>Starting from here, you&rsquo;ll understand how important development is. In this stage, the UI won&rsquo;t change <em>BUT</em> we&rsquo;ll be significantly improving the performance.</p>
<p>So, while I was very happy about the project progress so far, I thought I&rsquo;ll ask my friend to open it up on his system. He had Windows, but fortunately he also had WSL. Thanks to him, he didn&rsquo;t give up on trying to run GUI on his WSL - and when finally the app loaded, it was <em>LAGGING</em>. &#x1f622;</p>
<p>I was surprised, because on my Mac - it was working fine. I opened up my Linux system, and guess what? It lagged there as well. I immediately knew I was doing something wrong. Now, as developers, we generally try to get to the bottleneck of the issue, and I had an instinct about it.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">view</span>(<span style="color:#f92672">&amp;</span>self) -&gt; <span style="color:#a6e22e">iced</span>::Element<span style="color:#f92672">&lt;</span>&#39;_, Self::Message<span style="color:#f92672">&gt;</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> choose_theme <span style="color:#f92672">=</span> <span style="color:#f92672">..</span>.;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> content <span style="color:#f92672">=</span> container(column![choose_theme].spacing(<span style="color:#ae81ff">20</span>).padding(<span style="color:#ae81ff">20</span>).max_width(<span style="color:#ae81ff">600</span>))
</span></span><span style="display:flex;"><span>        .width(Length::Fill)
</span></span><span style="display:flex;"><span>        .center_x();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> footer <span style="color:#f92672">=</span> <span style="color:#f92672">..</span>.;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> title_header <span style="color:#f92672">=</span> <span style="color:#f92672">..</span>.;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> all_cards <span style="color:#f92672">=</span> render_cards::create_list_of_cards(<span style="color:#f92672">&amp;</span>self.json_obj);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> binding <span style="color:#f92672">=</span> render_cards::ListOfCards::default();
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// RELEVANT...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">let</span> first_row <span style="color:#f92672">=</span> render_cards::create_row(all_cards.get(<span style="color:#ae81ff">0</span>).unwrap_or(<span style="color:#f92672">&amp;</span>binding));
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> second_row <span style="color:#f92672">=</span> render_cards::create_row(all_cards.get(<span style="color:#ae81ff">1</span>).unwrap_or(<span style="color:#f92672">&amp;</span>binding));
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> third_row <span style="color:#f92672">=</span> render_cards::create_row(all_cards.get(<span style="color:#ae81ff">2</span>).unwrap_or(<span style="color:#f92672">&amp;</span>binding));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    container(column![
</span></span><span style="display:flex;"><span>        content,
</span></span><span style="display:flex;"><span>        horizontal_rule(<span style="color:#ae81ff">10</span>),
</span></span><span style="display:flex;"><span>        title_header,
</span></span><span style="display:flex;"><span>        horizontal_rule(<span style="color:#ae81ff">10</span>),
</span></span><span style="display:flex;"><span>        first_row,
</span></span><span style="display:flex;"><span>        second_row,
</span></span><span style="display:flex;"><span>        third_row,
</span></span><span style="display:flex;"><span>        horizontal_rule(<span style="color:#ae81ff">10</span>),
</span></span><span style="display:flex;"><span>        footer,
</span></span><span style="display:flex;"><span>        horizontal_rule(<span style="color:#ae81ff">10</span>),
</span></span><span style="display:flex;"><span>    ])
</span></span><span style="display:flex;"><span>    .height(Length::Shrink)
</span></span><span style="display:flex;"><span>    .into()
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The <code>view</code> method above was running every time I switched the theme (whenever anything changed), and this was the problem. Let me show you the <code>create_row</code> method, which will give you an idea why it&rsquo;s slow:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">pub</span> <span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">create_row</span>(cards: <span style="color:#66d9ef">&amp;</span><span style="color:#a6e22e">ListOfCards</span>) -&gt; <span style="color:#a6e22e">Row</span><span style="color:#f92672">&lt;</span>&#39;static, Message<span style="color:#f92672">&gt;</span> {
</span></span><span style="display:flex;"><span>    Row::with_children(
</span></span><span style="display:flex;"><span>        cards
</span></span><span style="display:flex;"><span>            .cards
</span></span><span style="display:flex;"><span>            .iter()
</span></span><span style="display:flex;"><span>            .map(<span style="color:#f92672">|</span>each_card<span style="color:#f92672">|</span> {
</span></span><span style="display:flex;"><span>                container(
</span></span><span style="display:flex;"><span>                    row![
</span></span><span style="display:flex;"><span>                        column![create_card(each_card)].spacing(<span style="color:#ae81ff">50</span>).padding(<span style="color:#ae81ff">20</span>),
</span></span><span style="display:flex;"><span>                        column![profile_pic(<span style="color:#ae81ff">130</span>, each_card.avatar_link.to_owned())]
</span></span><span style="display:flex;"><span>                            .width(Length::Units(<span style="color:#ae81ff">130</span>))
</span></span><span style="display:flex;"><span>                            .height(Length::Units(<span style="color:#ae81ff">150</span>))
</span></span><span style="display:flex;"><span>                            .padding(<span style="color:#ae81ff">20</span>)
</span></span><span style="display:flex;"><span>                    ]
</span></span><span style="display:flex;"><span>                    .align_items(iced::Alignment::End)
</span></span><span style="display:flex;"><span>                    .height(Length::Fill),
</span></span><span style="display:flex;"><span>                )
</span></span><span style="display:flex;"><span>                .width(Length::Fill)
</span></span><span style="display:flex;"><span>                .center_y()
</span></span><span style="display:flex;"><span>                .style(theme::Container::Box)
</span></span><span style="display:flex;"><span>                .into()
</span></span><span style="display:flex;"><span>            })
</span></span><span style="display:flex;"><span>            .collect(),
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Just observe, that I was calling <code>profile_pic</code> method with the avatar link - which means that every time the theme is switched, the images will be fetched again. Wow! That&rsquo;s the only bottleneck? Nope!</p>
<p>Surprise! There is one more, we were actually reading the JSON file in the <code>view</code> function as well. Which was bad! So we finally have 2 bottlenecks for the performance:</p>
<ol>
<li>Downloading avatar link to an image handle.</li>
<li>Parsing and deserializing the JSON file to <code>YTCreator</code> struct.</li>
</ol>
<p>(Also thanks to the iced community on discord, who helped with the first point above. They were really helpful.)</p>
<p>Solving both bottlenecks above was intuitive to me. We could parse the JSON file as well as download the avatars when the app is created, for now. Later on, we&rsquo;ll do it when the user has changed inputs for the YT users they want to monitor. Here is how I solved it:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">new</span>() -&gt; <span style="color:#a6e22e">YTMonitor</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> json_obj <span style="color:#f92672">=</span> render_cards::get_json_data();
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> image_handles <span style="color:#f92672">=</span> render_cards::get_all_avatars(<span style="color:#f92672">&amp;</span>json_obj);
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Because dark as default is cool :D
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    YTMonitor {
</span></span><span style="display:flex;"><span>        theme: <span style="color:#a6e22e">Theme</span>::Dark,
</span></span><span style="display:flex;"><span>        json_obj,
</span></span><span style="display:flex;"><span>        loaded_photos: <span style="color:#a6e22e">image_handles</span>,
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>As you can see above^, we have <code>json_obj, loaded_photos</code> as two added fields to the <code>YTMonitor</code> struct. We parsed the JSON file as well as downloaded all the avatars (we already know the avatar links from the JSON file). Later on, I would just use these as <code>self.json_obj</code> and <code>self.image_handles</code> in the <code>view</code> function, so no more performance degradation!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">view</span>(<span style="color:#f92672">&amp;</span>self) -&gt; <span style="color:#a6e22e">iced</span>::Element<span style="color:#f92672">&lt;</span>&#39;_, Self::Message<span style="color:#f92672">&gt;</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">let</span> all_cards <span style="color:#f92672">=</span> render_cards::create_list_of_cards(<span style="color:#f92672">&amp;</span>self.json_obj);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> binding <span style="color:#f92672">=</span> render_cards::ListOfCards::default();
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> all_photos <span style="color:#f92672">=</span> self.loaded_photos.to_owned();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> first_row <span style="color:#f92672">=</span>
</span></span><span style="display:flex;"><span>        render_cards::create_row(all_cards.get(<span style="color:#ae81ff">0</span>).unwrap_or(<span style="color:#f92672">&amp;</span>binding), <span style="color:#f92672">&amp;</span>all_photos, <span style="color:#ae81ff">0</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> second_row <span style="color:#f92672">=</span>
</span></span><span style="display:flex;"><span>        render_cards::create_row(all_cards.get(<span style="color:#ae81ff">1</span>).unwrap_or(<span style="color:#f92672">&amp;</span>binding), <span style="color:#f92672">&amp;</span>all_photos, <span style="color:#ae81ff">4</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> third_row <span style="color:#f92672">=</span>
</span></span><span style="display:flex;"><span>        render_cards::create_row(all_cards.get(<span style="color:#ae81ff">2</span>).unwrap_or(<span style="color:#f92672">&amp;</span>binding), <span style="color:#f92672">&amp;</span>all_photos, <span style="color:#ae81ff">8</span>);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>As you can see above, I am passing the <code>all_photos</code> variable to <code>create_row</code> this time (along with the offset). The <code>profile_pic</code> method just takes the image handle now:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">pub</span> <span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">profile_pic</span><span style="color:#f92672">&lt;</span><span style="color:#a6e22e">&#39;a</span><span style="color:#f92672">&gt;</span>(width: <span style="color:#66d9ef">u16</span>, img_handle: <span style="color:#a6e22e">image</span>::Handle) -&gt; <span style="color:#a6e22e">Container</span><span style="color:#f92672">&lt;</span><span style="color:#a6e22e">&#39;a</span>, Message<span style="color:#f92672">&gt;</span> {
</span></span><span style="display:flex;"><span>    container(
</span></span><span style="display:flex;"><span>        image(img_handle)
</span></span><span style="display:flex;"><span>            .height(Length::Units(width))
</span></span><span style="display:flex;"><span>            .width(Length::Units(width)),
</span></span><span style="display:flex;"><span>    )
</span></span><span style="display:flex;"><span>    .width(Length::Fill)
</span></span><span style="display:flex;"><span>    .center_x()
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>^^ This makes it much faster now! And yes, it did solve the problem. While doing this, of course, I learnt a lot of Rust, and Iced. So many things to learn, and I&rsquo;m already enjoying the challenges.</p>
<p>I know this doesn&rsquo;t look the best yet, there are so many good apps out there built on the top of Iced, but I&rsquo;m getting started. Once this is done, I know at least - I - would love it. ‚ù§Ô∏è</p>
<p>Here is how the app looks like, right now (featuring my friend Mohit Wankhade üòÉ):</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/rust_app_stage_fourth.png" alt="Stage - 4"></p>
<p>We aren&rsquo;t done yet by the way, I have to cover some macros I built, but I&rsquo;ll keep it for my next blog. Until then, I hope you continue grinding whatever you love, and make the best out of the time you have. Take care, and thank you for being here. üíó</p>
]]></content>
        </item>
        
        <item>
            <title>Daily Update: 19th 20th 21st November 2022 - Day 5 to Day 7 (inclusive)</title>
            <link>https://krshrimali.github.io/posts/2022/11/daily-update-19th-20th-21st-november-2022-day-5-to-day-7-inclusive/</link>
            <pubDate>Mon, 21 Nov 2022 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2022/11/daily-update-19th-20th-21st-november-2022-day-5-to-day-7-inclusive/</guid>
            <description>Hi everyone! Sorry for missing out on publishing individual blogs for 19th, 20th and 21st November, but it has been very hectic for me, and I decided to give leetcode a break and explore System Design (a lot). Turns out, I had some idea about it already, one of the advantages of working with startups (CareAI/Dukaan). But in any case, quite a few interesting things I learnt. I can&amp;rsquo;t share all the links, as it will be just better to share the playlists or YT channels I referred:</description>
            <content type="html"><![CDATA[<p>Hi everyone! Sorry for missing out on publishing individual blogs for 19th, 20th and 21st November, but it has been very hectic for me, and I decided to give leetcode a break and explore System Design (a lot). Turns out, I had some idea about it already, one of the advantages of working with startups (CareAI/Dukaan). But in any case, quite a few interesting things I learnt. I can&rsquo;t share all the links, as it will be just better to share the playlists or YT channels I referred:</p>
<ol>
<li><a href="https://www.youtube.com/playlist?list=PLMCXHnjXnTnvo6alSjVkgxV-VH6EPyvoX">System Design Playlist from Gaurav Sen</a> - I didn&rsquo;t watch every single video, but about Consistent Hashing and Database Sharing were quite helpful.</li>
<li><a href="https://www.youtube.com/watch?v=o5n85GRKuzk">Design Twitter - System Design Interview from NeetCode</a> - NeetCode is one of my favorite content creators in the tech on YT, always on point, no nonsense.</li>
<li><a href="https://www.youtube.com/watch?v=PuU_0esYyhg">System Design Interview: Design Amazon Prime Video from Exponent</a></li>
<li><a href="https://www.youtube.com/@SystemDesignInterview">System Design Interview Channel</a> - Not active anymore, but whatever videos he has are really good.</li>
<li><a href="https://www.youtube.com/watch?v=ZS_kXvOeQ5Y">SQL vs NoSQL or MySQL vs MongoDB from Academind</a> - I got this question from NeetCode&rsquo;s video on his design choice to use SQL, so this got me interested (NoSQL vs SQL).</li>
</ol>
<p>Reading about Kafka, Apache Hadoop MapReduce vs Apache Spark was also helpful. I intend to use them more to understand their implementation details. Personally, using and managing load balancers for horizontal scaling is also interesting.</p>
<p>I&rsquo;ll have more to share in the coming days, until then - take care! :)</p>
]]></content>
        </item>
        
        <item>
            <title>Daily Update: 18th November 2022 - Day 5</title>
            <link>https://krshrimali.github.io/posts/2022/11/daily-update-18th-november-2022-day-5/</link>
            <pubDate>Fri, 18 Nov 2022 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2022/11/daily-update-18th-november-2022-day-5/</guid>
            <description>Hi everyone, Day 5 of this series of daily updates. Started my day, fairly early but was feeling unwell. In any case, I did make some progress with my learning of the Interpreter. One of motivation to learn about Interpreter is to learn the whole process, from the code we write to the object files / executables. Of course, in this goal, my next step would be to read the &amp;ldquo;Write a compiler in Go&amp;rdquo; book.</description>
            <content type="html"><![CDATA[<p>Hi everyone, Day 5 of this series of daily updates. Started my day, fairly early but was feeling unwell. In any case, I did make some progress with my learning of the Interpreter. One of motivation to learn about Interpreter is to learn the whole process, from the code we write to the object files / executables. Of course, in this goal, my next step would be to read the &ldquo;Write a compiler in Go&rdquo; book. But one step at a time, right?</p>
<p><strong>Projects/Learning</strong>:</p>
<ol>
<li>Completed Chapter 1 (Lexing) of the book &ldquo;Write an Interpreter in Go&rdquo;. Very detailed, and I love how the author included REPL in the chapter 1. Even though it&rsquo;s not a lot of code, it just makes it so intuitive to run line by line and get the tokens.</li>
<li>Started reading Chapter 2 (Parser). Fortunately, I do have some knowledge about grammars, BNF and EBNF forms, and using parser generators. But I agree with the author there, you&rsquo;ll learn a lot if you create the parser from scratch. So I&rsquo;m looking forward to it.</li>
</ol>
<p><strong>Leetcode</strong>:</p>
<p>Revisit most of the problems I&rsquo;ve solved so far. Implement them again in C++ and Rust.</p>
<p>Thank you! :)</p>
]]></content>
        </item>
        
        <item>
            <title>Daily Update: 17th November 2022 - Day 4</title>
            <link>https://krshrimali.github.io/posts/2022/11/daily-update-17th-november-2022-day-4/</link>
            <pubDate>Thu, 17 Nov 2022 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2022/11/daily-update-17th-november-2022-day-4/</guid>
            <description>Hi everyone, Day 4 of this series of daily updates. I don&amp;rsquo;t have a lot to share today, just one of those days where I spent a lot of time going through whatever I&amp;rsquo;ve done already. I take some time to look at the things I learned so far, and see if I could be more intuitive back then. I&amp;rsquo;m going to continue doing the same for the next day, though this time for the problems I&amp;rsquo;ve solved on Leetcode.</description>
            <content type="html"><![CDATA[<p>Hi everyone, Day 4 of this series of daily updates. I don&rsquo;t have a lot to share today, just one of those days where I spent a lot of time going through whatever I&rsquo;ve done already. I take some time to look at the things I learned so far, and see if I could be more intuitive back then. I&rsquo;m going to continue doing the same for the next day, though this time for the problems I&rsquo;ve solved on Leetcode.</p>
<p><strong>Projects/Learning</strong>:</p>
<ol>
<li>Studied a bit about MapReduce algorithm. Surprisingly, there isn&rsquo;t enough about it, except blogs like <a href="https://www.ibm.com/in-en/topics/mapreduce#:~:text=MapReduce%20is%20a%20programming%20paradigm,tasks%20that%20Hadoop%20programs%20perform.">this from IBM</a> sharing the same old definitions and examples.</li>
<li>Spent some time going through possibilities of handwritten recognition using Stable Diffusion, I think it&rsquo;s an interesting area to explore. Autoencoders can do a good job here, and with the amount of data we can generate for this task - it could be huge.</li>
</ol>
<p>Thank you! :)</p>
]]></content>
        </item>
        
        <item>
            <title>Daily Update: 16th November 2022 - Day 3</title>
            <link>https://krshrimali.github.io/posts/2022/11/daily-update-16th-november-2022-day-3/</link>
            <pubDate>Wed, 16 Nov 2022 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2022/11/daily-update-16th-november-2022-day-3/</guid>
            <description>Hi everyone, Day 3 of this series of daily updates. Woke up fairly early (~6 AM), and started working. Though it seemed productive to me, but you won&amp;rsquo;t see a lot of content here today - just one of those days where I didn&amp;rsquo;t do a lot of different things, I guess. :)
Projects/Learning:
I made my rust-leetcode repository public today. It currently contains 12 solved problems, you&amp;rsquo;ll see huge difference between the first few codes to the last few codes.</description>
            <content type="html"><![CDATA[<p>Hi everyone, Day 3 of this series of daily updates. Woke up fairly early (~6 AM), and started working. Though it seemed productive to me, but you won&rsquo;t see a lot of content here today - just one of those days where I didn&rsquo;t do a lot of different things, I guess. :)</p>
<p><strong>Projects/Learning</strong>:</p>
<ol>
<li>I made my <a href="https://github.com/krshrimali/rust-leetcode/">rust-leetcode</a> repository public today. It currently contains 12 solved problems, you&rsquo;ll see huge difference between the first few codes to the last few codes. I&rsquo;ve been learning, please don&rsquo;t refer it for learning. I&rsquo;m just documenting it there.</li>
<li>Autogenerate README once a new file is added to my Rust Leetcode repository:</li>
</ol>
<ul>
<li>I first started with writing a Python script to auto-generate the <code>README.md</code> file, from the modules registered in the <code>src/lib.rs</code>. The script is <a href="https://github.com/krshrimali/rust-leetcode/blob/main/update_readme.py">here</a>.</li>
<li>Since I wanted to explore how it can be done in Rust, I ported it to Rust as well. The script is <a href="https://github.com/krshrimali/rust-leetcode/blob/main/src/main.rs">here</a>.</li>
</ul>
<p>Took some break from doing leetcode today, had a lot of work which I unfortunately can&rsquo;t mention here.</p>
]]></content>
        </item>
        
        <item>
            <title>Daily Update: 15th November 2022 - Day 2</title>
            <link>https://krshrimali.github.io/posts/2022/11/daily-update-15th-november-2022-day-2/</link>
            <pubDate>Tue, 15 Nov 2022 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2022/11/daily-update-15th-november-2022-day-2/</guid>
            <description>Hi everyone, Day 2 of this series of daily updates. Started my day earlier than yesterday, at around 9 AM (work).
Learning:
Watched this nice video from Jason on The Right Way to Write C++ in 2022: I like when he advocated on using different compilers, or at least verifying that it works for all (and if not, then you&amp;rsquo;re aware). Interest: take warnings seriously. Need to start doing it, I&amp;rsquo;ve been following this with Rust, but C++ never raised Rust-like &amp;ldquo;good enough&amp;rdquo; warnings.</description>
            <content type="html"><![CDATA[<p>Hi everyone, Day 2 of this series of daily updates. Started my day earlier than yesterday, at around 9 AM (work).</p>
<p><strong>Learning</strong>:</p>
<ul>
<li>Watched this nice video from Jason on <a href="https://www.youtube.com/watch?v=q7Gv4J3FyYE">The Right Way to Write C++ in 2022</a>:
<ul>
<li>I like when he advocated on using different compilers, or at least verifying that it works for all (and if not, then you&rsquo;re aware).</li>
<li>Interest: take warnings seriously. Need to start doing it, I&rsquo;ve been following this with Rust, but C++ never raised Rust-like &ldquo;good enough&rdquo; warnings. Might as well start doing it now.</li>
<li>Code coverage analysis: hmm, it used to stay at around 87 to 90% for the libraries I worked with. I agree, most of it should be tested, but as the library grows longer, you can&rsquo;t block PRs on coverage (specially by the community). But it&rsquo;s underrated, I&rsquo;ve seen developers ignore it until they face the wrath of weird bugs. 100% testing coverage, will always be difficult, but if the goal is kept in that direction, it might reach to 95-100%.</li>
<li>Never heard of fuzz testing before&hellip;after reading about it, just another word of what we have done before. Never got a name to it though. ;)</li>
<li>Ship with Hardening Enabled: Again, no idea about this. I&rsquo;ll have to read about it. Marked as a TODO.</li>
</ul>
</li>
<li>Missed watching Edward&rsquo;s stream on TorchDynamo, I woke up late. :/ Going to re-watch the stream now. I&rsquo;ll share the notes in a separate blog once I&rsquo;m done, I could only watch <em>some</em> of it today.</li>
<li>I&rsquo;ve started learning Kernel Fusion, how does it work and why it can help (and when it can not). This is going to be a long road, hopefully I&rsquo;ll be able to share something concrete soon.</li>
</ul>
<p><strong>Leetcode Problems</strong>:</p>
<ul>
<li><a href="https://leetcode.com/problems/longest-substring-without-repeating-characters">Longest substring without repeating characters</a></li>
<li><a href="https://leetcode.com/problems/clone-graph">Clone graph</a>
<ul>
<li>Note: this was done in C++, Leetcode didn&rsquo;t have Rust added as the supported language for this.</li>
</ul>
</li>
<li><a href="https://leetcode.com/problems/product-of-array-except-self/">Product of Array Except Self</a>
I&rsquo;m still learning Rust, so it takes some time for me to write the <em>best</em> Rust versions of the codes above, but yeah - doing it the best way I can. I don&rsquo;t want to rush completing tens of problems in a day, to me - that doesn&rsquo;t make sense.</li>
</ul>
<h2 id="ending-words">Ending Words</h2>
<p>Felt better as I am slowly collecting myself together. It&rsquo;s going to take some time though, but I aim to be consistent with the things I love doing.</p>
]]></content>
        </item>
        
        <item>
            <title>Daily Update: 14th November 2022 - Day 1</title>
            <link>https://krshrimali.github.io/posts/2022/11/daily-update-14th-november-2022-day-1/</link>
            <pubDate>Mon, 14 Nov 2022 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2022/11/daily-update-14th-november-2022-day-1/</guid>
            <description>Hi everyone, I&amp;rsquo;m back to - writing daily update blogs. Just sharing what I did today, and documenting my progress. Now of course it won&amp;rsquo;t contain everything I do, but yep - everything related to learning and things I&amp;rsquo;m passionate about.
Reading
Just In Time Compilation (Wiki): Wiki: https://en.wikipedia.org/wiki/Just-in-time_compilation Honestly, I wanted to start with a few papers on it, but Wikipedia does give enough background and sets some context. Leetcode problems</description>
            <content type="html"><![CDATA[<p>Hi everyone, I&rsquo;m back to - writing daily update blogs. Just sharing what I did today, and documenting my progress. Now of course it won&rsquo;t contain everything I do, but yep - everything related to learning and things I&rsquo;m passionate about.</p>
<p><strong>Reading</strong></p>
<ul>
<li>Just In Time Compilation (Wiki):
<ul>
<li>Wiki: <a href="https://en.wikipedia.org/wiki/Just-in-time_compilation">https://en.wikipedia.org/wiki/Just-in-time_compilation</a></li>
<li>Honestly, I wanted to start with a few papers on it, but Wikipedia does give enough background and sets some context.</li>
</ul>
</li>
</ul>
<p><strong>Leetcode problems</strong></p>
<p>For some context, I started doing these problems to brush up my problem solving skills. The following problems were solved in both Rust and C++. I&rsquo;ll share the rust codes in a few days.</p>
<ul>
<li><a href="https://leetcode.com/problems/k-closest-points-to-origin/">K Closest Points to the origin</a></li>
<li><a href="https://leetcode.com/problems/jump-game/">Jump Game</a></li>
<li><a href="https://leetcode.com/problems/jump-game-ii/">Jump Game - II</a></li>
</ul>
<p><strong>Miscellaneous</strong></p>
<ul>
<li>Spent some time fixing my colorscheme in neovim changing because of tmux :/ I was wondering what went wrong. Finally, I found this: <a href="https://stackoverflow.com/questions/60309665/neovim-losing-colorscheme-when-in-tmux-all-past-solutions-i-see-dont-work-for">neovim losing colorscheme when in tmux</a>. I&rsquo;ve updated my <a href="https://github.com/krshrimali/dotfiles">dotfiles</a> with the fix in case anyone is still using it.</li>
</ul>
<p><strong>Ending words</strong></p>
<p>Still starting off with the momentum. Going to take some time, but I hope to continue doing it.</p>
]]></content>
        </item>
        
        <item>
            <title>Applying for Research Internships (Universities)</title>
            <link>https://krshrimali.github.io/posts/2022/09/applying-for-research-internships-universities/</link>
            <pubDate>Sun, 04 Sep 2022 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2022/09/applying-for-research-internships-universities/</guid>
            <description>Hi everyone! Over the last few months, I&amp;rsquo;ve received a lot of queries regarding applying to research internships. And I wanted to answer them shortly, in this blog, with a disclaimer to begin with.
DISCLAIMER
I did only one research internship (NTU Singapore, ROSE Labs), and there are people who are more qualified than me to answer this, but I&amp;rsquo;ll make my best attempt.
Here is how I will suggest to apply:</description>
            <content type="html"><![CDATA[<p>Hi everyone! Over the last few months, I&rsquo;ve received a lot of queries regarding applying to research internships. And I wanted to answer them shortly, in this blog, with a disclaimer to begin with.</p>
<p><strong>DISCLAIMER</strong></p>
<p>I did only one research internship (NTU Singapore, ROSE Labs), and there are people who are more qualified than me to answer this, but I&rsquo;ll make my best attempt.</p>
<p>Here is how I will suggest to apply:</p>
<h2 id="assumptions">Assumptions</h2>
<ol>
<li>You are interested in Research.</li>
<li>You are not doing a research internship because you think getting into an industry is really tough, and emailing a professor will be easier.</li>
<li>You know what field excites you, not necessarily &ldquo;your passion&rdquo; - but still your interests.</li>
<li>You read papers in some frequency. (can be anything, I am too much a developer to comment on this üòÑ)</li>
<li>You have your work hosted somewhere, for others to see and judge! ;)</li>
</ol>
<h2 id="process">Process</h2>
<p><strong>Gather information:</strong></p>
<ol>
<li>Find the research papers that interested you the most.</li>
</ol>
<ul>
<li>Take a note of the authors, and co-authors.</li>
<li>Take a note of the institutes that funded this research.</li>
<li>Take a note of their timezone.</li>
<li>Does the author work in a lab? Take a note of that lab.</li>
</ul>
<ol start="2">
<li>Find the institutes that offer research internships (preferably paid). Not all of them do, but most of the times - professors have some funds.</li>
</ol>
<ul>
<li>Can be outside India.</li>
<li>Prefer institutes with good labs for your field over the best institutes with absolutely no active labs for your interests.</li>
</ul>
<p><strong>Review</strong></p>
<ol>
<li>Check if the professors/institutes have openings in their labs? Most of the times, their home page will tell you about the status.</li>
<li>Sometimes, Post Docs are also active in interviewing research interns, so it doesn&rsquo;t have to be all about professors/institutes.</li>
<li>What is the field of interest of the person? Is it something that aligns with you (you may not know in the first glance, but if you are excited about what they do&hellip; then the answer is yes!)?</li>
<li>Note that: for labs, a lot of times they pair with industries and other academic institutions</li>
</ol>
<p><strong>Reach Out</strong></p>
<p><em>Assuming that the Review process is followed thoroughly</em></p>
<ol>
<li>Email the profs/post docs/researchers:</li>
</ol>
<ul>
<li>Try scheduling emails in their mornings, worst case: their time zones.</li>
<li>Mention the research you&rsquo;ve done about their work.</li>
<li>Mention any relevant papers you&rsquo;ve written (or read from their work, and share any feedback -&gt; only honest feedback, please don&rsquo;t write random things).</li>
<li>Talk to them about how you can contribute, if you don&rsquo;t have an idea on this - let them know about what you&rsquo;ve done so far.</li>
<li>Keep it brief.</li>
</ul>
<ol start="2">
<li>Wait for a few weeks.</li>
<li>Gentle ping, in case they haven&rsquo;t gotten back to you.</li>
<li>If they didn&rsquo;t, it&rsquo;s okay.‚ù§Ô∏è There is a lot to explore, keep doing your work!</li>
</ol>
<h2 id="a-suggestion">A suggestion</h2>
<p>This process changes over time, depends on the labs, I tried my best to share the generalized version of it. However, remember that if you are honest to the work you do -&gt; people will eventually recognize your talent, and you&rsquo;ll get the opportunities you ever needed. Have patience, and enjoy the work.</p>
<p>Hope it helps you all. Thank you!</p>
]]></content>
        </item>
        
        <item>
            <title>Porting a Tiling Window Manager Extenstion to C&#43;&#43; (Bismuth): Part-2 (getting closest relative window)</title>
            <link>https://krshrimali.github.io/posts/2022/07/porting-a-tiling-window-manager-extenstion-to-c-bismuth-part-2-getting-closest-relative-window/</link>
            <pubDate>Sun, 31 Jul 2022 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2022/07/porting-a-tiling-window-manager-extenstion-to-c-bismuth-part-2-getting-closest-relative-window/</guid>
            <description>Hi everyone! In this blog, I will be discussing the algorithm used in Bismuth to find the closest relative window to be focused for focusWindowByDirection event. If you haven&amp;rsquo;t read the previous blog, make sure to give it a read here.
Recap from the previous blog Let&amp;rsquo;s start with a quick recap though, in the previous blog, we discussed:
focusWindowByDirection requires the following information:
direction (from the user) - can be one of: right, left, top/up, bottom/down.</description>
            <content type="html"><![CDATA[<p>Hi everyone! In this blog, I will be discussing the algorithm used in Bismuth to find the closest relative window to be focused for <code>focusWindowByDirection</code> event. If you haven&rsquo;t read the previous blog, make sure to give it a read <a href="https://krshrimali.github.io/posts/2022/07/porting-a-tiling-window-manager-extenstion-to-c-bismuth-part-1/">here</a>.</p>
<h2 id="recap-from-the-previous-blog">Recap from the previous blog</h2>
<p>Let&rsquo;s start with a quick recap though, in the previous blog, we discussed:</p>
<p><code>focusWindowByDirection</code> requires the following information:</p>
<ul>
<li><code>direction</code> (from the user) - can be one of: <code>right, left, top/up, bottom/down</code>.</li>
<li><code>activeWindow</code> (from the current session) - this is needed since <code>focusWindowByDirection</code> event is a <em>relative</em> event to your current focused window.</li>
<li>Neighbor window candidates (<code>neighborCandidates</code>) to your current window (<code>activeWindow</code>) and the given direction (<code>direction</code>).</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// declaration
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span>Window<span style="color:#f92672">&gt;</span> Engine<span style="color:#f92672">::</span>getNeighborCandidates(<span style="color:#66d9ef">const</span> FocusDirection <span style="color:#f92672">&amp;</span>direction, <span style="color:#66d9ef">const</span> Window <span style="color:#f92672">&amp;</span>basisWindow);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// use
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span>Window<span style="color:#f92672">&gt;</span> neighborCandidates <span style="color:#f92672">=</span> getNeighborCandidates(direction, basisWindow);
</span></span></code></pre></div><ul>
<li>From these neighbor candidates (<code>neighborCandidates</code>), we will now find the closest relative window corner. To me, it was tricky to understand at first, so we&rsquo;ll be discussing this in detail over in the later sections.</li>
<li>Once we know the closest relative window corner, we&rsquo;ll try to find the window which satisfies the corner condition.</li>
<li>If there were multiple found, we&rsquo;ll return the first one based on the time-stamp (last used)</li>
</ul>
<h2 id="understanding-the-scenario">Understanding the scenario</h2>
<p>I want to start off with a visual, took me some time to draw it, but in case it doesn&rsquo;t look good, I&rsquo;m sorry! My drawing teacher in the high school tried his best, but&hellip;</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/bismuth-part-2-window-alignment.png" alt=""></p>
<p>Above image is visual of a tiling window layout where there are in total 5 windows opened (just for imagination, no sane person would open these many windows on a 24 inch monitor&hellip; xD): <code>A, B, C, D, E</code>, where as mentioned in the figure above, <code>E</code> is the active window and we are trying to focus <code>UP</code>. A few notes to take from the figure:</p>
<ol>
<li><code>A, B, C, D</code> windows are of same height and width <code>w</code> and <code>h</code>. We&rsquo;ll use this information later.</li>
<li><code>E</code> window is the active window with width: <code>2 * w</code> and height: <code>h</code>.</li>
<li>We are trying to focus <code>UP</code>.</li>
</ol>
<h2 id="getting-closest-relative-window-corner">Getting Closest Relative Window Corner</h2>
<p>In the <a href="https://krshrimali.github.io/posts/2022/07/porting-a-tiling-window-manager-extenstion-to-c-bismuth-part-1/">previous blog</a>, we had covered <code>getNeighborCandidates</code>, the output here would be windows: <code>A, B, C, D</code>. The order will not matter here for understanding, so don&rsquo;t worry about that.</p>
<p>The next steps in the code include:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">int</span> closestRelativeWindowCorner <span style="color:#f92672">=</span> getClosestRelativeWindowCorner(direction, neighborCandidates);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> closestWindows <span style="color:#f92672">=</span> getClosestRelativeWindow(direction, neighborCandidates, getClosestRelativeWindow);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> <span style="color:#a6e22e">most_recently_used</span>(closestWindows);
</span></span></code></pre></div><p>I didn&rsquo;t add comments here, because we&rsquo;ll be going through these 2 magic functions below. Let&rsquo;s start with <code>getClosestRelativeWindowCorner</code>. The source code for the definition of this function is:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">int</span> Engine<span style="color:#f92672">::</span>getClosestRelativeWindowCorner(<span style="color:#66d9ef">const</span> Engine<span style="color:#f92672">::</span>FocusDirection <span style="color:#f92672">&amp;</span>direction, <span style="color:#66d9ef">const</span> std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span>Window<span style="color:#f92672">&gt;</span> <span style="color:#f92672">&amp;</span>neighbors)
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> std<span style="color:#f92672">::</span>reduce(neighbors.cbegin(),
</span></span><span style="display:flex;"><span>                       neighbors.cend(),
</span></span><span style="display:flex;"><span>                       <span style="color:#75715e">/* initial value */</span> direction <span style="color:#f92672">==</span> Engine<span style="color:#f92672">::</span>FocusDirection<span style="color:#f92672">::</span>Up <span style="color:#f92672">||</span> direction <span style="color:#f92672">==</span> Engine<span style="color:#f92672">::</span>FocusDirection<span style="color:#f92672">::</span>Left <span style="color:#f92672">?</span> <span style="color:#ae81ff">0</span> <span style="color:#f92672">:</span> INT_MAX,
</span></span><span style="display:flex;"><span>                       [<span style="color:#f92672">&amp;</span>](<span style="color:#66d9ef">int</span> prevValue, <span style="color:#66d9ef">const</span> Window <span style="color:#f92672">&amp;</span>window) {
</span></span><span style="display:flex;"><span>                           <span style="color:#66d9ef">switch</span> (direction) {
</span></span><span style="display:flex;"><span>                           <span style="color:#66d9ef">case</span> Engine<span style="color:#f92672">::</span>FocusDirection<span style="color:#f92672">::</span>Up:
</span></span><span style="display:flex;"><span>                               <span style="color:#66d9ef">return</span> std<span style="color:#f92672">::</span>max(window.geometry().bottom(), prevValue);
</span></span><span style="display:flex;"><span>                           <span style="color:#66d9ef">case</span> Engine<span style="color:#f92672">::</span>FocusDirection<span style="color:#f92672">::</span>Down:
</span></span><span style="display:flex;"><span>                               <span style="color:#66d9ef">return</span> std<span style="color:#f92672">::</span>min(window.geometry().y(), prevValue);
</span></span><span style="display:flex;"><span>                           <span style="color:#66d9ef">case</span> Engine<span style="color:#f92672">::</span>FocusDirection<span style="color:#f92672">::</span>Left:
</span></span><span style="display:flex;"><span>                               <span style="color:#66d9ef">return</span> std<span style="color:#f92672">::</span>max(window.geometry().right(), prevValue);
</span></span><span style="display:flex;"><span>                           <span style="color:#66d9ef">case</span> Engine<span style="color:#f92672">::</span>FocusDirection<span style="color:#f92672">::</span>Right:
</span></span><span style="display:flex;"><span>                               <span style="color:#66d9ef">return</span> std<span style="color:#f92672">::</span>min(window.geometry().x(), prevValue);
</span></span><span style="display:flex;"><span>                           }
</span></span><span style="display:flex;"><span>                       });
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Don&rsquo;t worry about the code if it confuses you, keep in mind that we have the direction as <code>Engine::FocusDirection::Up</code>, and <code>neighbors</code> as <code>{A, B, C, D}</code>. This function gets you the closest window corner relative to the active window or the basis window. How would you do that? Well, it will depend on the direction.</p>
<p>If the direction is <code>Up</code> or <code>Down</code> &ndash;&gt; you should compare the <code>y</code> coordinate.
If the direction is <code>Left</code> or <code>Right</code> &ndash;&gt; you should compare the <code>x</code> coordinate.</p>
<p>Now remember the mathematics lectures you had way back in the high school, if you wanna focus up, which vertex do you really care about? Keep your focus on the window C and E for once, the comparison should definitely be with the bottom right&rsquo;s y coordinate, right? That&rsquo;s what we do here:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">case</span> Engine<span style="color:#f92672">::</span>FocusDirection<span style="color:#f92672">::</span>Up: 
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> std<span style="color:#f92672">::</span>max(window.geometry().bottom(), prevValue);
</span></span></code></pre></div><p>A quick look at <code>bottom()</code> source code in <code>qrect.h</code> file:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>Q_DECL_CONSTEXPR <span style="color:#66d9ef">inline</span> QRect<span style="color:#f92672">::</span>bottom() <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">noexcept</span> { <span style="color:#66d9ef">return</span> y2; }
</span></span></code></pre></div><p>Where <code>y2</code> is the bottom right&rsquo;s y coordinate. Since we are going up, and anything above the basis window should have <code>y</code> value &lt; basis window&rsquo;s <code>y</code> value. (The top left of any screen is considered to be <code>(0, 0)</code> in this blog). Hence we set the initial value as <code>0</code>. If we had to go down, we&rsquo;ll set it to <code>INT_MAX</code> as for anything below the basis window, we&rsquo;ll use <code>std::min</code> and hence <code>INT_MAX</code> will fade away with each neighbor window.</p>
<p>Anyways, enough of theory, so what will be the output of this function for our scenario? Well, this function will give us <code>y_C + h</code> (which is equal to <code>y_D + h</code>, so any of them is fine). Now, we&rsquo;ll go ahead to the next function.</p>
<h2 id="getting-closest-relative-window">Getting Closest Relative Window</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span>Window<span style="color:#f92672">&gt;</span> getClosestRelativeWindow(<span style="color:#66d9ef">const</span> Engine<span style="color:#f92672">::</span>FocusDirection <span style="color:#f92672">&amp;</span>direction, <span style="color:#66d9ef">const</span> std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span>Window<span style="color:#f92672">&gt;</span> <span style="color:#f92672">&amp;</span>windowArray, <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">int</span> <span style="color:#f92672">&amp;</span>closestPoint)
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span>Window<span style="color:#f92672">&gt;</span> result;
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>copy_if(windowArray.cbegin(), windowArray.cend(), result.begin(), [<span style="color:#f92672">&amp;</span>](<span style="color:#66d9ef">const</span> Window <span style="color:#f92672">&amp;</span>window) {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">switch</span> (direction) {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">case</span> Engine<span style="color:#f92672">::</span>FocusDirection<span style="color:#f92672">::</span>Up:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> window.geometry().bottom() <span style="color:#f92672">&gt;</span> closestPoint <span style="color:#f92672">-</span> <span style="color:#ae81ff">5</span>;
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">case</span> Engine<span style="color:#f92672">::</span>FocusDirection<span style="color:#f92672">::</span>Down:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> window.geometry().y() <span style="color:#f92672">&lt;</span> closestPoint <span style="color:#f92672">+</span> <span style="color:#ae81ff">5</span>;
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">case</span> Engine<span style="color:#f92672">::</span>FocusDirection<span style="color:#f92672">::</span>Left:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> window.geometry().right() <span style="color:#f92672">&gt;</span> closestPoint <span style="color:#f92672">-</span> <span style="color:#ae81ff">5</span>;
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">case</span> Engine<span style="color:#f92672">::</span>FocusDirection<span style="color:#f92672">::</span>Right:
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> window.geometry().x() <span style="color:#f92672">&lt;</span> closestPoint <span style="color:#f92672">+</span> <span style="color:#ae81ff">5</span>;
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    });
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> result;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Again, remember, we have <code>direction</code> as <code>Engine::FocusDirection::Up</code>, <code>windowArray</code> as <code>{A, B, C, D}</code>, and <code>closestPoint</code> as <code>y_C + h</code> value.</p>
<p>This function only exists to give you <em>all the windows</em> which are <em>close enough</em> to the <code>closestPoint</code>. The output out of this function will be windows <code>C, D</code> (reminder: <code>E</code> is the basis or active window).</p>
<p>Some will wonder why do we have two functions: <code>getClosestRelativeWindowCorner</code>, and <code>getClosestRelativeWindow</code>? And why this <code>-5, +5</code>? Unfortunately, it&rsquo;s possible that some windows aren&rsquo;t tiled properly, see <a href="https://github.com/Bismuth-Forge/bismuth/issues/102">this</a> issue. I&rsquo;ve attached the screenshot: (credits to the author)</p>
<p><img src="https://user-images.githubusercontent.com/13597663/136797590-9c525224-6421-4384-ad42-4de54a814cb2.png" alt=""></p>
<p>Hence we can&rsquo;t be too strict here. I personally believe this number <code>+/- 5</code> should be tinkered better and not hard-coded, but that&rsquo;s for later.</p>
<p>So from <code>A, B, C, D</code> being the <em>neighbor candidates</em>, we have <code>C, D</code> as the final <em>closest windows</em> to the basis window (<code>E</code>). Now which one to choose? That&rsquo;s where we&rsquo;ll have to store the timestamps for each window. And this timestamp should record the last time it was used or accessed. We just get the most recently used out of these windows, and I&rsquo;ll be discussing in the future blogs. I think we discussed a lot today. So that should be it&hellip;</p>
<h2 id="acknowledgement">Acknowledgement</h2>
<p>I don&rsquo;t want to shy away from thanking the main maintainer of Bismuth, <a href="https://github.com/gikari">gikari</a> who has worked pro-actively on Bismuth. Of course, the credits should also go to <a href="https://github.com/esjeon/krohnkite">krohnkite</a> for the hard work they put in.</p>
<p>In case anyone has a feedback or suggestion, please leave a comment on this blog. I wish everyone good health and success. Thanks for reading &lt;3</p>
]]></content>
        </item>
        
        <item>
            <title>Porting a Tiling Window Manager Extenstion to C&#43;&#43; (Bismuth): Part-1</title>
            <link>https://krshrimali.github.io/posts/2022/07/porting-a-tiling-window-manager-extenstion-to-c-bismuth-part-1/</link>
            <pubDate>Sat, 23 Jul 2022 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2022/07/porting-a-tiling-window-manager-extenstion-to-c-bismuth-part-1/</guid>
            <description>Hi everyone! I understand it&amp;rsquo;s been a long time, and I&amp;rsquo;m so excited to be writing this blog today. In today&amp;rsquo;s blog, I wanted to talk about my journey (so far) on contributing to Bismuth (a KDE&amp;rsquo;s Tiling Window Manager Extension), mainly how and why I started, and where I am right now.
The Story: Why KDE Plasma and Why Bismuth? For the last few months (close to a year), I&amp;rsquo;ve been using Pop OS (a linux distribution by System 76) which had this amazing automatic tiling window extension called pop-shell, and it was close to what I always needed:</description>
            <content type="html"><![CDATA[<p>Hi everyone! I understand it&rsquo;s been a long time, and I&rsquo;m so excited to be writing this blog today. In today&rsquo;s blog, I wanted to talk about my journey (so far) on contributing to <a href="https://github.com/Bismuth-Forge/bismuth/">Bismuth (a KDE&rsquo;s Tiling Window Manager Extension)</a>, mainly how and why I started, and where I am right now.</p>
<h2 id="the-story-why-kde-plasma-and-why-bismuth">The Story: Why KDE Plasma and Why Bismuth?</h2>
<p>For the last few months (close to a year), I&rsquo;ve been using Pop OS (a linux distribution by System 76) which had this amazing automatic tiling window extension called <a href="https://github.com/pop-os/shell"><code>pop-shell</code></a>, and it was close to what I always needed:</p>
<ol>
<li>Tiling.</li>
<li>A desktop environment.</li>
<li>Ability to configure keyboard shortcuts.</li>
<li>Ability to turn-off tiling to floating.</li>
<li>An option to launch specific windows as floating windows. (example: Steam)</li>
<li>An active community to seek help or suggestions from.</li>
<li>Open-Sourced!</li>
</ol>
<p>Now some would say that there is a possibility to install tiling window managers on desktop environments (I&rsquo;m aware <a href="https://github.com/heckelson/i3-and-kde-plasma">i3 on KDE Plasma</a>), but that just felt&hellip; <em>odd</em> for some reason. So I stuck with Pop OS, until <a href="https://github.com/pop-os/shell/issues/1470">this happened</a>, oh and also <a href="https://github.com/pop-os/pop/issues/2444">this</a>. The second issue where there was a lag while dragging windows, was unfortunately not a Pop OS bug but was mostly related to upstream (mutter if I&rsquo;m not wrong). And when they say that it only happened with NVIDIA drivers, I knew that it&rsquo;s something that will probably take some time to resolve (I would rather prefer not to get into the details here).</p>
<p>That&rsquo;s when I decided to explore KDE Plasma. KDE Plasma 5.25 was just announced, and oh man - it seemed to have impressed a lot of people out there. However, what impressed me the most was that it had no such issues with NVIDIA drivers, at least no lag while dragging windows. I also liked their zoom accessibility feature, much much much better than what GNOME had. Needless to say, that I had decided to stick to KDE Plasma after that.</p>
<p>Just to give some context, I use multiple monitors and while people happily survive without a tiling window manager, I was the opposite - I felt the need of tiling, specially when I started streaming or sharing my work with others. And then I saw <a href="https://www.youtube.com/watch?v=TQzaDrmsE9A">this video: &ldquo;TILING comes to KDE Kwin? ;)&rdquo;</a>! I was wow-ed (is that a word BTW?). I was introduced to this amazing KDE Tiling Window Manager Extension named <strong>Bismuth</strong> (<a href="https://github.com/Bismuth-Forge/bismuth/)">https://github.com/Bismuth-Forge/bismuth/)</a>. I didn&rsquo;t waste any time in installing and setting up the extension on my machine&hellip;</p>
<h2 id="the-motivation-why-contribute">The Motivation: Why contribute?</h2>
<p>Of course, with great power comes great responsibility, and in the Linux ecosystem, <em>with more users, comes more bugs</em>. The same happened with Bismuth, lots of users started trying it, and it had good amount of issues, interestingly, less were bugs and more were about features. However, I got stuck with one of the most important feature I needed, and it was &ldquo;Move window to the next/previous screen/monitor&rdquo; with a keyboard-shortcut. Now, do note that Bismuth did promise that it comes with the feature, so it was a bug. And as any other user would do, I thought of raising an issue but there was one already: <a href="https://github.com/Bismuth-Forge/bismuth/issues/370">here</a>. I regularly move my windows from one screen to another with keyboard shortcuts, and with this bug, I started facing issues. But as they say, in open-source, the community is everything. A guy with username: <a href="https://github.com/benemorius">benemorius</a> came up with a solution, and even though it took me some time to get it working, but it was eventually fixed. I started realizing how much I love this process, but more than that - I wanted to dive into the source code, and understand how it works. That was the time I realized I will look at the issues, found many opened, but since the maintainer of the library had a goal of porting it from typescript to C++, which meant that new features were essentially blocked till then (unless and until they are small with respect to the number of lines of code).</p>
<p>That was the time I realized that I should stop complaining, and instead start helping. I found an opened issue <a href="https://github.com/Bismuth-Forge/bismuth/issues/335#issuecomment-1159362257">here</a> and left a comment. The maintainer was very kind to respond, and guide through the process. And that&rsquo;s where I started contributing to Bismuth.</p>
<p>To a lot of people, and even to me, porting looks like an onboarding task, you have got things baked in for yourself, all you have to do is port it to another language. This was different though, I realized that I might have to write my own code at some places (<a href="https://github.com/Bismuth-Forge/bismuth/issues/335#issuecomment-1159993392)">https://github.com/Bismuth-Forge/bismuth/issues/335#issuecomment-1159993392)</a>, it was a re-write from ground up.</p>
<p>One thing I missed writing so far, was how much I loved developing tools and libraries. It&rsquo;s something that comes naturally to me, and Bismuth seemed to be an amazing place to continue my passion.</p>
<h2 id="contributions">Contributions</h2>
<p>For those who might be unaware, I did all my contributions (so far) live on my Twitch channel: <a href="https://twitch.tv/buffetcodes">buffetcodes</a>, and have uploaded all the recordings on my <a href="https://youtube.com/c/kushashwaraviShrimali">YouTube channel</a>. There is a <a href="https://www.youtube.com/playlist?list=PLfjzHJeA53gTMjuPI1YaQ9jjZx_E8mqJZ">playlist if you are interested</a>.</p>
<p>Honestly speaking, I had no clue when I started that how the journey will be, how easy/difficult it will be! To me, it was just fun. I don&rsquo;t know if it was easy, or if it was difficult, it was just something very fun to do! Plus, came with a lot of learning. So far, when I&rsquo;m writing this blog, I&rsquo;ve 2 opened PRs:</p>
<ol>
<li><a href="https://github.com/Bismuth-Forge/bismuth/pull/387">C++ Port: <code>focusWindowByDirection</code></a></li>
<li><a href="https://github.com/Bismuth-Forge/bismuth/pull/393">C++ Port: <code>ThreeColumn</code> layout</a></li>
</ol>
<p>To give you a glimpse, here is how the code looks when you do press a keyboard shortcut to focus window to your left/right/up/down:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">void</span> Engine<span style="color:#f92672">::</span>focusWindowByDirection(FocusDirection direction)
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> windowsToChoseFrom <span style="color:#f92672">=</span> m_windows.visibleWindowsOn(activeSurface());
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (windowsToChoseFrom.empty()) {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span>;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// If there is no current window, select the first one.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">auto</span> activeWindow <span style="color:#f92672">=</span> m_windows.activeWindow();
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (<span style="color:#f92672">!</span>activeWindow.has_value()) {
</span></span><span style="display:flex;"><span>        activeWindow <span style="color:#f92672">=</span> windowsToChoseFrom.front();
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> window <span style="color:#f92672">=</span> windowNeighbor(direction, activeWindow.value());
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (window.has_value()) {
</span></span><span style="display:flex;"><span>        window<span style="color:#f92672">-&gt;</span>activate();
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Let&rsquo;s consider that you are trying to focus right from your current window, so the parameter <code>direction</code> will have a value of <code>FocusDirection::Right</code> (it&rsquo;s an <code>enum</code>). The current state of Bismuth only allowed you to move right/left/top/bottom on the current screen, that means if you want to move to the next monitor - you can&rsquo;t use the same keyboard shortcuts. Hence the first line in the body of the function:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// This gets all the visible windows (not hidden) on the active screen/montior/surface
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">auto</span> windowsToChoseFrom <span style="color:#f92672">=</span> m_windows.visible(activeSurface());
</span></span></code></pre></div><p>Now of-course there is a possibility that you have no windows visible on the surface, in that case it will just return (which is what the next 3 lines do):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Early return if no window is visible on the current surface
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">if</span> (windowsToChoseFrom.empty()) {
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span>;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Okay, now comes the serious part. Whenever you think of <code>focusWindowByDirection</code>, there are 2 possibilities (apart from those listed above):</p>
<ol>
<li>You have an active window, that means your mouse is already focused on a window on the current screen.</li>
<li>You don&rsquo;t have an active window, that means your focus can be on the panel, or maybe on an icon or wherever except a window on the current surface.</li>
</ol>
<p>These two cases need to be handled, and that&rsquo;s what the next few lines do:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// If there is no current window, select the first one.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">auto</span> activeWindow <span style="color:#f92672">=</span> m_windows.activeWindow();
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (<span style="color:#f92672">!</span>activeWindow.has_value()) {
</span></span><span style="display:flex;"><span>    activeWindow <span style="color:#f92672">=</span> windowsToChoseFrom.front();
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Once the extension knows what <code>activeWindow</code> is, it&rsquo;s comparatively easier to figure out which window to focus on (only if it&rsquo;s possible). Time to talk about the function that does the magic.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">/* This function returns the closest window (if any) from the current window for the given direction */</span>
</span></span><span style="display:flex;"><span>std<span style="color:#f92672">::</span>optional<span style="color:#f92672">&lt;</span>Window<span style="color:#f92672">&gt;</span> Engine<span style="color:#f92672">::</span>windowNeighbor(Engine<span style="color:#f92672">::</span>FocusDirection direction, <span style="color:#66d9ef">const</span> Window <span style="color:#f92672">&amp;</span>basisWindow);
</span></span></code></pre></div><p>Above is the declaration of the function, and hopefully the comment describes it well. You will definitely need to know the window relative to which you&rsquo;ll return the output window, and the direction is a must. Note the return type, <code>std::optional&lt;Window&gt;</code>. As I said, it is possible that there is a window to the right, it&rsquo;s also possible that there are no more windows to the right direction. Hence <a href="https://en.cppreference.com/w/cpp/utility/optional"><code>std::optional</code></a> there.</p>
<p>Let me quickly talk about the algorithm that Bismuth follows for this feature:</p>
<ol>
<li>Get all possible candidates in the neighborhood of the active window <em>for the given direction</em>:</li>
</ol>
<ul>
<li>If the direction is right, you need to know how many <em>tiled</em> windows are on the right to the active window.</li>
<li>These neighbor candidates can also be on the top-right if the given direction is right.</li>
</ul>
<ol start="2">
<li>Get the <em>closest</em> relative window from the candidates selected in the step-1.</li>
<li>If there are multiple windows from step-2, return the window which was used recently (this means that we need each window to have &ldquo;the time it was last used&rdquo; as a meta-data).</li>
</ol>
<p>I&rsquo;ll be diving deep into the code for each of these steps in my next blog.</p>
<p>Do note that I&rsquo;m not doing this full-time, so this will obviously look slow to a lot of people, but I see a motivation behind doing this. I also believe that it is worth to mention <a href="https://github.com/benemorius/bismuth/">benemorius&rsquo;s work</a> on Bismuth, where has fixed a lot of the issues + added new features to Bismuth, and that is amazing! Shoutout to him on what he has been doing for the community.</p>
<p>Thank you for reading this blog, and if you are interested, feel free to check out <a href="https://github.com/Bismuth-Forge/bismuth/">Bismuth</a>. üòÑ‚ù§Ô∏è</p>
]]></content>
        </item>
        
        <item>
            <title>Common Collections (Vector and Strings) in Rust [Notes]</title>
            <link>https://krshrimali.github.io/posts/2022/01/common-collections-vector-and-strings-in-rust-notes/</link>
            <pubDate>Sun, 09 Jan 2022 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2022/01/common-collections-vector-and-strings-in-rust-notes/</guid>
            <description>Chapter 8: Common Collections These are my notes from the chapter-8 of rust book. Please scroll down to the bottom (Note) section if you are curious about what this is.
8.1: Storing Lists of Values with Vectors Vec&amp;lt;T&amp;gt; collection type discussed, aka vector: * By default contiguous. * All values should be of same type.
// Creation let v: Vec&amp;lt;i32&amp;gt; = Vec::new(); // vec! macro for convenience // default integer type is i32 let v = vec!</description>
            <content type="html"><![CDATA[<h2 id="chapter-8-common-collections">Chapter 8: Common Collections</h2>
<p>These are my notes from the <a href="https://doc.rust-lang.org/book/ch08-00-common-collections.html">chapter-8</a> of <a href="https://doc.rust-lang.org/book">rust book</a>. Please scroll down to the bottom (<code>Note</code>) section if you are curious about what this is.</p>
<h3 id="81-storing-lists-of-values-with-vectors">8.1: Storing Lists of Values with Vectors</h3>
<p><code>Vec&lt;T&gt;</code> collection type discussed, aka vector:
* By default contiguous.
* All values should be of same type.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#75715e">// Creation
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> v: Vec<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">i32</span><span style="color:#f92672">&gt;</span> <span style="color:#f92672">=</span> Vec::new();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// vec! macro for convenience
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// default integer type is i32
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> v <span style="color:#f92672">=</span> vec![<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>];
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Modifying
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> v <span style="color:#f92672">=</span> Vec::new();
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Rust infers the type from the elements pushed here
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>v.push(<span style="color:#ae81ff">5</span>);
</span></span><span style="display:flex;"><span>v.push(<span style="color:#ae81ff">6</span>);
</span></span><span style="display:flex;"><span><span style="color:#75715e">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Dropping
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// a vector is freed, when it goes out of scope
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>{
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> v <span style="color:#f92672">=</span> vec![<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>];
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>} <span style="color:#75715e">// &lt;-- v goes out of scope here, and hence memory is freed as well
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Reading Elements of Vectors
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> v <span style="color:#f92672">=</span> vec![<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">5</span>];
</span></span><span style="display:flex;"><span><span style="color:#75715e">// First way:
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> third: <span style="color:#66d9ef">&amp;</span><span style="color:#66d9ef">i32</span> <span style="color:#f92672">=</span> <span style="color:#f92672">&amp;</span>v[<span style="color:#ae81ff">2</span>];
</span></span><span style="display:flex;"><span>println!(<span style="color:#e6db74">&#34;The third element is: </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span>, third);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Second way:
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">match</span> v.get(<span style="color:#ae81ff">2</span>) {
</span></span><span style="display:flex;"><span>    Some(num) <span style="color:#f92672">=&gt;</span> println!(<span style="color:#e6db74">&#34;The third element is: </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span>, num),
</span></span><span style="display:flex;"><span>    None <span style="color:#f92672">=&gt;</span> println!(<span style="color:#e6db74">&#34;There is no third element.&#34;</span>),
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p><code>.get(&amp;index)</code> method allows you to handle out of range errors.</p>
<blockquote>
<p>When a program has a valid reference, the borrow checker enforces the ownership and borrowing rules to ensure this reference and any other references to the contents of the vector remain valid.</p>
</blockquote>
<p>Following example will fail:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> v <span style="color:#f92672">=</span> vec![<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">5</span>];
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">let</span> first <span style="color:#f92672">=</span> <span style="color:#f92672">&amp;</span>v[<span style="color:#ae81ff">0</span>];
</span></span><span style="display:flex;"><span>v.push(<span style="color:#ae81ff">6</span>);
</span></span><span style="display:flex;"><span>println!(<span style="color:#e6db74">&#34;The first element is: </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span>, first);
</span></span></code></pre></div><ul>
<li>Adding an element to a vector may require the old memory chunk to be transferred to a new space, causing old memory disallocation for the object <code>v</code>.</li>
<li>Accessing <code>&amp;v[0]</code> can thus be dangerous, and hence the borrowing rules prevent programs from ending up in that situation.</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#75715e">// Iterating over the values in a vector
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> v <span style="color:#f92672">=</span> vec![<span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">32</span>, <span style="color:#ae81ff">57</span>];
</span></span><span style="display:flex;"><span><span style="color:#75715e">// get immutable references to each element in a vector v
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">for</span> i <span style="color:#66d9ef">in</span> <span style="color:#f92672">&amp;</span>v {
</span></span><span style="display:flex;"><span>    println!(<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span>, i);
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// get mutable references to each element in a mutable veector v
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> v <span style="color:#f92672">=</span> vec![<span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">32</span>, <span style="color:#ae81ff">57</span>];
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> i <span style="color:#66d9ef">in</span> <span style="color:#f92672">&amp;</span><span style="color:#66d9ef">mut</span> v {
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">*</span>i <span style="color:#f92672">+=</span> <span style="color:#ae81ff">50</span>;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>You can use an <code>enum</code> to store multiple type values in a vector, but indirectly, this is how:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">enum</span> <span style="color:#a6e22e">SpreadsheetCell</span> {
</span></span><span style="display:flex;"><span>    Int(<span style="color:#66d9ef">i32</span>),
</span></span><span style="display:flex;"><span>    Float(<span style="color:#66d9ef">f64</span>),
</span></span><span style="display:flex;"><span>    Text(String),
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">let</span> row <span style="color:#f92672">=</span> vec![
</span></span><span style="display:flex;"><span>    SpreadsheetCell::Int(<span style="color:#ae81ff">3</span>),
</span></span><span style="display:flex;"><span>    SpreadsheetCell::Text(String::from(<span style="color:#e6db74">&#34;blue&#34;</span>)),
</span></span><span style="display:flex;"><span>    SpreadsheetCell::Float(<span style="color:#ae81ff">10.12</span>),
</span></span><span style="display:flex;"><span>];
</span></span></code></pre></div><p>Note how <code>row</code> vector still has same types (of <code>enum SpreadsheetCell</code>) but can hold values of multiple types through enums.</p>
<h3 id="82-storing-utf-8-encoded-text-with-strings">8.2: Storing UTF-8 Encoded Text with Strings</h3>
<p>In Rust, strings are implemented as a collection of bytes + some methods to provide useful functionality when those bytes are interpreted as text.</p>
<p>(both types listed below are UTF-8 encoded)</p>
<ul>
<li>Rust has only one string type in the <strong>core language</strong>: string slice <code>str</code> (usually seen in borrowed form: <code>&amp;str</code>).</li>
<li>Rust&rsquo;s standard library provides <code>String</code> type: (not coded into the core language):
<ul>
<li>It&rsquo;s <em>growbable, mutable, and owned</em> UTF-8 encoded string type.</li>
</ul>
</li>
</ul>
<p>There are other string types included in Rust&rsquo;s standard library: <code>OsString, OsStr, CString, CStr&quot;. Types ending with </code>String<code>refer to owned variants, while types ending with</code>Str` refer to borrowed variants. (not discussed in the book/chapter)</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#75715e">// Creating a new string
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> s <span style="color:#f92672">=</span> String::new();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// If you have some initial data, use to_string method
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// this is available on any type that implements the Display trait
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Following three methods are valid
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// First
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> data <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;initial contents&#34;</span>; <span style="color:#75715e">// a string literal
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> s <span style="color:#f92672">=</span> data.to_string();
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Second
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> s <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;initial conents&#34;</span>.to_string();
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Third
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> s <span style="color:#f92672">=</span> String::from(<span style="color:#e6db74">&#34;initial contents&#34;</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Updating a string
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> s <span style="color:#f92672">=</span> String::from(<span style="color:#e6db74">&#34;foo&#34;</span>);
</span></span><span style="display:flex;"><span>s.push_str(<span style="color:#e6db74">&#34;bar&#34;</span>); <span style="color:#75715e">// s is now &#34;foobar&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Appending to a string
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// using push_str and push
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> s <span style="color:#f92672">=</span> String::from(<span style="color:#e6db74">&#34;foo&#34;</span>);
</span></span><span style="display:flex;"><span>s.push_str(<span style="color:#e6db74">&#34;bar&#34;</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> s1 <span style="color:#f92672">=</span> String::from(<span style="color:#e6db74">&#34;foo&#34;</span>);
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">let</span> s2 <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;bar&#34;</span>;
</span></span><span style="display:flex;"><span><span style="color:#75715e">// We don&#39;t take ownership of s2 here
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// To ensure that we can still use s2 even after appending contents to s1
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>s1.push_str(s2);
</span></span><span style="display:flex;"><span>println!(<span style="color:#e6db74">&#34;s2 is </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span>, s2);
</span></span><span style="display:flex;"><span>println!(<span style="color:#e6db74">&#34;s1 is </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span>, s1);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Use push to append single character to the String
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> s <span style="color:#f92672">=</span> String::from(<span style="color:#e6db74">&#34;lo&#34;</span>);
</span></span><span style="display:flex;"><span>s.push(<span style="color:#e6db74">&#39;l&#39;</span>); <span style="color:#75715e">// now &#34;lol&#34;
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Concatenation with + operator or the format! macro
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> s1 <span style="color:#f92672">=</span> String::from(<span style="color:#e6db74">&#34;Hello, &#34;</span>);
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">let</span> s2 <span style="color:#f92672">=</span> String::from(<span style="color:#e6db74">&#34;world!&#34;</span>);
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">let</span> s3 <span style="color:#f92672">=</span> s1 <span style="color:#f92672">+</span> <span style="color:#f92672">&amp;</span>s2;
</span></span></code></pre></div><p>Consider the following script:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">let</span> s1 <span style="color:#f92672">=</span> String::from(<span style="color:#e6db74">&#34;foo&#34;</span>);
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">let</span> s2 <span style="color:#f92672">=</span> String::from(<span style="color:#e6db74">&#34; bar&#34;</span>);
</span></span><span style="display:flex;"><span><span style="color:#75715e">// The operation takes ownership of s1 here
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> s3 <span style="color:#f92672">=</span> s1 <span style="color:#f92672">+</span> <span style="color:#f92672">&amp;</span>s2;
</span></span><span style="display:flex;"><span><span style="color:#75715e">// You can not use s1 after the operation above
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>println!(<span style="color:#e6db74">&#34;s3 is: </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span>, s3);
</span></span></code></pre></div><p>Following is the error you&rsquo;ll get:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span>error[E0382]: <span style="color:#a6e22e">borrow</span> of moved value: <span style="color:#960050;background-color:#1e0010">`</span>s1<span style="color:#960050;background-color:#1e0010">`</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">-</span>-&gt; <span style="color:#a6e22e">src</span><span style="color:#f92672">/</span>main.rs:<span style="color:#ae81ff">5</span>:<span style="color:#ae81ff">27</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">2</span> <span style="color:#f92672">|</span>     <span style="color:#66d9ef">let</span> s1 <span style="color:#f92672">=</span> String::from(<span style="color:#e6db74">&#34;foo&#34;</span>);
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">|</span>         <span style="color:#f92672">--</span> <span style="color:#66d9ef">move</span> occurs because <span style="color:#960050;background-color:#1e0010">`</span>s1<span style="color:#960050;background-color:#1e0010">`</span> has <span style="color:#66d9ef">type</span> <span style="color:#960050;background-color:#1e0010">`</span>String<span style="color:#960050;background-color:#1e0010">`</span>, which does not implement the <span style="color:#960050;background-color:#1e0010">`</span>Copy<span style="color:#960050;background-color:#1e0010">`</span> <span style="color:#66d9ef">trait</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">3</span> <span style="color:#f92672">|</span>     <span style="color:#66d9ef">let</span> s2 <span style="color:#f92672">=</span> String::from(<span style="color:#e6db74">&#34; bar&#34;</span>);
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4</span> <span style="color:#f92672">|</span>     <span style="color:#66d9ef">let</span> s3 <span style="color:#f92672">=</span> s1 <span style="color:#f92672">+</span> <span style="color:#f92672">&amp;</span>s2;
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">|</span>              <span style="color:#f92672">--</span> value moved here
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">5</span> <span style="color:#f92672">|</span>     println!(<span style="color:#e6db74">&#34;s1 is: </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span>, s1);
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">|</span>                           <span style="color:#f92672">^^</span> value borrowed here after <span style="color:#66d9ef">move</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>For more information about this error, <span style="color:#66d9ef">try</span> <span style="color:#960050;background-color:#1e0010">`</span>rustc <span style="color:#f92672">--</span>explain E0382<span style="color:#960050;background-color:#1e0010">`</span>
</span></span></code></pre></div><p>So what&rsquo;s happening? The <code>+</code> operator uses an <code>add</code> method whose signature looks like this for our inputs:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">add</span>(self, s: <span style="color:#66d9ef">&amp;</span><span style="color:#66d9ef">str</span>) -&gt; String {
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>}
</span></span></code></pre></div><p>A few notes about <code>s</code> parameter:</p>
<ol>
<li>It&rsquo;s taken by reference. Means you add reference of the second string to the firstt string.</li>
<li>You can not add 2 <code>String</code> values together, only <code>&amp;str</code> to a <code>String</code>. (Rust compiler, in our case, coerces the <code>&amp;String</code> argument into a <code>&amp;str</code>, more on deref coercion later).</li>
</ol>
<p>Note about <code>self</code> parameter:</p>
<ol>
<li><code>add</code> method takes ownership of <code>self</code> (it doesn&rsquo;t have an <code>&amp;</code>).</li>
<li>The point above implies, <code>s1</code> will be moved to the <code>add</code> call and no longer be valid after that.</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">let</span> s3 <span style="color:#f92672">=</span> s1 <span style="color:#f92672">+</span> <span style="color:#f92672">&amp;</span>s2;
</span></span></code></pre></div><p>The above statement actually:</p>
<ol>
<li>Moves <code>s1</code> into the <code>add</code> call / takes ownership of <code>s1</code> (making it invalid after that)</li>
<li>Appends a <em>copy</em> of the contents of <code>s2</code>.</li>
<li>Returns ownership of the result.</li>
</ol>
<p>(this process is more efficient than copying).</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#75715e">// Concatenating multiple strings
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> s1 <span style="color:#f92672">=</span> String::from(<span style="color:#e6db74">&#34;tic&#34;</span>);
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">let</span> s2 <span style="color:#f92672">=</span> String::from(<span style="color:#e6db74">&#34;tac&#34;</span>);
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">let</span> s2 <span style="color:#f92672">=</span> String::from(<span style="color:#e6db74">&#34;toe&#34;</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">let</span> s <span style="color:#f92672">=</span> s1 <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;-&#34;</span> <span style="color:#f92672">+</span> <span style="color:#f92672">&amp;</span>s2 <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;-&#34;</span> <span style="color:#f92672">+</span> <span style="color:#f92672">&amp;</span>s3;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// You can also do:
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Uses reference for all parameters, so no ownership of any here...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> s <span style="color:#f92672">=</span> format!(<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">-</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">-</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span>, s1, s2, s3);
</span></span></code></pre></div><p>Talking about Indexing into Strings:</p>
<p>The following will give an error.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#75715e">// Indexing into Strings
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Not like other languages (C++/Python):
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> s1 <span style="color:#f92672">=</span> String::from(<span style="color:#e6db74">&#34;hello&#34;</span>);
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">let</span> h <span style="color:#f92672">=</span> s1[<span style="color:#ae81ff">0</span>];
</span></span></code></pre></div><p>Error:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span>error[E0277]: <span style="color:#a6e22e">the</span> <span style="color:#66d9ef">type</span> <span style="color:#960050;background-color:#1e0010">`</span>String<span style="color:#960050;background-color:#1e0010">`</span> cannot be indexed by <span style="color:#960050;background-color:#1e0010">`</span>{integer}<span style="color:#960050;background-color:#1e0010">`</span>
</span></span><span style="display:flex;"><span> <span style="color:#f92672">-</span>-&gt; <span style="color:#a6e22e">src</span><span style="color:#f92672">/</span>main.rs:<span style="color:#ae81ff">3</span>:<span style="color:#ae81ff">13</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">3</span> <span style="color:#f92672">|</span>     <span style="color:#66d9ef">let</span> h <span style="color:#f92672">=</span> s1[<span style="color:#ae81ff">0</span>];
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">|</span>             <span style="color:#f92672">^^^^^</span> <span style="color:#960050;background-color:#1e0010">`</span>String<span style="color:#960050;background-color:#1e0010">`</span> cannot be indexed by <span style="color:#960050;background-color:#1e0010">`</span>{integer}<span style="color:#960050;background-color:#1e0010">`</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span>  <span style="color:#f92672">=</span> help: <span style="color:#a6e22e">the</span> <span style="color:#66d9ef">trait</span> <span style="color:#960050;background-color:#1e0010">`</span>Index<span style="color:#f92672">&lt;</span>{integer}<span style="color:#f92672">&gt;</span><span style="color:#960050;background-color:#1e0010">`</span> is not implemented <span style="color:#66d9ef">for</span> <span style="color:#960050;background-color:#1e0010">`</span>String<span style="color:#960050;background-color:#1e0010">`</span>
</span></span></code></pre></div><p><em>Rust strings don&rsquo;t support indexing</em>. To understand, let&rsquo;s understand how memory storage works for strings in Rust.</p>
<p>A <code>String</code> is a wrapper over a <code>Vec&lt;u8&gt;</code>. Consider:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#75715e">// Hola is 4 bytes long (each of the chars take 1 byte when encoded in UTF-8) and len will be 4
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> hello <span style="color:#f92672">=</span> String::from(<span style="color:#e6db74">&#34;Hola&#34;</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Now consider:
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> hello <span style="color:#f92672">=</span> String::from(<span style="color:#e6db74">&#34;–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ&#34;</span>);
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Number of bytes stored for hello: 24
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Each unicode scalar value in the string above takes 2 bytes of storage.
</span></span></span></code></pre></div><p>Hence, indexing into string&rsquo;s bytes will not always correlate to a valid Unicode scalar value. Hence, no indexing support for strings in Rust.</p>
<blockquote>
<p>A final reason Rust doesn‚Äôt allow us to index into a String to get a character is that indexing operations are expected to always take constant time (O(1)). But it isn‚Äôt possible to guarantee that performance with a String, because Rust would have to walk through the contents from the beginning to the index to determine how many valid characters there were.</p>
</blockquote>
<p>Slicing strings:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">let</span> hello <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ&#34;</span>;
</span></span><span style="display:flex;"><span><span style="color:#75715e">// This will give you first 4 bytes of hello string
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> s <span style="color:#f92672">=</span> <span style="color:#f92672">&amp;</span>hello[<span style="color:#ae81ff">0</span><span style="color:#f92672">..</span><span style="color:#ae81ff">4</span>];
</span></span><span style="display:flex;"><span><span style="color:#75715e">// In hello, every character is of 2 bytes, so s will have –ó–¥
</span></span></span></code></pre></div><p>With the same <code>hello</code> string, what will be the output if we used <code>let s = &amp;hello[0..1];</code>? Following error will be raised:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span>thread <span style="color:#a6e22e">&#39;main&#39;</span> panicked at <span style="color:#a6e22e">&#39;byte</span> index <span style="color:#ae81ff">1</span> is not a <span style="color:#66d9ef">char</span> boundary; it is inside <span style="color:#e6db74">&#39;–ó&#39;</span> (bytes <span style="color:#ae81ff">0</span><span style="color:#f92672">..</span><span style="color:#ae81ff">2</span>) of <span style="color:#960050;background-color:#1e0010">`–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ`</span><span style="color:#a6e22e">&#39;</span>, src<span style="color:#f92672">/</span>main.rs:<span style="color:#ae81ff">3</span>:<span style="color:#ae81ff">13</span>
</span></span></code></pre></div><p>Iterating over strings: use the <code>chars</code> method.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> c <span style="color:#66d9ef">in</span> <span style="color:#e6db74">&#34;‡§®‡§Æ‡§∏‡•ç‡§§‡•á&#34;</span>.chars() {
</span></span><span style="display:flex;"><span>    println!(<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span>, c);
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Output:
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">//  ‡§®
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">//  ‡§Æ
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">//  ‡§∏
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">//   ‡•ç
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">//  ‡§§
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">//   ‡•á
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// bytes method will return each raw byte
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">for</span> b <span style="color:#66d9ef">in</span> <span style="color:#e6db74">&#34;‡§®‡§Æ‡§∏‡•ç‡§§‡•á&#34;</span>.bytes() {
</span></span><span style="display:flex;"><span>    println!(<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span>, b);
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Output:
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// All 18 bytes that made up this string
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// 224
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// 164
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// 168
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// 224
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// 164
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// 174
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// 224
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// 164
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// 184
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// 224
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// 165
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// 141
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// 224
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// 164
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// 164
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// 224
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// 165
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// 135
</span></span></span></code></pre></div><p>Note: valid unicode scalar values maybe made up of more than 1 byte, like above.</p>
<h2 id="note">Note</h2>
<hr>
<p><strong>NOTE</strong></p>
<p>These are just my notes, or things I write down while/after reading the chapters/blogs or going through resources. I like sharing them, for everyone&rsquo;s and also my memory. At no point I say or mean that these should be preferred or read &ldquo;over&rdquo; the original resource mentioned. But as always, I&rsquo;m open for feedback and/or suggestions, so feel free to comment here on the blog (just be nice, is all I ask for).</p>
<hr>
]]></content>
        </item>
        
        <item>
            <title>Common Collections (Vector and Strings) in Rust [Notes]</title>
            <link>https://krshrimali.github.io/posts/2022/01/common-collections-vector-and-strings-in-rust-notes/</link>
            <pubDate>Sun, 09 Jan 2022 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2022/01/common-collections-vector-and-strings-in-rust-notes/</guid>
            <description>Chapter 8: Common Collections (Hash Maps) In the previous blog, I shared my notes on strings and vectors in Rust, and in this post we&amp;rsquo;ll cover Hash Maps. I personally have found their use in competitive programming, a lot, but hopefully as we move on, we&amp;rsquo;ll see lots of use-cases in real-life problems.
Hash Maps Hash Maps: HashMap&amp;lt;K, V&amp;gt;
You can&amp;rsquo;t access using indices, but through keys. Hash Maps store data on heap.</description>
            <content type="html"><![CDATA[<h2 id="chapter-8-common-collections-hash-maps">Chapter 8: Common Collections (Hash Maps)</h2>
<p>In the <a href="https://krshrimali.github.io/posts/2022/01/common-collections-vector-and-strings-in-rust-notes/">previous blog</a>, I shared my notes on strings and vectors in Rust, and in this post we&rsquo;ll cover Hash Maps. I personally have found their use in competitive programming, a lot, but hopefully as we move on, we&rsquo;ll see lots of use-cases in real-life problems.</p>
<h2 id="hash-maps">Hash Maps</h2>
<p>Hash Maps: <code>HashMap&lt;K, V&gt;</code></p>
<ul>
<li>You can&rsquo;t access using indices, but through keys.</li>
<li>Hash Maps store data on heap.</li>
<li>Hash Maps are homogenous (all keys must have same type, and all values must have same type).</li>
<li>Use <code>std::collections::HashMap</code> to bring <code>HashMap</code> to scope.</li>
</ul>
<p><strong>Creating a New Hash Map</strong></p>
<p>First Way:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">use</span> std::collections::HashMap;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> scores <span style="color:#f92672">=</span> HashMap::new();
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Now insert key, val pair
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>scores.insert(<span style="color:#e6db74">&#34;Kush&#34;</span>, <span style="color:#ae81ff">3</span>);
</span></span><span style="display:flex;"><span>scores.insert(<span style="color:#e6db74">&#34;Kushashwa&#34;</span>, <span style="color:#ae81ff">10</span>);
</span></span></code></pre></div><p>Second Way: In case you have keys and values stored in two different vectors, and want to generate a hashmap from them, use <code>collect()</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">use</span> std::collections::HashMap;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">let</span> teams <span style="color:#f92672">=</span> vec![String::from(<span style="color:#e6db74">&#34;Blue&#34;</span>), String::from(<span style="color:#e6db74">&#34;Yellow&#34;</span>)];
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">let</span> initial_scores <span style="color:#f92672">=</span> vec![<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">50</span>];
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Types will be infered by Rust from the data in the vectors
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> scores: <span style="color:#a6e22e">HashMap</span><span style="color:#f92672">&lt;</span>_, _<span style="color:#f92672">&gt;</span> <span style="color:#f92672">=</span> teams.into_iter().zip(initial_scores.into_iter()).collect();
</span></span></code></pre></div><p>Why <code>HashMap&lt;_, _&gt;</code>? <code>collect()</code> method can store values into different datastructures, and we need to specify the type of <code>scores</code>. For the types of keys and values, Rust can infer the types itself - hence we specify <code>_</code>.</p>
<p>I was curious what <code>into_iter()</code> does, and <a href="https://stackoverflow.com/a/34745885">here</a> is a very interesting answer to <code>into_iter()</code> vs <code>iter()</code> on Stackoverflow. Someone mentioned <a href="https://hermanradtke.com/2015/06/22/effectively-using-iterators-in-rust.html/">this blog post</a> in the comments, I&rsquo;ve this as a TODO - but from the looks of it, it might be useful.</p>
<p>If you are curious what <code>teams.into_iter().zip(initial_scores.into_iter())</code> do? Great, check this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">main</span>() {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> teams <span style="color:#f92672">=</span> vec![String::from(<span style="color:#e6db74">&#34;Blue&#34;</span>), String::from(<span style="color:#e6db74">&#34;Yellow&#34;</span>)];
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> initial_scores <span style="color:#f92672">=</span> vec![<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">50</span>];
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> tuple_output <span style="color:#f92672">=</span> teams.into_iter().zip(initial_scores.into_iter());
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> item <span style="color:#66d9ef">in</span> tuple_output {
</span></span><span style="display:flex;"><span>        println!(<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">, </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span> ,item.<span style="color:#ae81ff">0</span>, item.<span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Outputs:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span>Blue, <span style="color:#ae81ff">10</span>
</span></span><span style="display:flex;"><span>Yellow, <span style="color:#ae81ff">50</span>
</span></span></code></pre></div><p>So clearly, creating a vector of tuples (of a <code>String</code> and <code>Integer</code>). Maybe try passing a vector of different length to <code>.zip()</code> function? ;)</p>
<h2 id="hash-maps-and-ownership">Hash Maps and Ownership</h2>
<p>Ownership is always the center of discussion when it comes to Rust. When you create a hashmap, and insert <code>String</code> objects, <code>i32</code> values, the ownership behaves differently:</p>
<ol>
<li>For types that implement <code>Copy</code> trait, like <code>i32</code>, the values will be copied to the hashmap.</li>
<li>For <code>String</code> values (owned values), the values are moved into the hashmap and the hashmap will be the owner.</li>
</ol>
<p>See the following example and corresponding error:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">use</span> std::collections::HashMap;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">main</span>() {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> str1 <span style="color:#f92672">=</span> String::from(<span style="color:#e6db74">&#34;Kush&#34;</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> str2 <span style="color:#f92672">=</span> String::from(<span style="color:#e6db74">&#34;Name&#34;</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> map <span style="color:#f92672">=</span> HashMap::new();
</span></span><span style="display:flex;"><span>    map.insert(str1, str2);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    println!(<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span>, str1);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span>   <span style="color:#f92672">|</span>
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">4</span>  <span style="color:#f92672">|</span>     <span style="color:#66d9ef">let</span> str1 <span style="color:#f92672">=</span> String::from(<span style="color:#e6db74">&#34;Kush&#34;</span>);
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">|</span>         <span style="color:#f92672">----</span> <span style="color:#66d9ef">move</span> occurs because <span style="color:#960050;background-color:#1e0010">`</span>str1<span style="color:#960050;background-color:#1e0010">`</span> has <span style="color:#66d9ef">type</span> <span style="color:#960050;background-color:#1e0010">`</span>String<span style="color:#960050;background-color:#1e0010">`</span>, which does not implement the <span style="color:#960050;background-color:#1e0010">`</span>Copy<span style="color:#960050;background-color:#1e0010">`</span> <span style="color:#66d9ef">trait</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">..</span>.
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">8</span>  <span style="color:#f92672">|</span>     map.insert(str1, str2);
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">|</span>                <span style="color:#f92672">----</span> value moved here
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">9</span>  <span style="color:#f92672">|</span> 
</span></span><span style="display:flex;"><span><span style="color:#ae81ff">10</span> <span style="color:#f92672">|</span>     println!(<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span>, str1);
</span></span><span style="display:flex;"><span>   <span style="color:#f92672">|</span>                    <span style="color:#f92672">^^^^</span> value borrowed here after <span style="color:#66d9ef">move</span>
</span></span></code></pre></div><p>As you can see, value was moved when <code>map.insert(str1, str2)</code> was called. One important point, that I&rsquo;ll just take from the book:</p>
<blockquote>
<p>If we insert references to values into the hash map, the values won‚Äôt be moved into the hash map. The values that the references point to must be valid for at least as long as the hash map is valid.</p>
</blockquote>
<p>(This is covered in detail in Chapter 10, so let&rsquo;s save it for later).</p>
<h2 id="accessing-values-in-a-hash-map">Accessing Values in a Hash Map</h2>
<p>Use <code>&lt;HashMap&gt;.get(&lt;Key&gt;)</code> function to get the value corresponding to the key. Please note that it returns <code>Option&lt;&amp;V&gt;</code> where <code>V</code> is the type of the value.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">use</span> std::collections::HashMap;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">main</span>() {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> str1 <span style="color:#f92672">=</span> String::from(<span style="color:#e6db74">&#34;Kush&#34;</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> str2 <span style="color:#f92672">=</span> String::from(<span style="color:#e6db74">&#34;Name&#34;</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> map <span style="color:#f92672">=</span> HashMap::new();
</span></span><span style="display:flex;"><span>    map.insert(str1, str2);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> val <span style="color:#f92672">=</span> map.get(<span style="color:#f92672">&amp;</span>String::from(<span style="color:#e6db74">&#34;Kush&#34;</span>));
</span></span><span style="display:flex;"><span>    println!(<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span>, val.unwrap());
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Outputs: <code>Name</code>.</p>
<p>Since <code>map.get(&amp;String::from(&quot;Kush&quot;))</code> returns <code>Option&lt;&amp;String&gt;</code> object, we need to <code>unwrap()</code> it in order to print it. Here is <a href="https://www.ameyalokare.com/rust/2017/10/23/rust-options.html">an interesting post</a> on why using <code>unwrap()</code> is not the best idea, and what other options we have. I used <code>unwrap()</code> here, since I knew it is not <code>None</code>.</p>
<p>Iterating through a hash map is also easy in Rust:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#75715e">// Use the same code as above
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">for</span> (key, value) <span style="color:#66d9ef">in</span> <span style="color:#f92672">&amp;</span>map {
</span></span><span style="display:flex;"><span>    println!(<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">: </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">&#34;</span>, key, value);
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Output:
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Kush: Name
</span></span></span></code></pre></div><h2 id="updating-a-hash-map">Updating a Hash Map</h2>
<p>Note that you can only have one value corresponding to a key. Let&rsquo;s consider our options:</p>
<ol>
<li>
<p><strong>Overwriting a value</strong>: <code>insert()</code> twice, and the new value will replace the old value.</p>
</li>
<li>
<p><strong>Only insert if key has no value</strong>:</p>
<ul>
<li>Use <code>entry(&lt;Key&gt;)</code>, it returns an <code>Enum</code>: <code>Empty</code> (represents a value that might or might not exist).</li>
<li>Call <code>or_insert</code> on the enum, which inserts a value if key doesn&rsquo;t exist.</li>
<li><code>or_insert</code> returns a mutable reference to the value present, or to the new value inserted.</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">use</span> std::collections::HashMap;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">main</span>() {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> scores <span style="color:#f92672">=</span> HashMap::new();
</span></span><span style="display:flex;"><span>    scores.insert(String::from(<span style="color:#e6db74">&#34;Blue&#34;</span>), <span style="color:#ae81ff">10</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    scores.entry(String::from(<span style="color:#e6db74">&#34;Yellow&#34;</span>)).or_insert(<span style="color:#ae81ff">50</span>);
</span></span><span style="display:flex;"><span>    scores.entry(String::from(<span style="color:#e6db74">&#34;Blue&#34;</span>)).or_insert(<span style="color:#ae81ff">50</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    println!(<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{:?}</span><span style="color:#e6db74">&#34;</span>, scores);
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Outputs
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// {&#34;Blue&#34;: 10, &#34;Yellow&#34;: 50}
</span></span></span></code></pre></div></li>
<li>
<p><strong>Updating a value based on the old value</strong>: Comments in the code should help explain the example.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-rust" data-lang="rust"><span style="display:flex;"><span><span style="color:#66d9ef">use</span> std::collections::HashMap;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">fn</span> <span style="color:#a6e22e">main</span>() {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> text <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;hello world wonderful world&#34;</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">let</span> <span style="color:#66d9ef">mut</span> map <span style="color:#f92672">=</span> HashMap::new();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// &#34;hello&#34;, &#34;world&#34;, &#34;wonderful&#34;, &#34;world&#34; - values of word
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">for</span> word <span style="color:#66d9ef">in</span> text.split_whitespace() {
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// if the map has an entry for word, return the count of it
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#75715e">// else, insert 0 and increase the counter by 1
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#75715e">// note that count is mutable reference
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#75715e">// so it needs to be de-referenced (in order to use it)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#66d9ef">let</span> count <span style="color:#f92672">=</span> map.entry(word).or_insert(<span style="color:#ae81ff">0</span>);
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">*</span>count <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    println!(<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">{:?}</span><span style="color:#e6db74">&#34;</span>, map); 
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Outputs:
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// {&#34;world&#34;: 2, &#34;wonderful&#34;: 1, &#34;hello&#34;: 1}
</span></span></span></code></pre></div></li>
</ol>
<h2 id="hashing-functions">Hashing Functions</h2>
<p>By default, Hash Maps in Rust use <a href="https://en.wikipedia.org/wiki/SipHash"><code>SipHash</code></a> hashing function, but you can use your own as well - it should implement <code>BuildHasher</code> trait. More on this is discussed in Chapter 10.</p>
<p>That&rsquo;s it for Chapter 8, thank you for reading. :)</p>
<h2 id="note">Note</h2>
<hr>
<p>These are just my notes, or things I write down while/after reading the chapters/blogs or going through resources. I like sharing them, for everyone&rsquo;s and also my memory. At no point I say or mean that these should be preferred or read &ldquo;over&rdquo; the original resource mentioned. But as always, I&rsquo;m open for feedback and/or suggestions, so feel free to comment here on the blog (just be nice, is all I ask for).</p>
<hr>
]]></content>
        </item>
        
        <item>
            <title>Weekly Progress Report: 03-10-2021, 2</title>
            <link>https://krshrimali.github.io/posts/2021/10/weekly-progress-report-03-10-2021-2/</link>
            <pubDate>Sun, 03 Oct 2021 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2021/10/weekly-progress-report-03-10-2021-2/</guid>
            <description>Hi everyone, so this week has been comparatively more productive in terms of learning as well as work! I&amp;rsquo;m happy, so why not share with everyone as well? &amp;#x1f389;
PyTorch: (ft. Quansight and Facebook)
Started working on porting index_add to structured kernels, see the PR I made on my forked repo here, and on upstream here. This included adding an out= variant to the op. Refining the way it&amp;rsquo;s registered in PyTorch.</description>
            <content type="html"><![CDATA[<p>Hi everyone, so this week has been comparatively more productive in terms of learning as well as work! I&rsquo;m happy, so why not share with everyone as well? &#x1f389;</p>
<p><strong>PyTorch</strong>: (ft. Quansight and Facebook)</p>
<ul>
<li>Started working on porting <code>index_add</code> to structured kernels, see the PR I made on my forked repo <a href="https://github.com/krshrimali/pytorch/pull/14">here</a>, and on upstream <a href="https://github.com/pytorch/pytorch/pull/65993">here</a>.
<ul>
<li>This included adding an <code>out=</code> variant to the op.</li>
<li>Refining the way it&rsquo;s registered in PyTorch. I am thinking to pass defalut value while registering, but it will be a BC breaking change.</li>
<li>Finally got to use <a href="https://github.com/ezyang/ghstack.git">ghstack</a>, thanks to <a href="https://github.com/ysiraichi">Yukio (Quansight)</a>.</li>
<li>Revised derivatives yaml file. Personally I feel that this one needs opinions from the Facebook team, and a lot of changes might be rejected (which is okay, at the end of the day - everything we do should be <em>good</em> for the library).</li>
<li>My PR <a href="https://github.com/pytorch/pytorch/pull/65993">here</a> is more like a prototype for everyone to get a chance to review, as well as comment on what they feel.</li>
</ul>
</li>
<li>Structured Kernel porting PR for <code>baddbmm, bmm</code> has been merged. Yay! &#x1f389; &#x2764;&#xfe0f; <a href="https://github.com/pytorch/pytorch/pull/65993">PR</a>.</li>
<li>Took a walkthrough of lots of autogenerated code in PyTorch, to understand how ops are registered.</li>
<li>Listened to <a href="https://open.spotify.com/show/6UzHKeiy368jKfQMKKvJY5">Ed&rsquo;s podcast</a> - episode on NVIDIA GPUs. A sweet little introduction to NVIDIA GPUs.</li>
</ul>
<p><strong>Extras</strong>:</p>
<ul>
<li>Continued reading history of JIT, but couldn&rsquo;t complete it. :sad: Will have to continue reading the next week, find the link <a href="http://eecs.ucf.edu/~dcm/Teaching/COT4810-Spring2011/Literature/JustInTimeCompilation.pdf">here</a>.</li>
<li>Effective Modern C++: I finished reading Item 14 of Chapter 3, but couldn&rsquo;t write notes about it. This blog post, I&rsquo;m planning to discuss the intermediate generated code (closer to assembly), so let&rsquo;s see how that goes the next week.</li>
<li>Learnt a bit about compilers, started reading a book on it.</li>
<li>Wrote a shell script in case I distro hop a lot, will link on this later once I&rsquo;ve uploaded it.</li>
<li>Started going through NumPy&rsquo;s source code, just something I&rsquo;m doing for learning.</li>
<li>Reading about memory overlaps in C.</li>
<li>BuffetCodes organization was dissolved recently, and the repositories were transferred. Thanks to my friend (Himanshu Singh) on working with me on this, it was a great experience.</li>
</ul>
<p>I&rsquo;m continuously thinking if writing this is anyway helpful for anyone else, so yes - please do let me know if you like reading these. However, I&rsquo;m enjoying learning and I think that&rsquo;s all that matters. I plan to start new projects very soon, and hopefully that should go good.</p>
]]></content>
        </item>
        
        <item>
            <title>Weekly Progress Report: 26-09-2021, 1</title>
            <link>https://krshrimali.github.io/posts/2021/09/weekly-progress-report-26-09-2021-1/</link>
            <pubDate>Sun, 26 Sep 2021 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2021/09/weekly-progress-report-26-09-2021-1/</guid>
            <description>Hi everyone, before I go ahead and share my progress, I wanted to quickly talk about what this blog is about.
I am highly passionate with the idea of high performance computing, optimizing deep learning applications, and solving real world problems using deep learning, computer vision, and speech processing. While I&amp;rsquo;m on this path - I would like to document this somewhere. And while I&amp;rsquo;m doing that, why not share it publicly?</description>
            <content type="html"><![CDATA[<p>Hi everyone, before I go ahead and share my progress, I wanted to quickly talk about what this blog is about.</p>
<p>I am highly passionate with the idea of high performance computing, optimizing deep learning applications, and solving real world problems using deep learning, computer vision, and speech processing. While I&rsquo;m on this path - I would like to document this somewhere. And while I&rsquo;m doing that, why not share it publicly?</p>
<p>So here it is, the first weekly update blog on what I&rsquo;ve been upto:</p>
<p><strong>PyTorch</strong>: (ft. Quansight and Facebook)</p>
<ul>
<li>Followed up on <code>batch_norm</code> <a href="https://github.com/pytorch/pytorch/pull/63218">PR</a>. Merged &#x1f389;</li>
<li>Structured Kernel porting for <code>baddbmm, bmm</code> <a href="https://github.com/pytorch/pytorch/pull/64805">PR</a>. Lots of interesting discussions, and should be approved after final round of review. Will have to follow up on this coming week.</li>
<li>Structured Kernel porting (WIP) for <code>nonzero</code> <a href="https://github.com/krshrimali/pytorch/pull/13">PR</a>. Putting this on hold, as there is a related PR on this - and it makes more sense to let that one go first, and then start working on this.</li>
<li>Finished the <code>max_poolNd</code> <a href="https://github.com/pytorch/pytorch/pull/62544">PR</a>, the PR is approved and will be merged after some time.</li>
<li>While working on <a href="https://github.com/pytorch/pytorch/pull/64805">structured kernel for baddbmm, bmm PR</a>, we needed to differentiate between in-place and out calls, interestingly - the autogenerated <code>set_output</code> function was the answer. A good discussion on this is <a href="https://github.com/pytorch/pytorch/pull/64805#discussion_r710952117">here</a>.</li>
<li>Took a look at implementation of <code>ArrayRef</code> class, find the source code <a href="https://github.com/pytorch/pytorch/blob/master/c10/util/ArrayRef.h#L41">here</a>.</li>
</ul>
<p><strong>Extras</strong>:</p>
<ul>
<li>The concept behind JIT is very interesting, and I wanted to read more about it. Started with <a href="http://eecs.ucf.edu/~dcm/Teaching/COT4810-Spring2011/Literature/JustInTimeCompilation.pdf">this</a> article on &ldquo;A Brief History of Just-In-Time&rdquo;. I plan to write a blog on this once I&rsquo;m done reading.</li>
<li>Effective Modern C++: I continued reading through Item 12 and Item 13 of Chapter 3:
<ul>
<li><a href="https://krshrimali.github.io/posts/2021/09/declaring-overriding-functions-override-notes/">Declaring Overriding Functions override</a></li>
<li><a href="https://krshrimali.github.io/posts/2021/09/prefer-const_iterators-to-iterators-notes/">Prefer const_iterators to iterators</a></li>
</ul>
</li>
<li>A very interesting blog on <code>vmap</code> and <code>pmap</code> in Jax is <a href="https://www.kaggle.com/aakashnain/tf-jax-tutorials-part-8-vmap-pmap">here</a>. Read half of it, will continue reading in the next week.</li>
<li>An interesting watch on <a href="https://www.youtube.com/watch?v=b9_0bqrm2G8">When do I use a union in C or C++, instead of a struct?</a>. I like watching such videos when I&rsquo;m a little tired from work.</li>
<li>Blog theme:
<ul>
<li>Worked on a new theme inspired by <a href="https://github.com/haoZeke/hugo-theme-hello-friend-ng-hz/">this theme</a>.</li>
<li>Re-organized the blog, fixed all the links (wherever it&rsquo;s shared on the internet), in-blog images and cover images as well. Check the milestone <a href="https://github.com/krshrimali/krshrimali.github.io/milestone/1">here</a>.</li>
<li>With this blog, the milestone for the blog will be closed. &#x1f389;</li>
</ul>
</li>
<li>Started reading tutorial on PyTorch&rsquo;s official docs about <a href="https://pytorch.org/tutorials/advanced/dispatcher.html">Returning a Dispatched Operator in C++</a>. Half way through, will continue reading in the next week.</li>
<li>Contribution to <a href="https://github.com/pystiche/pystiche/">pystiche</a>, attempting to suppress deprecation warnings produced by pystiche module. <a href="https://github.com/pystiche/pystiche/pull/566">PR</a>, a few review comments to address otherwise should look good.</li>
</ul>
<p>Yes, and apart from all of this, I did won a few games of CSGO with my friends, had a few health issues to catch up with (&#x1f622;), updated my <a href="https://discord.gg/5tXuYANP7R">discord channel</a> with blog announcements, helped a few friends with their doubts, and well, yeah that&rsquo;s it.</p>
<p>I hope to perform better once I feel good (w.r.t health). Thank you for reading.</p>
]]></content>
        </item>
        
        <item>
            <title>Prefer const_iterators to iterators (Notes)</title>
            <link>https://krshrimali.github.io/posts/2021/09/prefer-const_iterators-to-iterators-notes/</link>
            <pubDate>Sun, 26 Sep 2021 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2021/09/prefer-const_iterators-to-iterators-notes/</guid>
            <description>NOTE
My notes on Chapter 3, Item 13 of Effective Modern C++ written by Scott Meyers.
Some (or even all) of the text can be similar to what you see in the book, as these are notes: I&amp;rsquo;ve tried not to be unnecessarily creative with my words. :)
In C++, iterators come handy to point at memory addresses of STL containers. For example,
// C++11 std::vector&amp;lt;int&amp;gt; x {11, 9, 23, 6}; // begin() member function returns an iterator, which points to the first // memory address of the container x std::vector&amp;lt;int&amp;gt;::iterator it = x.</description>
            <content type="html"><![CDATA[<hr>
<p><strong>NOTE</strong></p>
<p>My notes on Chapter 3, Item 13 of Effective Modern C++ written by Scott Meyers.</p>
<p>Some (or even all) of the text can be similar to what you see in the book, as these are notes: I&rsquo;ve tried not to be unnecessarily creative with my words. :)</p>
<hr>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/prefer-const-iterators-to-iterators.png" alt=""></p>
<p>In C++, iterators come handy to point at memory addresses of STL containers. For example,</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// C++11
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> x {<span style="color:#ae81ff">11</span>, <span style="color:#ae81ff">9</span>, <span style="color:#ae81ff">23</span>, <span style="color:#ae81ff">6</span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// begin() member function returns an iterator, which points to the first
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// memory address of the container x
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;::</span>iterator it <span style="color:#f92672">=</span> x.begin();
</span></span></code></pre></div><p>While the general practice is to use <code>const</code> whenever possible, but programmers tend to use whenever it&rsquo;s <em>practical</em>. <code>const_iterators</code> is particularly suggested when you want to use iterators, but you don&rsquo;t need to modify what it points to.</p>
<p>Take an example of the code snippet above, you have the iterator <code>it</code> pointing to the beginning position of the container, and if you want to insert a value before this, you just need to pass this iterator to <code>x.insert()</code> along with the value, right? You don&rsquo;t need to modify the iterator. In such cases, <code>const_iterator</code> will be a better choice.</p>
<p>But, this is all for C++-11 and above. In C++-98, <code>const_iterator</code> wasn&rsquo;t just ready:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// C++-98
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Without using const_iterator
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// C++-98, initializing a vector wasn&#39;t that trivial as it is now
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">const</span> <span style="color:#66d9ef">int</span> values[] <span style="color:#f92672">=</span> {<span style="color:#ae81ff">11</span>, <span style="color:#ae81ff">23</span>, <span style="color:#ae81ff">6</span>};
</span></span><span style="display:flex;"><span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> x (values, values<span style="color:#f92672">+</span><span style="color:#ae81ff">3</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Want to insert 9 before 23 here
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;::</span>iterator it <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>find(x.begin(), x.end(), <span style="color:#ae81ff">23</span>);
</span></span><span style="display:flex;"><span>x.insert(it, <span style="color:#ae81ff">9</span>);
</span></span></code></pre></div><p>While this will work in C++-98, but since we don&rsquo;t modify the iterator <code>it</code>, using <code>const_iterators</code> is a better choice:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// C++-98: this won&#39;t compile
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Not using aliases here, C++-98 didn&#39;t have the support for aliases
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// (was introduced in C++-11)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Using these typedefs makes it easier to reuse them
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">typedef</span> std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;::</span>iterator it;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">typedef</span> std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;::</span>const_iterator c_it;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// C++-98, initializing a vector wasn&#39;t that trivial as it is now
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">const</span> <span style="color:#66d9ef">int</span> values[] <span style="color:#f92672">=</span> {<span style="color:#ae81ff">11</span>, <span style="color:#ae81ff">23</span>, <span style="color:#ae81ff">6</span>};
</span></span><span style="display:flex;"><span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> x (values, values<span style="color:#f92672">+</span><span style="color:#ae81ff">3</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>c_it ci <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>find(<span style="color:#66d9ef">static_cast</span><span style="color:#f92672">&lt;</span>c_it<span style="color:#f92672">&gt;</span>(x.begin()), <span style="color:#66d9ef">static_cast</span><span style="color:#f92672">&lt;</span>c_it<span style="color:#f92672">&gt;</span>(x.end()), <span style="color:#ae81ff">23</span>);
</span></span><span style="display:flex;"><span>x.insert(<span style="color:#66d9ef">static_cast</span><span style="color:#f92672">&lt;</span>it<span style="color:#f92672">&gt;</span>(ci), <span style="color:#ae81ff">9</span>);
</span></span></code></pre></div><p>If you compile the code snippet above using C++-98 (if you are using <code>g++</code>, use: <code>g++ &lt;filename&gt;.cpp -std=c++-98</code>), you will hopefully get an error similar to:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>main.cpp:<span style="color:#ae81ff">10</span><span style="color:#f92672">:</span><span style="color:#ae81ff">14</span><span style="color:#f92672">:</span> error: no matching conversion <span style="color:#66d9ef">for</span> <span style="color:#66d9ef">static_cast</span> from <span style="color:#960050;background-color:#1e0010">&#39;</span>c_it<span style="color:#960050;background-color:#1e0010">&#39;</span> (aka <span style="color:#960050;background-color:#1e0010">&#39;</span>__wrap_iter<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">const</span> <span style="color:#66d9ef">int</span> <span style="color:#f92672">*&gt;</span><span style="color:#960050;background-color:#1e0010">&#39;</span>) to <span style="color:#960050;background-color:#1e0010">&#39;</span>it<span style="color:#960050;background-color:#1e0010">&#39;</span> (aka <span style="color:#960050;background-color:#1e0010">&#39;</span>__wrap_iter<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span> <span style="color:#f92672">*&gt;</span><span style="color:#960050;background-color:#1e0010">&#39;</span>)
</span></span><span style="display:flex;"><span>    x.insert(<span style="color:#66d9ef">static_cast</span><span style="color:#f92672">&lt;</span>it<span style="color:#f92672">&gt;</span>(ci), <span style="color:#ae81ff">9</span>);
</span></span><span style="display:flex;"><span>             <span style="color:#f92672">^~~~~~~~~~~~~~~~~~~</span>
</span></span></code></pre></div><p>As you can probably notice, it says &ldquo;no matching coversion for <code>static_cast</code> from <code>c_it</code> to <code>it</code>&rdquo;, that means in C++-98 there was no straight forward way to cast <code>const_iterator</code> to <code>iterator</code>. The author does point that there are some reall non-trivial ways to get around, but those are out of the scope of this blog and the book as well.</p>
<p>A few observations in the snippet above:</p>
<ol>
<li>In <code>std::find</code> we cast <code>x.begin()</code> iterators to <code>const_iterator</code> (<code>c_it</code>) because in C++-98, there was no simple way to get a <code>const_iterator</code> from a non-const container.</li>
<li>The reason we cast our <code>const_iterator</code> (<code>ci</code>) back to <code>iterator</code> in the call <code>x.insert()</code> is: in C++-98, locations for insertions (and erasures) could only be specified by iterators, not const iterators.</li>
</ol>
<p>In fact, in C++-11, there is no simple way to convert <code>const_iterator</code> to <code>iterator</code>.</p>
<p>Here comes C++-11 now, they introduced <code>cbegin()</code> which returns a <code>const_iterator</code> instead, similarly <code>cend()</code> member function exists.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// In C++-11, initializing of a vector got easier
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> x {<span style="color:#ae81ff">11</span>, <span style="color:#ae81ff">23</span>, <span style="color:#ae81ff">6</span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// could have used auto here, but just typing the type for understanding 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Notice the use of cbegin(), cend() instead of static_cast&lt;c_it&gt;(x.begin()), ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;::</span>const_iterator ci <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>find(x.cbegin(), x.cend(), <span style="color:#ae81ff">23</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>x.insert(ci, <span style="color:#ae81ff">11</span>);
</span></span></code></pre></div><p>This will compile successfully, make sure to pass <code>-std=c++11</code> flag while compiling if you are using <code>g++</code> to make sure you are using C++-11.</p>
<p>It&rsquo;s near this time, isn&rsquo;t it?</p>
<p>Only place where C++-11 comes up a bit short is, when you want to use non-member functions (in case you are writing a generic code for your library, see example below):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// This is a generic function which will find targetVal in a container
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Use of decltype discussed before
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">template</span><span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> C, <span style="color:#66d9ef">typename</span> V<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> find_value(C<span style="color:#f92672">&amp;</span> container, <span style="color:#66d9ef">const</span> V<span style="color:#f92672">&amp;</span> targetVal) <span style="color:#f92672">-&gt;</span> <span style="color:#66d9ef">decltype</span>(std<span style="color:#f92672">::</span>begin(container)) {
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Notice the use of non-member cbegin and cend functions here
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// Note: member functions would have looked like: container.cbegin(), container.cend()
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">auto</span> it <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>find(std<span style="color:#f92672">::</span>cbegin(container), std<span style="color:#f92672">::</span>cend(container), targetVal);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> it;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>If you try to compile this using C++-11 <code>-std=c++11</code> flag, this will fail with an error like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>main.cpp:<span style="color:#ae81ff">6</span><span style="color:#f92672">:</span><span style="color:#ae81ff">25</span><span style="color:#f92672">:</span> error: no matching function <span style="color:#66d9ef">for</span> call to <span style="color:#960050;background-color:#1e0010">&#39;</span>begin<span style="color:#960050;background-color:#1e0010">&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> it <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>find(std<span style="color:#f92672">::</span>cbegin(container), std<span style="color:#f92672">::</span>cend(container), targetVal);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>main.cpp:<span style="color:#ae81ff">6</span><span style="color:#f92672">:</span><span style="color:#ae81ff">49</span><span style="color:#f92672">:</span> error: no matching function <span style="color:#66d9ef">for</span> call to <span style="color:#960050;background-color:#1e0010">&#39;</span>end<span style="color:#960050;background-color:#1e0010">&#39;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> it <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>find(std<span style="color:#f92672">::</span>cbegin(container), std<span style="color:#f92672">::</span>cend(container), targetVal);
</span></span></code></pre></div><p>In C++-11, they failed to add <code>cbegin, cend, rbegin, rend, crbegin, crend</code> as member functions (but <code>begin, end</code> were added). This was later rectified in C++-14, so if you compile the code above using <code>-std=c++14</code>, this won&rsquo;t fail anymore.</p>
<p>If you are using C++-11, you can get around by defining a <code>cbegin()</code> function:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">template</span><span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">C</span><span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> cbegin(<span style="color:#66d9ef">const</span> C<span style="color:#f92672">&amp;</span> container) <span style="color:#f92672">-&gt;</span> <span style="color:#66d9ef">decltype</span>(std<span style="color:#f92672">::</span>begin(container)) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> std<span style="color:#f92672">::</span>begin(container);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The reason using <code>std::begin</code> works here, because in C++-11, if you pass a reference to <code>const</code> version of the container to <code>std::begin</code>, it will return a <code>const_iterator</code> (notice that we pass <code>const C&amp; container</code> in the arguments).</p>
<p>The whole gist is to use <code>const_iterator</code> whenever possible. C++-14 tidied up the usage, however C++-11 added required support and features.</p>
<p>Thank you for reading!</p>
]]></content>
        </item>
        
        <item>
            <title>Declaring Overriding Functions override (Notes)</title>
            <link>https://krshrimali.github.io/posts/2021/09/declaring-overriding-functions-override-notes/</link>
            <pubDate>Sat, 25 Sep 2021 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2021/09/declaring-overriding-functions-override-notes/</guid>
            <description>NOTE
My notes on Chapter 3, Item 12 of Effective Modern C++ written by Scott Meyers.
Some (or even all) of the text can be similar to what you see in the book, as these are notes: I&amp;rsquo;ve tried not to be unnecessarily creative with my words. :)
Overriding != Overloading
Example of virtual function overriding:
// Base class class Base { public: virtual void doWork(); // ... }; // Derived class from Base class Derived: public Base { public: // virtual is optional // this will &amp;#34;override&amp;#34; Base::doWork virtual void doWork(); // .</description>
            <content type="html"><![CDATA[<hr>
<p><strong>NOTE</strong></p>
<p>My notes on Chapter 3, Item 12 of Effective Modern C++ written by Scott Meyers.</p>
<p>Some (or even all) of the text can be similar to what you see in the book, as these are notes: I&rsquo;ve tried not to be unnecessarily creative with my words. :)</p>
<hr>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/declaring-overriding-functions-override.png" alt=""></p>
<p>Overriding != Overloading</p>
<p><em>Example</em> of virtual function overriding:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Base class
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Base</span> {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">virtual</span> <span style="color:#66d9ef">void</span> doWork();
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Derived class from Base
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Derived</span><span style="color:#f92672">:</span> <span style="color:#66d9ef">public</span> Base {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// virtual is optional
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// this will &#34;override&#34; Base::doWork
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">virtual</span> <span style="color:#66d9ef">void</span> doWork();
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// This creates a &#34;Base&#34; class pointer to &#34;Derived&#34; class object
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>std<span style="color:#f92672">::</span>unique_ptr<span style="color:#f92672">&lt;</span>Base<span style="color:#f92672">&gt;</span> upb <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>make_unique<span style="color:#f92672">&lt;</span>Derived<span style="color:#f92672">&gt;</span>();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Derived doWork() function is invoked
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>upb<span style="color:#f92672">-&gt;</span>doWork();
</span></span></code></pre></div><p>This is how virtual function overriding allows to invoke a &ldquo;derived class function&rdquo; from a base class interface.</p>
<p><strong>Requirements for overriding</strong>:</p>
<ol>
<li>Base class function must be virtual.</li>
<li>Base and derived function names must be identical (except for destructors).</li>
<li>Parameter types of base and derived functions must be identical.</li>
<li>Constness of both base and derived functions must be identical.</li>
<li>The return types and exception specifications of the base and derived functions must be compatible.</li>
<li>[from C++11] Both functions should have identical reference qualifiers (see below)</li>
</ol>
<p>Reference qualifiers were new to me, but the book gives a really good example:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Useful when you want to limit the calls to lvalues or rvalues only
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Widget</span> {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">void</span> doWork() <span style="color:#f92672">&amp;</span>; <span style="color:#75715e">// Only when *this is an lvalue
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">doWork</span>() <span style="color:#f92672">&amp;&amp;</span>; <span style="color:#75715e">// Only when *this is an rvalue
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Suppose there is a makeWidget() function that returns an instance of Widget class, this will be an rvalue here
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>Widget <span style="color:#a6e22e">makeWidget</span>();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// lvalue
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>Widget w;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// this will call void doWork() &amp;;
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>w.doWork();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// this will call void doWork() &amp;&amp;;
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>makeWidget().doWork();
</span></span></code></pre></div><p>In case the functions don&rsquo;t have identical reference qualifiers, the derived class will <em>still have</em> the function, but it won&rsquo;t override the base class function.</p>
<p>Because of a lot of conditions (see 6 <em>requirements</em> above), it&rsquo;s easy to make mistakes or forget a few things while overriding a function. And the book states that it&rsquo;s not worth expecting from compiler to report an error, because the code can still be valid - it&rsquo;s just you expected it to override, but it didn&rsquo;t.</p>
<p>See an example below:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Base</span> {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">virtual</span> <span style="color:#66d9ef">void</span> mf1() <span style="color:#66d9ef">const</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">virtual</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">mf2</span>(<span style="color:#66d9ef">int</span> x);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">virtual</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">mf3</span>() <span style="color:#f92672">&amp;</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">mf4</span>() <span style="color:#66d9ef">const</span>;
</span></span><span style="display:flex;"><span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Derived</span><span style="color:#f92672">:</span> <span style="color:#66d9ef">public</span> Base {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">virtual</span> <span style="color:#66d9ef">void</span> mf1();
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">virtual</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">mf2</span>(<span style="color:#66d9ef">unsigned</span> <span style="color:#66d9ef">int</span> x);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">virtual</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">mf3</span>() <span style="color:#f92672">&amp;&amp;</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">mf4</span>() <span style="color:#66d9ef">const</span>;
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p>None of the functions in <code>Derived</code> class will override functions in the <code>Base</code> class. Why?</p>
<ol>
<li><code>mf1()</code>: declared <code>const</code> in <code>Base</code> but not in <code>Derived</code>.</li>
<li><code>mf2()</code>: arg <code>int</code> in <code>Base</code> but <code>unsigned int</code> in <code>Derived</code>.</li>
<li><code>mf3()</code>: lvalue-qualified in <code>Base</code> but rvalue-qualified in <code>Derived</code>.</li>
<li><code>mf4()</code>: isn&rsquo;t declared <code>virtual</code> in <code>Base</code>.</li>
</ol>
<p>To avoid worrying about human mistakes, it&rsquo;s better to let the compiler know explicitly that these functions are expected to override. For that, declare the functions in <code>Derived</code> class <code>override</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Derived</span><span style="color:#f92672">:</span> <span style="color:#66d9ef">public</span> Base {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">virtual</span> <span style="color:#66d9ef">void</span> mf1() <span style="color:#66d9ef">override</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">virtual</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">mf2</span>(<span style="color:#66d9ef">unsigned</span> <span style="color:#66d9ef">int</span> x) <span style="color:#66d9ef">override</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">virtual</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">mf3</span>() <span style="color:#f92672">&amp;&amp;</span> <span style="color:#66d9ef">override</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">virtual</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">mf4</span>() <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">override</span>;
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p>Now, this won&rsquo;t compile for sure no matter what compiler you are using.</p>
<p>C++-11 introduced  2 contextual keywords: <code>final</code> (see note below), <code>override</code>. These keywords are reserved, but only in certain contexts.</p>
<p><strong>Note:</strong> In case you want to prevent a function in a base class to be overridden in derived classes, you can declare them <code>final</code>. <code>final</code> can also be declared for a class, in which case it won&rsquo;t be allowed to be used a base class.</p>
<p>For <code>override</code>: In case your old (legacy) code uses <code>override</code> somewhere else, it&rsquo;s fine - keep it! Only when it&rsquo;s used at the end of a member function declaration, then it&rsquo;s reserved.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Sample</span> {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// legal
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">void</span> <span style="color:#66d9ef">override</span>();
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The chapter (item) ends with a brief about lvalue and rvalue reference member functions, which I would like to cover in another blog. For this blog, I think this should be good! :)</p>
<p>Thank you for reading.</p>
]]></content>
        </item>
        
        <item>
            <title>Prefer Deleted Functions to Private Undefined Ones (Notes)</title>
            <link>https://krshrimali.github.io/posts/2021/08/prefer-deleted-functions-to-private-undefined-ones-notes/</link>
            <pubDate>Wed, 25 Aug 2021 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2021/08/prefer-deleted-functions-to-private-undefined-ones-notes/</guid>
            <description>Prefer deleted functions to private undefined ones This item (11) in the chapter 3 focuses on:
Why and How to prevent users calling particular functions? C++-98 and C++-11 approach What&amp;rsquo;s the difference between deleting a function vs declaring a member function private (and not defining them)? NOTE
These are my notes on Chapter 3, Item 11 of Effective Modern C++ written by Scott Meyers.
Some (or even all) of the text can be similar to what you see in the book, as these are notes: I&amp;rsquo;ve tried not to be unnecessarily creative with my words.</description>
            <content type="html"><![CDATA[<h2 id="prefer-deleted-functions-to-private-undefined-ones">Prefer deleted functions to private undefined ones</h2>
<p>This item (11) in the chapter 3 focuses on:</p>
<ul>
<li>Why and How to prevent users calling particular functions?</li>
<li>C++-98 and C++-11 approach</li>
<li>What&rsquo;s the difference between deleting a function vs declaring a member function private (and not defining them)?</li>
</ul>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Item-11-Notes.png" alt=""></p>
<hr>
<p><strong>NOTE</strong></p>
<p>These are my notes on Chapter 3, Item 11 of Effective Modern C++ written by Scott Meyers.</p>
<p>Some (or even all) of the text can be similar to what you see in the book, as these are notes: I&rsquo;ve tried not to be unnecessarily creative with my words. :)</p>
<hr>
<ul>
<li>When is it required to delete a function/not define a private member function?</li>
</ul>
<p>Problem:</p>
<ul>
<li>Cases when you don&rsquo;t want the client to call a particular function.</li>
</ul>
<p>Solution:</p>
<ul>
<li>Just don&rsquo;t declare the function</li>
</ul>
<p>But&hellip;doesn&rsquo;t work always:</p>
<p><strong>Case:</strong> Special member functions generated by C++ automatically, discussed later). Examples considered in this blog:</p>
<ul>
<li>Copy Constructor</li>
<li>Copy Assignment Operator</li>
</ul>
<p><strong>C++-98 Approach</strong>:</p>
<ul>
<li>
<p>Declare these functions private and don&rsquo;t define them.</p>
</li>
<li>
<p><em>Example:</em></p>
<ul>
<li>All <code>istream</code> and <code>ostream</code> objects inherit (possibly) from <code>basic_ios</code> class in the C++ Standard Library.</li>
<li>Copying these objects is undersirable.</li>
</ul>
</li>
<li>
<p>Why is copying objects of <code>istream</code> and <code>ostream</code> undesirable? [Also see <a href="https://stackoverflow.com/questions/8785730/cannot-assign-or-copy-iostream-object">this</a> question on stackoverflow]</p>
<ul>
<li><code>istream</code> object: represents stream of input values.
<ul>
<li>some might have been read before.</li>
<li>and some may be read later.</li>
</ul>
</li>
<li>If you copy <code>istream</code> object:
<ul>
<li>Will that copy those values which have been read before?</li>
<li>Or will also copy values which are to be read later?</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>Hence, it&rsquo;s just better to not allow copying <code>istream</code> or <code>ostream</code> objects.</p>
<h2 id="in-c-98">In C++-98:</h2>
<p>Reminder (from above): All <code>istream</code> and <code>ostream</code> objects inherit from <code>basic_ios</code> class (possibly) in the C++ standard, and the <code>basic_ios</code> class in C++-98 looks something like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">charT</span>, <span style="color:#66d9ef">class</span> <span style="color:#a6e22e">traits</span> <span style="color:#f92672">=</span> char_traits<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;</span> <span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">basic_ios</span> <span style="color:#f92672">:</span> <span style="color:#66d9ef">public</span> ios_base {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Declaring the copy constructor and copy assignment operator private prohibits clients from calling them
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">private</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    basic_ios(<span style="color:#66d9ef">const</span> basic_ios<span style="color:#f92672">&amp;</span>);  <span style="color:#75715e">// not defined
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    basic_ios<span style="color:#f92672">&amp;</span> <span style="color:#66d9ef">operator</span><span style="color:#f92672">=</span>(<span style="color:#66d9ef">const</span> basic_ios<span style="color:#f92672">&amp;</span>);  <span style="color:#75715e">// not defined
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>};
</span></span></code></pre></div><p>Note that:</p>
<ul>
<li><code>basic_ios(const basic_ios&amp;)</code> is the copy constructor</li>
<li><code>basic_ios&amp; operator=(const basic_ios&amp;)</code> is the copy assignment operator</li>
</ul>
<p>(and both are <code>private</code>).</p>
<p>How does <em>not defining</em> these functions help?</p>
<ul>
<li>Consider a case where a <code>friend</code> class or member functions try accessing these functions, then linking will fail because of missing function definitions.</li>
</ul>
<h2 id="in-c-11">In C++-11</h2>
<p>In C++-11, the above can be done using <code>= delete</code> to mark the copy constructor and the copy assignment operator as <em>deleted</em> functions.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">charT</span>, <span style="color:#66d9ef">class</span> <span style="color:#a6e22e">traits</span> <span style="color:#f92672">=</span> char_traits<span style="color:#f92672">&lt;</span>charT<span style="color:#f92672">&gt;</span> <span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">basic_ios</span> <span style="color:#f92672">:</span> <span style="color:#66d9ef">public</span> ios_base {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    basic_ios(<span style="color:#66d9ef">const</span> basic_ios<span style="color:#f92672">&amp;</span> ) <span style="color:#f92672">=</span> <span style="color:#66d9ef">delete</span>;  <span style="color:#75715e">// deleted function
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    basic_ios<span style="color:#f92672">&amp;</span> <span style="color:#66d9ef">operator</span><span style="color:#f92672">=</span>(<span style="color:#66d9ef">const</span> basic_ios<span style="color:#f92672">&amp;</span>) <span style="color:#f92672">=</span> <span style="color:#66d9ef">delete</span>;  <span style="color:#75715e">// deleted function
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>};
</span></span></code></pre></div><p>It&rsquo;s a convention to declare <em>deleted</em> functions <code>public</code>, but why? Better error messages.</p>
<p>In case you declare your <em>deleted</em> functions <code>private</code>, some compilers will probably complain about the function being <code>private</code> and can hide the error message of it not being usable (because it being <code>deleted</code>). Hence, it&rsquo;s a <em>good practice</em> to make them <code>public</code>:</p>
<p>From my experience though, Apple&rsquo;s clang compiler (v 12.0.5) doesn&rsquo;t complain about it being <code>private</code>, but then - it can vary from compiler to compiler, so better to play safe. Here is an example of how the error message looks like:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;iostream&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Sample</span> {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    Sample(<span style="color:#66d9ef">int</span> x) <span style="color:#f92672">:</span> x(x) { };
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Copy constructor has been deleted, so should not be callable
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    Sample(<span style="color:#66d9ef">const</span> Sample<span style="color:#f92672">&amp;</span>) <span style="color:#f92672">=</span> <span style="color:#66d9ef">delete</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">trying_copy_construct</span>(Sample s) {
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// This function tries to use a copy constructor
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#75715e">// This should fail
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        Sample new_object(s);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">private</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> x;
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p>Compiling the above code fails with the following error:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>main.cpp:<span style="color:#ae81ff">10</span><span style="color:#f92672">:</span><span style="color:#ae81ff">16</span><span style="color:#f92672">:</span> error: call to deleted constructor of <span style="color:#960050;background-color:#1e0010">&#39;</span>Sample<span style="color:#960050;background-color:#1e0010">&#39;</span>
</span></span><span style="display:flex;"><span>        Sample new_object(s);
</span></span><span style="display:flex;"><span>               <span style="color:#f92672">^</span>          <span style="color:#f92672">~</span>
</span></span><span style="display:flex;"><span>main.cpp:<span style="color:#ae81ff">6</span><span style="color:#f92672">:</span><span style="color:#ae81ff">5</span><span style="color:#f92672">:</span> note: <span style="color:#960050;background-color:#1e0010">&#39;</span>Sample<span style="color:#960050;background-color:#1e0010">&#39;</span> has been explicitly marked deleted here
</span></span><span style="display:flex;"><span>    Sample(<span style="color:#66d9ef">const</span> Sample<span style="color:#f92672">&amp;</span>) <span style="color:#f92672">=</span> <span style="color:#66d9ef">delete</span>;
</span></span></code></pre></div><h2 id="difference-bw-using-delete-vs-declaring-private">Difference b/w using delete vs declaring private</h2>
<p>Note: There is more to it except the <em>good practice</em> reasoning.</p>
<ul>
<li>Using a <em>deleted</em> function in a member function or by a <code>friend</code> class won&rsquo;t even compile the code if it tries to copy <code>basic_ios</code> objects <em>while</em> declaring <code>private</code> will compile successfully but fail during link-time.</li>
<li>Conventionally deleted functions are declared <code>public</code>, not <code>private</code> while the C++-98 way requires the functions to be declared private (see the section above for reasoning).</li>
<li>Only member functions can be private, while <em>any</em> function can be deleted (so you can delete some overloads for your function, in case you don&rsquo;t want it to accept certain type inputs).</li>
</ul>
<p>Let&rsquo;s discuss the last point in detail:</p>
<p>Consider the case where you have:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">template</span><span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> T<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">void</span> processPointer(T<span style="color:#f92672">*</span> ptr);
</span></span></code></pre></div><p>And:</p>
<ul>
<li>You need a template that works with built-in pointers. You want to reject calls with <code>void*</code> and <code>char*</code> pointers (more on this later, these deserve special handling at times).</li>
<li>Ideal way? Delete these instantiations (with <code>void*</code> or <code>char*</code> input pointers).</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">template</span><span style="color:#f92672">&lt;&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">void</span> processPointer<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">void</span><span style="color:#f92672">&gt;</span>(<span style="color:#66d9ef">void</span><span style="color:#f92672">*</span>) <span style="color:#f92672">=</span> <span style="color:#66d9ef">delete</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">template</span><span style="color:#f92672">&lt;&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">void</span> processPointer<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">char</span><span style="color:#f92672">&gt;</span>(<span style="color:#66d9ef">char</span><span style="color:#f92672">*</span>) <span style="color:#f92672">=</span> <span style="color:#66d9ef">delete</span>;
</span></span></code></pre></div><p>But, with C++-98 way, it&rsquo;s not possible within the class scope. That is, you can not give template specialization to your member function within the class scope (it should be done in the namespace scope):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Sample</span> {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> T<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">void</span> processPointer(T<span style="color:#f92672">*</span> ptr)
</span></span><span style="display:flex;"><span>    { ... }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">private</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// This is template specialization inside the scope of the class - not allowed
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">void</span> processPointer<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">void</span><span style="color:#f92672">&gt;</span>(<span style="color:#66d9ef">void</span><span style="color:#f92672">*</span>);  <span style="color:#75715e">// error
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>};
</span></span></code></pre></div><p>While with the C++-11 way, you can delete function outside the <code>class</code> scope:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Sample</span> {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> T<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">void</span> processPointer(T<span style="color:#f92672">*</span> ptr)
</span></span><span style="display:flex;"><span>    { ... }
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">void</span> Sample<span style="color:#f92672">::</span>processPointer<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">void</span><span style="color:#f92672">&gt;</span>(<span style="color:#66d9ef">void</span><span style="color:#f92672">*</span>) <span style="color:#f92672">=</span> <span style="color:#66d9ef">delete</span>;  <span style="color:#75715e">// in public scope, and deleted!
</span></span></span></code></pre></div><p>I hope you liked this blog, thank you for reading! :)</p>
]]></content>
        </item>
        
        <item>
            <title>Prefer Scoped Enums over Unscoped Enums (Notes)</title>
            <link>https://krshrimali.github.io/posts/2021/08/prefer-scoped-enums-over-unscoped-enums-notes/</link>
            <pubDate>Sat, 14 Aug 2021 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2021/08/prefer-scoped-enums-over-unscoped-enums-notes/</guid>
            <description>Scoped vs Unscoped Enums General rule: declaring a name inside curly braces is limited to that scope. Exception: C++-98 style Enums NOTE
My notes on Chapter 3, Item 10 of Effective Modern C++ written by Scott Meyers.
Some (or even all) of the text can be similar to what you see in the book, as these are notes: I&amp;rsquo;ve tried not to be unnecessarily creative with my words. :)
// You can&amp;#39;t declare black, white, red in the scope containing the enum Color enum Color { black, white, red; }; auto white = false; // error: white already declared in this scope Unscoped Enums have implicit type conversions for their enumerators.</description>
            <content type="html"><![CDATA[<h2 id="scoped-vs-unscoped-enums">Scoped vs Unscoped Enums</h2>
<ul>
<li><strong>General rule:</strong> declaring a name inside curly braces is limited to that scope.</li>
<li><strong>Exception:</strong> C++-98 style Enums</li>
</ul>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Unscoped-Scoped-Enums.png" alt=""></p>
<hr>
<p><strong>NOTE</strong></p>
<p>My notes on Chapter 3, Item 10 of Effective Modern C++ written by Scott Meyers.</p>
<p>Some (or even all) of the text can be similar to what you see in the book, as these are notes: I&rsquo;ve tried not to be unnecessarily creative with my words. :)</p>
<hr>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// You can&#39;t declare black, white, red in the scope containing the enum Color
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">enum</span> <span style="color:#a6e22e">Color</span> {
</span></span><span style="display:flex;"><span>    black, white, red;
</span></span><span style="display:flex;"><span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> white <span style="color:#f92672">=</span> false; <span style="color:#75715e">// error: white already declared in this scope
</span></span></span></code></pre></div><ul>
<li>Unscoped Enums have implicit type conversions for their enumerators.</li>
<li>Enumerators can implicitly convert to integral types, and then to floating-point types.</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Assume Color is declared like above
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>Color c <span style="color:#f92672">=</span> red; <span style="color:#75715e">// valid since Enumerator white is leaked to the scope Color is in
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">if</span> (c <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">10</span>) {  <span style="color:#75715e">// valid, implicit conversion
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// ... do something
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>}
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">else</span> <span style="color:#a6e22e">if</span> (c <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">10.5</span>) {  <span style="color:#75715e">// also valid, implicit conversion
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// ... do something
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>}
</span></span></code></pre></div><p>The C++-98 Style Enums are termed as Unscoped Enums (because of leaking names).</p>
<p><strong>C++-11 Scoped Enums</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// black, white, red are now scoped to Color Enum
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">enum</span> <span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Color</span> {
</span></span><span style="display:flex;"><span>    black, white, red;
</span></span><span style="display:flex;"><span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// This is now valid
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">auto</span> white <span style="color:#f92672">=</span> false;
</span></span></code></pre></div><p>Separately, if you do: (consider <code>Color</code> Enum has already been declared)</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>Color c <span style="color:#f92672">=</span> white; <span style="color:#75715e">// error: no enumerator named &#34;white&#34; is in this scope
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>Color c <span style="color:#f92672">=</span> Color<span style="color:#f92672">::</span>white; <span style="color:#75715e">// valid
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">auto</span> c <span style="color:#f92672">=</span> Color<span style="color:#f92672">::</span>white; <span style="color:#75715e">// valid
</span></span></span></code></pre></div><ul>
<li>Also referred as enum classes (because declared using <code>enum class</code>).</li>
<li>Enumerators in scoped Enums are strongly typed (no implicit type conversion)</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Assume Color is declared as above using enum class
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>Color c <span style="color:#f92672">=</span> Color<span style="color:#f92672">::</span>red;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (c <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">10.5</span>) {  <span style="color:#75715e">// Error! can&#39;t compare Color and double
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// do something...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>}
</span></span></code></pre></div><p><strong>Note:</strong> you can do explicit casting using <code>cast</code>.
<strong>Note about enums in C++:</strong>
* Every enum in C++ has an integral underlying type that is determined by compilers.
* Compilers need to know the size of enum before using it.</p>
<h2 id="c98-vs-c11-on-enums">C++98 vs C++11 on Enums</h2>
<p><strong>C++98:</strong></p>
<ul>
<li>Unscoped enums can not be forward-declared.
<ul>
<li>Hence only enums with definitions are supported.</li>
<li>Allows compilers to choose underlying type for each enum prior to the enum being used.</li>
</ul>
</li>
<li>Drawbacks?
<ul>
<li>Increase in compilation dependencies: wherever the enum is used, even if not affected by any addition in the enum, it will be recompiled (generally speaking, that is without any tweaks/optimizations).</li>
</ul>
</li>
</ul>
<p><strong>C++11:</strong></p>
<ul>
<li>Both unscoped and scoped enums can be forward-declared. Unscoped enums will need a few efforts though:</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">/* For Scoped Enums */</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Default underlying type is int
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">enum</span> <span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Status</span>; 
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Override it
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">enum</span> <span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Status</span><span style="color:#f92672">:</span> std<span style="color:#f92672">::</span><span style="color:#66d9ef">uint32_t</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">/* For Unscoped Enums */</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// There is no underlying type for unscoped enum
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// You can manually specify though
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">enum</span> <span style="color:#a6e22e">Status</span><span style="color:#f92672">:</span> sd<span style="color:#f92672">::</span><span style="color:#66d9ef">uint32_t</span>;
</span></span></code></pre></div><p><em>These specifications for underlying types can also go on enum&rsquo;s definitions.</em></p>
<h2 id="unscoped-enums-over-scoped-enums">Unscoped Enums over Scoped Enums?</h2>
<p>Imagine when you have a code like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Ordered as: name, email, reputation
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">using</span> UserInfo <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>tuple<span style="color:#f92672">&lt;</span>std<span style="color:#f92672">::</span>string, std<span style="color:#f92672">::</span>string, std<span style="color:#f92672">::</span>size_t<span style="color:#f92672">&gt;</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>UserInfo uInfo;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// This is not clear to the reader, you can&#39;t always remember what 1st indexed field in UserInfo is
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">auto</span> val <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>get<span style="color:#f92672">&lt;</span><span style="color:#ae81ff">1</span><span style="color:#f92672">&gt;</span>(uInfo);
</span></span></code></pre></div><p>Using the property of intrinsic conversion in unscoped enums, you can solve this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">enum</span> <span style="color:#a6e22e">InfoFields</span> { uName, uEmail, uReputation };
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// UserInfo defined as above
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>UserInfo uInfo;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Implicit conversion of int (default underlying type of enums) to std::size_t (that&#39;s what std::get takes)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">auto</span> val <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>get<span style="color:#f92672">&lt;</span>uEmail<span style="color:#f92672">&gt;</span>(uInfo);
</span></span></code></pre></div><p>For scoped enums though, you&rsquo;ll have to use <code>static_cast&lt;std::size_t&gt;(InfoFields::uEmail)</code> instead of just <code>uEmail</code> (for unscoped enums) passed to <code>std::get</code>, which is less readable. But&hellip;</p>
<p>This can be redued by using a custom function which:
* takes: enum
* returns: corresponding <code>std::size_t</code> value</p>
<p><code>std::get</code> is a template, and the value needs to be understood during compilation only, so the function should be a <code>constexpr</code> (more on this later in the series).</p>
<p>To generalize, let&rsquo;s keep the enum&rsquo;s underlying type (<code>std::underlying_type</code> type trait)</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Using noexcept because we know there&#39;ll be no exceptions raised
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> E<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">constexpr</span> <span style="color:#66d9ef">typename</span> std<span style="color:#f92672">::</span>underlying_type<span style="color:#f92672">&lt;</span>E<span style="color:#f92672">&gt;::</span>type toUType(E enumerator) <span style="color:#66d9ef">noexcept</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#66d9ef">static_cast</span><span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> std<span style="color:#f92672">::</span>underlying_type<span style="color:#f92672">&lt;</span>E<span style="color:#f92672">&gt;::</span>type<span style="color:#f92672">&gt;</span>(enumerator);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>From the <a href="https://krshrimali.github.io/Alias-Declarations-over-Typedefs-CPP/">previous blog</a>, we know that in C++14, we could have simplified by writing:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Using noexcept because we know there&#39;ll be no exceptions raised
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> E<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">constexpr</span> std<span style="color:#f92672">::</span>underlying_type_t<span style="color:#f92672">&lt;</span>E<span style="color:#f92672">&gt;</span> toUType(E enumerator) <span style="color:#66d9ef">noexcept</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#66d9ef">static_cast</span><span style="color:#f92672">&lt;</span>std<span style="color:#f92672">::</span>underlying_type_t<span style="color:#f92672">&lt;</span>E<span style="color:#f92672">&gt;&gt;</span>(enumerator);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Could have used <code>auto</code> for return type in C++14:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Using noexcept because we know there&#39;ll be no exceptions raised
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> E<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">constexpr</span> <span style="color:#66d9ef">auto</span> toUType(E enumerator) <span style="color:#66d9ef">noexcept</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#66d9ef">static_cast</span><span style="color:#f92672">&lt;</span>std<span style="color:#f92672">::</span>underlying_type_t<span style="color:#f92672">&lt;</span>E<span style="color:#f92672">&gt;&gt;</span>(enumerator);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Now this can be used as:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Reminder, InfoFields was defined as:
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">enum</span> <span style="color:#a6e22e">InfoFields</span> { uName, uEmail, uReputation };
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// toUType is defined above
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">auto</span> val <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>get<span style="color:#f92672">&lt;</span>toUType(InfoFields<span style="color:#f92672">::</span>uEmail)<span style="color:#f92672">&gt;</span>(uInfo);
</span></span></code></pre></div><h2 id="good-reads">Good Reads</h2>
<ol>
<li>Forward Declaration:
<ul>
<li>Stackoverflow: <a href="https://stackoverflow.com/questions/4757565/what-are-forward-declarations-in-c">https://stackoverflow.com/questions/4757565/what-are-forward-declarations-in-c</a></li>
</ul>
</li>
<li>Are Unscoped Enums still helpful?
<ul>
<li>Stackoverflow: <a href="https://stackoverflow.com/questions/27320603/are-unscoped-enumerations-still-useful">https://stackoverflow.com/questions/27320603/are-unscoped-enumerations-still-useful</a></li>
</ul>
</li>
<li>Proposal for forward declaration to enums (accepted), dated 2008: <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2764.pdf">http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2008/n2764.pdf</a></li>
<li>Forward Declaring an Enum in C++?
<ul>
<li>Stackoverflow: <a href="https://stackoverflow.com/questions/71416/forward-declaring-an-enum-in-c">https://stackoverflow.com/questions/71416/forward-declaring-an-enum-in-c</a></li>
</ul>
</li>
</ol>
<h2 id="acknowledgement-reviews">Acknowledgement (Reviews)</h2>
<p>Thanks to <a href="https://kshitij12345.github.io/">Kshitij Kalambarkar</a> for helping in reviewing the blog. It&rsquo;s always helpful to get another set of eyes to what you write. :)</p>
<p>That&rsquo;s it for this blog, thank you for reading everyone!</p>
]]></content>
        </item>
        
        <item>
            <title>Union Find Problem, and a naive implementation (C&#43;&#43;)</title>
            <link>https://krshrimali.github.io/posts/2021/08/union-find-problem-and-a-naive-implementation-c-/</link>
            <pubDate>Sat, 14 Aug 2021 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2021/08/union-find-problem-and-a-naive-implementation-c-/</guid>
            <description>Hi Everyone, today I want to talk about Union Find Problem. This is going to be a series covering:
Union Find Problem (this blog) Solutions to Union Find (1): Quick Find Solutions to Union Find (2): Quick Union Solutions to Union Find (3): Weighted Quick Union Applications of Union Find (perculation and more) Cool project using Union Find Solving some competitive programming questions using Union Find Each blog will try to cover very basic concepts behind the topic, and also what it&amp;rsquo;s all about.</description>
            <content type="html"><![CDATA[<p>Hi Everyone, today I want to talk about Union Find Problem. This is going to be a series covering:</p>
<ul>
<li>Union Find Problem (this blog)</li>
<li>Solutions to Union Find (1): Quick Find</li>
<li>Solutions to Union Find (2): Quick Union</li>
<li>Solutions to Union Find (3): Weighted Quick Union</li>
<li>Applications of Union Find (perculation and more)</li>
<li>Cool project using Union Find</li>
<li>Solving some competitive programming questions using Union Find</li>
</ul>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Union-Find-Intro.png" alt=""></p>
<p>Each blog will try to cover very basic concepts behind the topic, and also what it&rsquo;s all about.</p>
<h2 id="union-find-problem-definition">Union Find Problem: Definition</h2>
<p>Let&rsquo;s define the problem first. It&rsquo;s a problem where you need to find whether two points/objects are in a connected relationship (defined below) or not in a defined environment (where you know the relationships).</p>
<p>Connection Relationship is an equivalence relation, which means:</p>
<ul>
<li>It&rsquo;s reflexive: <code>a ~ a</code> (a is connected to itself)</li>
<li>It&rsquo;s symmetric: <code>a ~ b iff b ~ a</code> (a is connected to b iff b is connected to a OR if a is connected to b, b is also connected to a)</li>
<li>It&rsquo;s transitive: <code>if a ~ b and b ~c then a ~ c</code> (if a is connected to b, and b is connected to c, then a is connected to c)</li>
</ul>
<p>And by <em>connected</em>, we just mean that there is a path between the two objects. My thinking around this problem is mostly surrounded by the plot of dynamic connectivity, where you want to find if there is a connection between 2 objects in a graph. These objects can be friends (whether A and B are friends or not in a circle - here circle is the environment).</p>
<h2 id="union-find-problem-why-study-it">Union Find: Problem, why study it?</h2>
<p>It&rsquo;s a name to a problem, but you must have encountered this in real life. Whether you are a friend to your ex, oh definitely not ;) (even if Union Find solution finds a connection, trust me - move on :P). Okay, on a serious note now:</p>
<p>Union Find Problem is seen in lots of applications:</p>
<ul>
<li>Perculation (example: if you pour water on the top of a tank having lots of cells/blocks - some are open, some are closed - will it reach the bottom?).
<ul>
<li>I also see this as an application where you want to find if the leakage in a whole network of oil pipes will exit or if it will be blocked.</li>
</ul>
</li>
<li>Dynamic Connectivity: A very simple definition would be, whether there is a connection between two objects?
<ul>
<li>You can see it&rsquo;s application in social media, whether two objects (I know I should use <em>humans</em> but the whole internet objectifies you ;), hence objects ;)).</li>
<li>Whether there is a connection between two places in a nation or not?</li>
</ul>
</li>
<li>Games (will be discussed later)</li>
<li>and more&hellip;</li>
</ul>
<p>Now it&rsquo;s indeed a very interesting problem, and in this blog, I&rsquo;ll show you a very basic implementation which I wrote before studying the algorithms which attempt to solve this problem.</p>
<h2 id="union-find-breakdown-union-and-find">Union Find breakdown: Union and Find</h2>
<hr>
<p><strong>NOTE</strong></p>
<p>All codes are written here in C++ and code is available here: <a href="https://github.com/krshrimali/Algorithms-All-In-One/">https://github.com/krshrimali/Algorithms-All-In-One/</a>.</p>
<hr>
<p>Breaking it down to two functions, is really helpful:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Object is an arbitrary type for now, can be an int, can be a user defined type as well
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">union</span>(Object a, Object b) {
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// This function will connect two objects, if:
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">//      * they exist
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">//      * there isn&#39;t a connection already
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>}
</span></span></code></pre></div><p>Similarly, the <code>find</code> function will try to find whether there is a connection between two objects:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Object is an arbitrary type for now, can be an int, can be a user defined type as well
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">bool</span> <span style="color:#a6e22e">find</span>(Object a, Object b) {
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// returns true if:
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">//      * both objects exist
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">//      * and they are connected
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// else returns false
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>}
</span></span></code></pre></div><p>Let&rsquo;s try to setup the environment first, and we need to answer these two questions first:</p>
<ul>
<li>What should be the objects?</li>
<li>Where are these objects stored?</li>
</ul>
<p>I like thinking of this as a graph (environment) and points as objects. So let&rsquo;s start implementing.</p>
<h2 id="implementation-modelling">Implementation: Modelling</h2>
<hr>
<p><strong>NOTE</strong></p>
<p>This is a very basic implementation and first try presenting a naive solution to the problem, we&rsquo;ll discuss better algorithms in next blogs.</p>
<hr>
<p>The very first question you should ask yourself is, what data structures should be used for <code>Graph</code> and <code>Point</code>(s)? The way I&rsquo;m thinking of solving this is:</p>
<ol>
<li>Each <code>Point</code> will have <code>(x, y)</code> coordinates. (so coordinates will be it&rsquo;s property)</li>
<li>Whenever two points are merged (<code>union</code> is called), the first point will append the second point in it&rsquo;s list of connections.
<ul>
<li>So each <code>Point</code> object will have a connection list. (<code>std::vector</code>?)</li>
</ul>
</li>
<li>Whenever <code>find</code> is called, that is - there is an attempt to find <em>if</em> there is a connection between two points?
<ul>
<li>We just need to search if second point is there in the first point&rsquo;s connection list. If it is, then there is a connection. And if not, then no connection.</li>
<li>In python, I would have used a <code>dict</code>, so I went ahead with <code>std::map</code> in C++, will help me not duplicating points.</li>
</ul>
</li>
</ol>
<p>So the <code>Graph</code> will be a <code>std::map</code> of <code>Point, std::vector&lt;Point&gt;</code>, which will look something like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// This is how graph will look like, in imagination
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// Example:
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// a is connected to b, c, d
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// b is connected to a
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>(Point a, {Point b, Point c, Point d}),
</span></span><span style="display:flex;"><span>(Point b, {Point a}),
</span></span><span style="display:flex;"><span>...so on
</span></span></code></pre></div><p>As you can see, there will be a list mapped to each Point, we call that list: <em>connection list</em>.</p>
<p>Now, the <code>Point</code> can simply be a <code>struct</code> having <code>int x, y</code> as coordinates.</p>
<h2 id="implementation-skeleton">Implementation: Skeleton</h2>
<p>Let&rsquo;s create the skeleton now:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">Point</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// x and y are the coordinates for each point
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">int</span> x, y;
</span></span><span style="display:flex;"><span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Graph will contain Points, helper functions: union and merge
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Graph</span> {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">private</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>map<span style="color:#f92672">&lt;</span>Point, std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span>Point<span style="color:#f92672">&gt;&gt;</span> graph;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// We take references to avoid internal copies, const is used since we don&#39;t want these functions
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// to modify these points in any way
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">void</span> union_(<span style="color:#66d9ef">const</span> Point<span style="color:#f92672">&amp;</span> a, <span style="color:#66d9ef">const</span> Point<span style="color:#f92672">&amp;</span> b) {
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Use find utility function of std::map
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#66d9ef">if</span> (<span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>graph.find(a) <span style="color:#f92672">==</span> <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>graph.end()) {
</span></span><span style="display:flex;"><span>            <span style="color:#75715e">// Not found
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>            <span style="color:#75715e">// Means create an entry in the graph, and add b to the connection list of a
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>            <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>graph[a] <span style="color:#f92672">=</span> {b};
</span></span><span style="display:flex;"><span>        } <span style="color:#66d9ef">else</span> {
</span></span><span style="display:flex;"><span>            <span style="color:#75715e">// Found
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>            <span style="color:#75715e">// Append b to the connection list of a
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>            <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>graph.at(a).push_back(b);
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Are a and b connected? OR Is there a path b/w a and b?
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">bool</span> <span style="color:#a6e22e">find_</span>(<span style="color:#66d9ef">const</span> Point<span style="color:#f92672">&amp;</span> a, <span style="color:#66d9ef">const</span> Point<span style="color:#f92672">&amp;</span> b) {
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// First check if there is an Point a in the graph
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#66d9ef">if</span> (<span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>graph.find(a) <span style="color:#f92672">==</span> <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>graph.end()) {
</span></span><span style="display:flex;"><span>            std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Not found</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>;
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> false;
</span></span><span style="display:flex;"><span>        } <span style="color:#66d9ef">else</span> {
</span></span><span style="display:flex;"><span>            <span style="color:#75715e">// Object found
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>            std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span>Point<span style="color:#f92672">&gt;</span> connection_list <span style="color:#f92672">=</span> <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>graph.at(a);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e">// Now find if b exists in the connection list, if yes then there is a connection
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>            <span style="color:#66d9ef">if</span> (std<span style="color:#f92672">::</span>find(connection_list.begin(), connection_list.end(), b) <span style="color:#f92672">!=</span> connection_list.end()) {
</span></span><span style="display:flex;"><span>                <span style="color:#75715e">// b found
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>                <span style="color:#66d9ef">return</span> true;
</span></span><span style="display:flex;"><span>            }
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">return</span> false;
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Usage
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>() {
</span></span><span style="display:flex;"><span>    Graph g_sample;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">Point</span> p(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">Point</span> q(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">3</span>);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">Point</span> r(<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">4</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Add a connection for (p, q) and (p, r), for testing
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    g_sample.union_(p, q);
</span></span><span style="display:flex;"><span>    g_sample.union_(p, r);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Are p and q connected? Answer: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> sampleGraph.find_(p, q) <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#39;\n&#39;</span>;  <span style="color:#75715e">// Expected: true
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Are p and r connected? Answer: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> sampleGraph.find_(p, r) <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#39;\n&#39;</span>;  <span style="color:#75715e">// Expected; true
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Are q and r connected? Answer: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> sampleGraph.find_(q, r) <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#39;\n&#39;</span>;  <span style="color:#75715e">// Expected: false
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>}
</span></span></code></pre></div><p>Now this is a great start, I won&rsquo;t spend time explaining the code as the comments should help. In case you have queries, please feel free to open an issue <a href="https://github.com/krshrimali/Algorithms-All-In-One/issues">here</a>.</p>
<p>But this won&rsquo;t compile. And the reason is, that when you are using <code>std::find</code> with user-defined types like <code>Point</code>, you need to define <code>&lt;</code> operator or give it a comparator because it does some comparisons. Think of this like:</p>
<p>The compiler isn&rsquo;t aware of how to do: Point(2, 3) &lt; Point(3, 3)</p>
<p>Because for the compiler, both of these are an object. So we need to tell it explicitly, that hey! when you do <code>&lt;</code> operation on <code>Point</code> objects, check their coordinates.</p>
<h2 id="final-implementation">Final Implementation</h2>
<p>The final code can be found <a href="https://github.com/krshrimali/Algorithms-All-In-One/blob/main/Union-Find/main.cpp">here</a>. There are a few TODOs in the code mentioned, and in case you want to pick them up, please create a PR for the same. :)</p>
<p>The code will change with time, so I&rsquo;ll refrain copy-pasting it here.</p>
<h2 id="homework">Homework?</h2>
<p>Let&rsquo;s do this before I release the next blog:</p>
<ul>
<li>Analyze the algorithm used here, it&rsquo;s time and space complexity.</li>
<li>Address the TODOs in the <a href="https://github.com/krshrimali/Algorithms-All-In-One/blob/main/Union-Find/main.cpp">code</a>.</li>
</ul>
<p>In case you are able to do this before my next blog, kudos to you! You might as well help creating a PR, that will be great.</p>
<p>Thank you for reading this blog. I hope you liked it! :)</p>
]]></content>
        </item>
        
        <item>
            <title>Prefer Alias Declarations to Typedefs (Notes)</title>
            <link>https://krshrimali.github.io/posts/2021/08/prefer-alias-declarations-to-typedefs-notes/</link>
            <pubDate>Thu, 12 Aug 2021 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2021/08/prefer-alias-declarations-to-typedefs-notes/</guid>
            <description>&lt;p&gt;One solution to avoiding using long type names:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;// So C++98 like
&lt;/span&gt;&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#75715e&#34;&gt;&lt;/span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;typedef&lt;/span&gt; std&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;unique_ptr&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;std&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;unordered_map&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;std&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;string, std&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;string&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&amp;gt;&lt;/span&gt; UPtrMapSS;
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</description>
            <content type="html"><![CDATA[<p>One solution to avoiding using long type names:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// So C++98 like
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">typedef</span> std<span style="color:#f92672">::</span>unique_ptr<span style="color:#f92672">&lt;</span>std<span style="color:#f92672">::</span>unordered_map<span style="color:#f92672">&lt;</span>std<span style="color:#f92672">::</span>string, std<span style="color:#f92672">::</span>string<span style="color:#f92672">&gt;&gt;</span> UPtrMapSS;
</span></span></code></pre></div><p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/alias-declarations-typedefs.png" alt=""></p>
<hr>
<p><strong>NOTE</strong></p>
<p>My notes on Chapter 3, Item 9 of Effective Modern C++ written by Scott Meyers.</p>
<p>Some (or even all) of the text can be similar to what you see in the book, as these are notes: I&rsquo;ve tried not to be unnecessarily creative with my words. :)</p>
<hr>
<p>C++11 also offers alias declarations:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">using</span> UPtrMapSS <span style="color:#f92672">=</span> <span style="color:#66d9ef">typedef</span> std<span style="color:#f92672">::</span>unique_ptr<span style="color:#f92672">&lt;</span>std<span style="color:#f92672">::</span>unordered_map<span style="color:#f92672">&lt;</span>std<span style="color:#f92672">::</span>string, std<span style="color:#f92672">::</span>string<span style="color:#f92672">&gt;&gt;</span>;
</span></span></code></pre></div><p>Advantages of alias declarations over typedefs:</p>
<ol>
<li>
<p>For types involving function pointers, aliases are easier to read (for some people):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// typedef
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">typedef</span> <span style="color:#a6e22e">void</span> (<span style="color:#f92672">*</span>FP)(<span style="color:#66d9ef">int</span>, <span style="color:#66d9ef">const</span> std<span style="color:#f92672">::</span>string<span style="color:#f92672">&amp;</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// alias declaration
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">using</span> FP <span style="color:#f92672">=</span> <span style="color:#66d9ef">void</span> (<span style="color:#f92672">*</span>)(<span style="color:#66d9ef">int</span>, <span style="color:#66d9ef">const</span> std<span style="color:#f92672">::</span>string<span style="color:#f92672">&amp;</span>);
</span></span></code></pre></div></li>
<li>
<p>Alias declarations can be templatized, but typedefs can not.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// MyAlloc is a custom allocator
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> T<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">using</span> MyAllocList <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>list<span style="color:#f92672">&lt;</span>T, MyAlloc<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;&gt;</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>MyAllocList<span style="color:#f92672">&lt;</span>Widget<span style="color:#f92672">&gt;</span> lw; <span style="color:#75715e">// will create std::list&lt;Widget, MyAlloc&lt;Widget&gt;&gt;
</span></span></span></code></pre></div><p>vs: typedef, a hack way:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// templatized struct here
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> T<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">MyAllocList</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">typedef</span> std<span style="color:#f92672">::</span>list<span style="color:#f92672">&lt;</span>T, MyAlloc<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;&gt;</span> type;
</span></span><span style="display:flex;"><span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>MyAllocList<span style="color:#f92672">&lt;</span>Widget<span style="color:#f92672">&gt;::</span>type lw;
</span></span></code></pre></div></li>
<li>
<p>In case you want to use a type specified by template parameter, with typedefs it gets complex:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// MyAllocList is defined as mentioned in 2nd point
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> T<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Widget</span> {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">private</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">typename</span> MyAllocList<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;::</span>type list;
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>};
</span></span></code></pre></div><ul>
<li>Here <code>MyAllocList&lt;T&gt;::type</code> is now a dependent type (dependent on type <code>T</code> from template paramater).</li>
<li>C++ Rule: need to use <code>typename</code> before name of a dependent type.</li>
</ul>
<p>With alias declaration of <code>MyAllocList</code>, no need to use <code>typename</code> and <code>::type</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> T<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Widget</span> {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">private</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// no typename and ::type
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    MyAllocList<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;</span> list;
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>}
</span></span></code></pre></div></li>
</ol>
<p>Explanation on the 3rd point:</p>
<ol>
<li>Compiler understands the alias declared <code>MyAllocList</code> when used inside a template class <code>Widget</code> as <code>MyAllocList&lt;T&gt;</code> is not a dependent type.</li>
<li>A user can have <code>type</code> as a data member, and thus it&rsquo;s important to mention <code>typename</code> when using <code>MyAllocList&lt;T&gt;::type</code> (as a type), so that compiler knows it&rsquo;s a type.</li>
</ol>
<p>Creating revised types from template type paramaeters is a common practice in Template Meta Programming (TMP). A few important points to note:</p>
<p>In C++11 (in header: <code>&lt;type_traits&gt;</code>):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>std<span style="color:#f92672">::</span>remove_const<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;::</span>type <span style="color:#75715e">// yields T from const T
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>std<span style="color:#f92672">::</span>remove_reference<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;::</span>type <span style="color:#75715e">// yields T from T&amp; and T&amp;&amp;
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>std<span style="color:#f92672">::</span>add_lvalue_reference<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;::</span>type <span style="color:#75715e">// yields T&amp; from T
</span></span></span></code></pre></div><p>In case you are applying the above transformations inside a template to a type parameter, you&rsquo;ll have to use <code>typename</code>. This is because they have been implemented as typedefs inside templatized structs.</p>
<p>In C++14, their alias equivalent were added which do not require you to prefix <code>typename</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// equivalents to the above 3 transformations 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>std<span style="color:#f92672">::</span>remove_const_t<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span>std<span style="color:#f92672">::</span>remove_reference_t<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span>std<span style="color:#f92672">::</span>add_lvalue_reference<span style="color:#f92672">&lt;</span>T<span style="color:#f92672">&gt;</span>
</span></span></code></pre></div><p><strong>Acknowledgement</strong></p>
<ul>
<li>Thanks to <a href="https://kshitij12345.github.io/">Kshitij Kalambarkar</a> for reviewing this blog.</li>
</ul>
<p>Thanks for reading!</p>
<p>{{ template &ldquo;_internal/disqus.html&rdquo; . }}</p>]]></content>
        </item>
        
        <item>
            <title>Function Pointers and Function Objects in C&#43;&#43;</title>
            <link>https://krshrimali.github.io/posts/2021/07/function-pointers-and-function-objects-in-c-/</link>
            <pubDate>Sun, 18 Jul 2021 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2021/07/function-pointers-and-function-objects-in-c-/</guid>
            <description>&lt;p&gt;In today&amp;rsquo;s blog, we&amp;rsquo;ll talk about two important concepts in C++: Function Pointers and Function Objects.&lt;/p&gt;
&lt;p&gt;Please note that, function objects are commonly referred as &lt;em&gt;functors&lt;/em&gt; but we have failed to notice any official alias to the name. Hence, we&amp;rsquo;ll restrict ourselves to using &lt;em&gt;Function Objects&lt;/em&gt; in this blog.&lt;/p&gt;</description>
            <content type="html"><![CDATA[<p>In today&rsquo;s blog, we&rsquo;ll talk about two important concepts in C++: Function Pointers and Function Objects.</p>
<p>Please note that, function objects are commonly referred as <em>functors</em> but we have failed to notice any official alias to the name. Hence, we&rsquo;ll restrict ourselves to using <em>Function Objects</em> in this blog.</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/fptr-fobj-cover.png" alt=""></p>
<h2 id="function-pointers">Function Pointers</h2>
<p>As the name sounds, a function pointer is simply a pointer to the memory address of a function. Consider a following function:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// A function which returns true if a &gt; b else false
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">bool</span> <span style="color:#a6e22e">isGreater</span>(<span style="color:#66d9ef">int</span> a, <span style="color:#66d9ef">int</span> b) {
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> a <span style="color:#f92672">&gt;</span> b;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>As we would expect, the function is stored in the memory starting with an address. You can print the memory address of a function by doing (we do this using <code>printf</code>, see: <a href="https://stackoverflow.com/a/2064722">https://stackoverflow.com/a/2064722</a>)</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> fn_addresss <span style="color:#f92672">=</span> isGreater; <span style="color:#75715e">// get the address of the function
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>printf(<span style="color:#e6db74">&#34;Function address: %p</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>, fn_address);
</span></span></code></pre></div><p>And you&rsquo;ll notice a hex value as the output: <code>0x5649d675c139</code> (in my case). The syntax for creating a function pointer looks like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>return_type (<span style="color:#f92672">*</span>ptr_name)(arg1_type, arg2_type, ...);
</span></span></code></pre></div><p>So in our case for <code>isGreater</code>, it will be:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">bool</span> (<span style="color:#f92672">*</span>justApointer)(<span style="color:#66d9ef">int</span>, <span style="color:#66d9ef">int</span>);
</span></span></code></pre></div><p>What this means is, the pointer <em>justApointer</em> will point to a function taking 2 integer arguments and returning a boolean value. But note that this doesn&rsquo;t point to any function yet. If you will do:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">bool</span> (<span style="color:#f92672">*</span>justApointer)(<span style="color:#66d9ef">int</span>, <span style="color:#66d9ef">int</span>);
</span></span><span style="display:flex;"><span><span style="color:#75715e">// De-reference the pointer and call 
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>(<span style="color:#f92672">*</span>justApointer)(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>);
</span></span></code></pre></div><p>This will cause a <code>segmentation fault (core dumped)</code> error because it points to no valid address of an executable code. So let&rsquo;s go ahead and point our pointer to the memory address of <code>isGreater</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>justApointer <span style="color:#f92672">=</span> <span style="color:#f92672">&amp;</span>isGreater;
</span></span></code></pre></div><p>Here we have given the address of the function to the pointer, you can also do:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Note: It&#39;s a good practice to avoid writing the type of function pointers again if it&#39;s too verbose
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">using</span> FnType <span style="color:#f92672">=</span> <span style="color:#66d9ef">bool</span> (<span style="color:#f92672">*</span>)(<span style="color:#66d9ef">int</span>, <span style="color:#66d9ef">int</span>);
</span></span><span style="display:flex;"><span>FnType justApointer{ <span style="color:#f92672">&amp;</span>isGreater }; <span style="color:#75715e">// OK
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>FnType yetAnotherPointer <span style="color:#f92672">=</span> <span style="color:#f92672">&amp;</span>isGreater; <span style="color:#75715e">// OK
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>FnType yetAnotherFnPointer <span style="color:#f92672">=</span> isGreater; <span style="color:#75715e">// OK, implicit conversion happens in C++ from function to function pointer, so you don&#39;t need to use &amp; operator
</span></span></span></code></pre></div><p>You could also have declared the pointer first, and then initialized:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Declararation
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">bool</span> (<span style="color:#f92672">*</span>justApointer)(<span style="color:#66d9ef">int</span>, <span style="color:#66d9ef">int</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Initialization
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>justApointer { <span style="color:#f92672">&amp;</span>isGreater };
</span></span><span style="display:flex;"><span>justApointer { isGreater };
</span></span><span style="display:flex;"><span>justApointer <span style="color:#f92672">=</span> <span style="color:#f92672">&amp;</span>isGreater;
</span></span><span style="display:flex;"><span>justApointer <span style="color:#f92672">=</span> isGreater;
</span></span></code></pre></div><p>All of this is valid and works in C++. If you&rsquo;re coming from Modern C++, you might have realized that it&rsquo;s OK to skip the syntax of a function pointer and use:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> justApointer <span style="color:#f92672">=</span> isGreater;
</span></span></code></pre></div><p>Calling a function pointer is fairly straight forward, you can just do:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Will return 0 since 3 is not greater than 4
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> (<span style="color:#f92672">*</span>justApointer)(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>);
</span></span></code></pre></div><p>Since it&rsquo;s a pointer, so you have to de-reference it to get to the function address (executable code in the memory) and then call it using the <code>()</code> call operator. C++ does the implicit conversion, and you can skip de-referencing:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Will also return 0 since 3 is not greater than 4
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> justApointer(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>);
</span></span></code></pre></div><p>If you are familiar with concepts of <code>const</code> pointers, you can also create a <em>const</em> function pointer, so that once initialized - it can not be pointed to a different function.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">bool</span> (<span style="color:#f92672">*</span><span style="color:#66d9ef">const</span> justApointer)(<span style="color:#66d9ef">int</span>, <span style="color:#66d9ef">int</span>) <span style="color:#f92672">=</span> <span style="color:#f92672">&amp;</span>isGreater;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// You can not re-initialize (aka assign) it to point to any other address
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>justApointer <span style="color:#f92672">=</span> <span style="color:#f92672">&amp;</span>isGreater; <span style="color:#75715e">// NOT OK, ERROR: assignment of read-only variable &#39;justApointer&#39;
</span></span></span></code></pre></div><p>If you have noticed, we used <code>*const justApointer</code> - since we wanted to indicate to the compiler - that the pointer is supposed to be <code>const</code>, not the output (<code>const bool (*justApointer)(int, int)</code>). You can play around with different specifiers and see how they work though.</p>
<p>One of the use-cases of function pointers is to be able to pass a function as an argument (often referred as <strong>Callback Functions</strong>). But well, you might have a question - you can use a global function in another function, right? Yes, that&rsquo;s possible, but consider a case where you want to pass different callback functions depending on your requirement to a more generic function (like sorting).</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">bool</span> <span style="color:#a6e22e">isGreater</span>(<span style="color:#66d9ef">int</span> a, <span style="color:#66d9ef">int</span> b) { <span style="color:#66d9ef">return</span> a <span style="color:#f92672">&gt;</span> b; }
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">bool</span> <span style="color:#a6e22e">isLesser</span>(<span style="color:#66d9ef">int</span> a, <span style="color:#66d9ef">int</span> b) { <span style="color:#66d9ef">return</span> a <span style="color:#f92672">&lt;</span> b; }
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">bool</span> <span style="color:#a6e22e">isEqual</span>(<span style="color:#66d9ef">int</span> a, <span style="color:#66d9ef">int</span> b) { <span style="color:#66d9ef">return</span> a <span style="color:#f92672">==</span> b; }
</span></span></code></pre></div><p>We have these 3 functions but we don&rsquo;t know yet which one we want to use to sort an array, let&rsquo;s say you want to sort an array in descending order, another array in ascending order.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> sample_vec <span style="color:#f92672">=</span> {<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">5</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">9</span>, <span style="color:#ae81ff">2</span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">a_generic_sorting_function</span>(std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> input_vec, <span style="color:#66d9ef">bool</span> (<span style="color:#f92672">*</span>comparisonFunction)(<span style="color:#66d9ef">int</span>, <span style="color:#66d9ef">int</span>)) {
</span></span><span style="display:flex;"><span>	<span style="color:#75715e">// ... sorting algorithm
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>	<span style="color:#75715e">// use comparisonFunction for comparisons
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>a_generic_sorting_function(sample_vec, isGreater); <span style="color:#75715e">// sorts in descending order
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>a_generic_sorting_function(sample_vec, isLesser); <span style="color:#75715e">// sorts in ascending order
</span></span></span></code></pre></div><p>Observe that even though we passed a function as an argument, but eventually - that&rsquo;s interpreted as a pointer (since that&rsquo;s what the 3rd argument type is, in <code>a_generic_sorting_function</code>).</p>
<h2 id="function-objects">Function Objects</h2>
<blockquote>
<p>Function Objects are types that implement call operator ().</p>
</blockquote>
<p>Function Objects provide us 2 advantages over function pointers, which are mainly:</p>
<ol>
<li>Can be optimized by the compiler, if possible.</li>
<li>Allows to store a state.</li>
</ol>
<h3 id="how-can-compiler-optimize-function-objects">How can compiler optimize function objects?</h3>
<p>You&rsquo;ll see this definition almost everywhere, and hence the quote. There is no better and simpler way to define a function object. But we&rsquo;ll also focus on how can they make things easier + faster. A <code>struct</code> or a <code>class</code> in C++ which defines/implements call operator <code>()</code> can be referred as function object. Interestingly, in C++:</p>
<ul>
<li><code>std::plus</code> is a <strong>function object</strong> implementing <code>x + y</code>.</li>
<li><code>std::minus</code> is a <strong>function object</strong> implementing <code>x - y</code>.</li>
</ul>
<p>and many more arithmetic operators like <code>/, *, %</code> and negation (<code>-x</code>). See <em>Operator Function Objects</em> section in <a href="https://en.cppreference.com/w/cpp/utility/functional">https://en.cppreference.com/w/cpp/utility/functional</a>.</p>
<p>There are other comparison, logical and bitwise operations as well which are provided as function objects in C++. Let&rsquo;s take a look at <code>std::greater</code> and <code>std::lesser</code> function objects to maintain the consistency b/w function pointers and objects sections. Going by the documentation (<a href="https://en.cppreference.com/w/cpp/utility/functional/greater)">https://en.cppreference.com/w/cpp/utility/functional/greater)</a>, the struct <code>std::greater</code> implements the call operator <code>()</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">bool</span> <span style="color:#a6e22e">operator</span>() (<span style="color:#66d9ef">const</span> T<span style="color:#f92672">&amp;</span> lhs, <span style="color:#66d9ef">const</span> T<span style="color:#f92672">&amp;</span> rhs) <span style="color:#66d9ef">const</span>; <span style="color:#75715e">// (until C++14)
</span></span></span></code></pre></div><p>(source: <a href="https://en.cppreference.com/w/cpp/utility/functional/greater">https://en.cppreference.com/w/cpp/utility/functional/greater</a>)</p>
<p>If we had to define our own function object, something similar to <code>std::greater</code> but only for integer inputs. As mentioned earlier, it&rsquo;s a type with the call operator defined, so let&rsquo;s go ahead and define our own <code>struct</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">greater</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">bool</span> <span style="color:#a6e22e">operator</span>()(<span style="color:#66d9ef">int</span> a, <span style="color:#66d9ef">int</span> b) {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> a <span style="color:#f92672">&gt;</span> b;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>greater comparison;
</span></span><span style="display:flex;"><span>std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> comparison(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>);  <span style="color:#75715e">// Returns 0
</span></span></span></code></pre></div><p>Now you can ask: this could have been accomplished with a function pointer as well, so why a function object? Well, so the answer boils down to optimization (in this case). A compiler can inline the function if it&rsquo;s possible to optimize the execution - and that&rsquo;s only possible with function objects, while for function pointers - you need to de-reference it to know the address which happens during the runtime (unless there is some real complex optimization - which I&rsquo;m not aware of right now).</p>
<p>A real example can be to see the compiled code on <a href="https://godbolt.org/">https://godbolt.org/</a> (an amazing compiler explorer). If I compile the following code (on x86-64, gcc 11.1 with no optimization flags):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;iostream&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">greater</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">bool</span> <span style="color:#a6e22e">operator</span>()(<span style="color:#66d9ef">int</span> a, <span style="color:#66d9ef">int</span> b) {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> a <span style="color:#f92672">&gt;</span> b;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>() {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">greater</span> obj;
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> obj(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">4</span>);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The relevant assembly code of the <code>main</code> function looks like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>main:
</span></span><span style="display:flex;"><span>        push    rbp
</span></span><span style="display:flex;"><span>        mov     rbp, rsp
</span></span><span style="display:flex;"><span>        sub     rsp, <span style="color:#ae81ff">16</span>
</span></span><span style="display:flex;"><span>        lea     rax, [rbp<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>]
</span></span><span style="display:flex;"><span>        mov     edx, <span style="color:#ae81ff">4</span>
</span></span><span style="display:flex;"><span>        mov     esi, <span style="color:#ae81ff">3</span>
</span></span><span style="display:flex;"><span>        mov     rdi, rax
</span></span><span style="display:flex;"><span>        call    greater<span style="color:#f92672">::</span><span style="color:#66d9ef">operator</span>()(<span style="color:#66d9ef">int</span>, <span style="color:#66d9ef">int</span>)
</span></span><span style="display:flex;"><span>        movzx   eax, al
</span></span><span style="display:flex;"><span>        mov     esi, eax
</span></span><span style="display:flex;"><span>        mov     edi, OFFSET FLAT:_ZSt4cout
</span></span><span style="display:flex;"><span>        call    std<span style="color:#f92672">::</span>basic_ostream<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">char</span>, std<span style="color:#f92672">::</span>char_traits<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">char</span><span style="color:#f92672">&gt;</span> <span style="color:#f92672">&gt;::</span><span style="color:#66d9ef">operator</span><span style="color:#f92672">&lt;&lt;</span>(<span style="color:#66d9ef">bool</span>)
</span></span><span style="display:flex;"><span>        mov     eax, <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        leave
</span></span><span style="display:flex;"><span>        ret
</span></span></code></pre></div><p>The above assembly code may look overwhelming to some, but the most relevant instruction is: (link to the code: <a href="https://godbolt.org/z/WqYozn7qv">https://godbolt.org/z/WqYozn7qv</a>)</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>call    greater<span style="color:#f92672">::</span><span style="color:#66d9ef">operator</span>(<span style="color:#66d9ef">int</span>, <span style="color:#66d9ef">int</span>)
</span></span></code></pre></div><p>Now if I add the optimization flag, you&rsquo;ll see the operator being inlined:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>main:
</span></span><span style="display:flex;"><span>        sub     rsp, <span style="color:#ae81ff">8</span>
</span></span><span style="display:flex;"><span>        xor     esi, esi
</span></span><span style="display:flex;"><span>        mov     edi, OFFSET FLAT:_ZSt4cout
</span></span><span style="display:flex;"><span>        call    std<span style="color:#f92672">::</span>basic_ostream<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">char</span>, std<span style="color:#f92672">::</span>char_traits<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">char</span><span style="color:#f92672">&gt;</span> <span style="color:#f92672">&gt;&amp;</span> std<span style="color:#f92672">::</span>basic_ostream<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">char</span>, std<span style="color:#f92672">::</span>char_traits<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">char</span><span style="color:#f92672">&gt;</span> <span style="color:#f92672">&gt;::</span>_M_insert<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">bool</span><span style="color:#f92672">&gt;</span>(<span style="color:#66d9ef">bool</span>)
</span></span><span style="display:flex;"><span>        xor     eax, eax
</span></span><span style="display:flex;"><span>        add     rsp, <span style="color:#ae81ff">8</span>
</span></span><span style="display:flex;"><span>        ret
</span></span><span style="display:flex;"><span>_GLOBAL__sub_I_main:
</span></span><span style="display:flex;"><span>        sub     rsp, <span style="color:#ae81ff">8</span>
</span></span><span style="display:flex;"><span>        mov     edi, OFFSET FLAT:_ZStL8__ioinit
</span></span><span style="display:flex;"><span>        call    std<span style="color:#f92672">::</span>ios_base<span style="color:#f92672">::</span>Init<span style="color:#f92672">::</span>Init() [complete object constructor]
</span></span><span style="display:flex;"><span>        mov     edx, OFFSET FLAT:__dso_handle
</span></span><span style="display:flex;"><span>        mov     esi, OFFSET FLAT:_ZStL8__ioinit
</span></span><span style="display:flex;"><span>        mov     edi, OFFSET FLAT:_ZNSt8ios_base4InitD1Ev
</span></span><span style="display:flex;"><span>        add     rsp, <span style="color:#ae81ff">8</span>
</span></span><span style="display:flex;"><span>        jmp     __cxa_atexit
</span></span></code></pre></div><p>Though, it may not be visible on the first look, but a closer look to the following instruction:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>call    std<span style="color:#f92672">::</span>basic_ostream<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">char</span>, std<span style="color:#f92672">::</span>char_traits<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">char</span><span style="color:#f92672">&gt;</span> <span style="color:#f92672">&gt;&amp;</span> std<span style="color:#f92672">::</span>basic_ostream<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">char</span>, std<span style="color:#f92672">::</span>char_traits<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">char</span><span style="color:#f92672">&gt;</span> <span style="color:#f92672">&gt;::</span>_M_insert<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">bool</span><span style="color:#f92672">&gt;</span>(<span style="color:#66d9ef">bool</span>)
</span></span></code></pre></div><p>tells us that it doesn&rsquo;t call the operator of the object of type <code>greater</code> anymore! Instead, the compiler knows that the value is <code>false</code> and hence it inlines the value to the <code>std::cout</code> call. While this is possible for function objects, it&rsquo;s not possible for function pointers (with the <code>-O3</code> flag at least).</p>
<h3 id="storing-a-state">Storing a state</h3>
<p>It&rsquo;s more like a property of a class/struct in C++ that you can take arguments in the constructor and have different objects with different values for a member variable. Take an example:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Usage:
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// GreaterThan obj(10);
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// obj(11); // is 11 &gt; 10?
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">//
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// GreaterThan obj_(-10);
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// obj_(-9); // is -9 &gt; -10?
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">GreaterThan</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> compare_with;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">void</span> greaterThan(<span style="color:#66d9ef">int</span> inp) <span style="color:#f92672">:</span> compare_with(inp) { }
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">bool</span> <span style="color:#a6e22e">operator</span>()(<span style="color:#66d9ef">int</span> another_number) { <span style="color:#66d9ef">return</span> another_number <span style="color:#f92672">&gt;</span> compare_with; }
</span></span><span style="display:flex;"><span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>() {
</span></span><span style="display:flex;"><span>    GreaterThan obj(<span style="color:#ae81ff">10</span>);
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> obj(<span style="color:#ae81ff">11</span>) <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#39;\n&#39;</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    GreaterThan obj_(<span style="color:#f92672">-</span><span style="color:#ae81ff">10</span>);
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> obj_(<span style="color:#f92672">-</span><span style="color:#ae81ff">9</span>) <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#39;\n&#39;</span>;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Here you have a member variable <code>compare_with</code> and you can have different values for each object instantiated. While it&rsquo;s also possible for a function by using a <code>static</code> variable but you can&rsquo;t have multiple values for it on a single run.</p>
<h2 id="function-objects-and-function-pointers-in-the-standard-library">Function Objects and Function Pointers in the Standard Library</h2>
<p>Function Objects and Function Pointers, just like any other type/value can be passed as a type to a template:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> T, <span style="color:#66d9ef">typename</span> ComparatorFunc<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">void</span> sort(T vector_input, ComparatorFunc func) {
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// ... sorting logic using given comparator function: func
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>}
</span></span></code></pre></div><p>This allows you to use <code>sort</code> as a generic function with different types of comparators. Let&rsquo;s take a look here, you have 2 function object types: <code>isGreater</code> and <code>isLesser</code>: (the same can be done for function pointers as well)</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">isGreater</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">bool</span> <span style="color:#a6e22e">operator</span>()(<span style="color:#66d9ef">int</span> a, <span style="color:#66d9ef">int</span> b) { <span style="color:#66d9ef">return</span> a <span style="color:#f92672">&gt;</span> b; }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">isLesser</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">bool</span> <span style="color:#a6e22e">operator</span>()(<span style="color:#66d9ef">int</span> a, <span style="color:#66d9ef">int</span> b) { <span style="color:#66d9ef">return</span> a <span style="color:#f92672">&lt;</span> b; }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> T, <span style="color:#66d9ef">typename</span> ComparatorFunc<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span>T sort(T input, ComparatorFunc func) {
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// use func to decide sorting strategy (descending/ascending)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>}
</span></span></code></pre></div><p>This is valid in C++, though I&rsquo;ll like to add a disclaimer here, you could have just used <code>std::sort</code> instead of implementing your own sorting strategy (unless you know what you are doing ;)):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>std<span style="color:#f92672">::</span>sort(input.begin(), input.end(), isGreater);
</span></span><span style="display:flex;"><span>std<span style="color:#f92672">::</span>sort(input.begin(), input.end(), isLesser);
</span></span></code></pre></div><p>This is mostly it for this blog, there is a lot to discuss about function pointers and objects, but I guess this should be enough for you to get started and follow us along in future blogs.</p>
<h2 id="references-and-good-reads">References and Good Reads</h2>
<ol>
<li><!-- raw HTML omitted -->Learn CPP&rsquo;s Blog on Function Pointer<!-- raw HTML omitted -->.</li>
<li><!-- raw HTML omitted -->Function Objects in the STL (Microsoft Docs)<!-- raw HTML omitted --></li>
<li><!-- raw HTML omitted -->CppReference: Function Objects<!-- raw HTML omitted -->.</li>
</ol>]]></content>
        </item>
        
        <item>
            <title>How to crop a circle in OpenCV? Implementing Portrait Bokeh - Part 2</title>
            <link>https://krshrimali.github.io/posts/2020/12/how-to-crop-a-circle-in-opencv-implementing-portrait-bokeh-part-2/</link>
            <pubDate>Thu, 10 Dec 2020 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2020/12/how-to-crop-a-circle-in-opencv-implementing-portrait-bokeh-part-2/</guid>
            <description>Hi everyone! In the previous blog we implemented Portrait Bokeh using Face Detection in OpenCV. While the results were good for a start, we definitely want to be closer to the output we expect. The end goal is to blur everything except the face. The main problem we noticed was:
The face cropped was a rectangle, and it was clearly visible in the output result. To overcome this, we will be talking about cropping a circle in OpenCV today.</description>
            <content type="html"><![CDATA[<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Dec_10_2020.jpg" alt=""></p>
<p>Hi everyone! In the previous blog we implemented Portrait Bokeh using Face Detection in OpenCV. While the results were good for a start, we definitely want to be closer to the output we expect. The end goal is to blur everything except the face. The main problem we noticed was:</p>
<ul>
<li>The face cropped was a rectangle, and it was clearly visible in the output result.</li>
</ul>
<p>To overcome this, we will be talking about cropping a circle in OpenCV today. This will enable us to get rid of &ldquo;some&rdquo; of the background noise we got earlier, for Portrait Bokeh. Let&rsquo;s take this step by step, and first talk about the intuition.</p>
<h2 id="intuition-behind-cropping-a-circle">Intuition behind cropping a circle</h2>
<p>while pixels are just the brightness values for each channel at a particular coordinate, so you can&rsquo;t really get half of the pixel and crop an exact circle. But the closest we can get to cropping a circle, is to imagine a circle circumscribed in a rectangle (face detection algorithm in OpenCV - CascadeClassifier returns a rectangle - can be a square as well). So if we are able to get a circle from our output of face detection (a rectangle), we will be closer to what we want.</p>
<p>But how do we get started? Clearly, since the circle is circumscribing the rectangle, the closest we can get to finding radius is: <code>max(width, height)/2</code>. While center will be: <code>(top_left_x + width/2, top_left_y + height/2)</code>. Once we know these two properties of the circle, we will now have the circle equation.</p>
<h2 id="methodology">Methodology</h2>
<p>Let&rsquo;s divide this problem statement into steps:</p>
<ol>
<li>Get face from Face Detection.</li>
<li>Get circle circumscribing the face (rectangle).</li>
<li>Crop the circle and store it in different array.</li>
<li>Blur the whole image except the face.</li>
</ol>
<p>Essentially, the main goal is to get the face cropped as a circle. Once we have that, we can simply overlay this on the blurred image. The trick is to figure out on how we can crop the circle once we know it&rsquo;s coordinates. Let&rsquo;s talk about it&rsquo;s solution in the next section.</p>
<h2 id="cropping-a-circle">Cropping a circle</h2>
<p>Usually, our images will have 3 channels (colored image): Blue, Green, Red (BGR). How about we add a transparency channel to our image? The idea behind this is to make all pixels transparent which are NOT in the face, and all the pixels opaque which are within/on the face (circle) boundary. The pseudo code for this should look something like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Assuming you got a circle equation representing the face</span>
</span></span><span style="display:flex;"><span>face <span style="color:#f92672">=</span> circle_equation
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Now iterate through all the pixel values in the imagge</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Check if the pixel is outside the face, if yes - then make it transparent</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Else - opaque</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> pixel_value <span style="color:#f92672">in</span> image:
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> pixel_value <span style="color:#f92672">is</span> outside the face:
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Make this pixel transparent</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Make this pixel opaque</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># This will be visible</span>
</span></span></code></pre></div><p>To have an option to add transparency, you need to convert the BGR input image to BGRA (4 channel image: Blue, Green, Red, Alpha) - here Alpha channel denotes transparency channel. When the transparency is set to 0, that represents opaque and when it&rsquo;s set to 255, it represents transparent value. Let&rsquo;s go ahead and use this for our application.</p>
<h2 id="video-tutorial">Video Tutorial</h2>
<p>I started a YouTube channel where I go live on the weekends, and upload videos on the week days (not so regularly) about Computer Vision, deploying models into production and more. If you haven&rsquo;t seen it before, please check it out <a href="https://youtube.com/c/kushashwaraviShrimali">here</a>. For this blog, I have already uploaded a detailed tutorial. Check it out <a href="https://www.youtube.com/watch?v=7seEhDVGvn4">here</a>.</p>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/7seEhDVGvn4" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<h2 id="step-1-get-face-from-face-detection">Step 1: Get face from face detection</h2>
<p>We have discussed this <a href="https://krshrimali.github.io/posts/2020/12/implementing-portrait-bokeh-in-opencv-using-face-detection-part-1/">before</a>, so we won&rsquo;t go in details but for the sake of continuity, I&rsquo;ll add the code for Face Detection.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> cv2<span style="color:#f92672">,</span> sys
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Get image path and read image</span>
</span></span><span style="display:flex;"><span>img_path <span style="color:#f92672">=</span> sys<span style="color:#f92672">.</span>argv[<span style="color:#ae81ff">1</span>] <span style="color:#66d9ef">if</span> len(sys<span style="color:#f92672">.</span>argv) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">1</span> <span style="color:#66d9ef">else</span> <span style="color:#e6db74">&#34;sample.png&#34;</span>
</span></span><span style="display:flex;"><span>img <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>imread(img_path, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Convert to grayscale, since Face Detection takes gray scale image as input</span>
</span></span><span style="display:flex;"><span>gray <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>cvtColor(img, cv2<span style="color:#f92672">.</span>COLOR_BGR2GRAY)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Initialize face detector from the model file</span>
</span></span><span style="display:flex;"><span>face_detector <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>CascadeClassifier(<span style="color:#e6db74">&#34;haarcascade_frontalface_default.xml&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Detect faces from gray-scaled image, using default parameters (scaleFactor)</span>
</span></span><span style="display:flex;"><span>faces <span style="color:#f92672">=</span> face_detector<span style="color:#f92672">.</span>detectMultiScale(gray, scaleFactor <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.1</span>, minNeighbors <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Note: Format of faces will be: [ [top_left_x, top_left_y, w, h (for face 1)], [... (for face 2)], ... ]</span>
</span></span></code></pre></div><p>Once you have ROI (Region Of Interest) of the faces in the image, we can go ahead and start cropping a circle (yay!).</p>
<h2 id="step-2-get-circle-circumscribing-the-face">Step 2: Get circle circumscribing the face</h2>
<p>From Step-1, we got the faces. Let&rsquo;s iterate through each face, and get the equation of the circle circumscribing that face. As we discussed before in the <strong>Intuition</strong> section, we&rsquo;ll have to calculate the radius and center of the face.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Make sure to convert BGR to BGRA image first</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># To be used later</span>
</span></span><span style="display:flex;"><span>imgTransp <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>cvtColor(img, cv2<span style="color:#f92672">.</span>COLOR_BGR2BGRA)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Iterate through each face one by one</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> face <span style="color:#f92672">in</span> faces:
</span></span><span style="display:flex;"><span>    top_left_x, top_left_y, width, height <span style="color:#f92672">=</span> face[<span style="color:#ae81ff">0</span>], face[<span style="color:#ae81ff">1</span>], face[<span style="color:#ae81ff">2</span>], face[<span style="color:#ae81ff">3</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    radius <span style="color:#f92672">=</span> max(width, height)<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>    center <span style="color:#f92672">=</span> (top_left_x <span style="color:#f92672">+</span> width<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>, top_left_y <span style="color:#f92672">+</span> height<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Cropping circle code will come here</span>
</span></span></code></pre></div><p>Here, we find the circle contained in the rectangle (closest) for each face. Let&rsquo;s go ahead and crop this circle one by one, and see how we can use this for Portrait Bokeh!</p>
<h2 id="step-3-crop-the-circle-and-store-it-in-different-array">Step 3: Crop the circle and store it in different array</h2>
<p>We discussed the pseudo code of this in <strong>Cropping a Circle</strong> section of this blog. But before this, we have to figure out: How to find a point is within that circle? Think of this as a simple maths problem where you have to find a given coordinate is inside a circle or not. What would you do?</p>
<ul>
<li>Find distance between point and center of the circle.</li>
<li>If distance is greater than radius, it&rsquo;s outside.</li>
<li>If distance is equal to radius, it&rsquo;s on the boundary.</li>
<li>If distance is less than radius, it&rsquo;s inside.</li>
</ul>
<p>We can simplify this for circle as we know it&rsquo;s equation: <code>(point_x - center_x)^2 + (point_y - center_y)^2 - radius^2</code>, which will be:</p>
<ul>
<li>0 if the point is on the boundary.</li>
<li>greater than 0 if the point is outside the circle.</li>
<li>less than 0 if the point is inside the circle.</li>
</ul>
<p>Let&rsquo;s use this concept here:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">is_inside</span>(point, center, radius):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34; This function returns True if point is inside/on the boundary, False otherwise &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    eqn <span style="color:#f92672">=</span> (point[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">-</span> center[<span style="color:#ae81ff">0</span>]) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">+</span> (point[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">-</span> center[<span style="color:#ae81ff">1</span>])<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">-</span> radius<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> eqn <span style="color:#f92672">&lt;=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Iterate through all the pixels in the image</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> row <span style="color:#f92672">in</span> range(img<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> col <span style="color:#f92672">in</span> range(img<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>]):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> is_inside(img[row][col], center, radius):
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Means the point is inside/on the face</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Make it opaque</span>
</span></span><span style="display:flex;"><span>            img[row][col][<span style="color:#ae81ff">3</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Means the point is outside the face</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Make it transparent</span>
</span></span><span style="display:flex;"><span>            img[row][col][<span style="color:#ae81ff">3</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">255</span>
</span></span></code></pre></div><p>We will have to execute the for loop once for each face, which means the code becomes:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Make sure to convert BGR to BGRA image first</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># To be used later</span>
</span></span><span style="display:flex;"><span>imgTransp <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>cvtColor(img, cv2<span style="color:#f92672">.</span>COLOR_BGR2BGRA)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Make the whole image transparent, by default</span>
</span></span><span style="display:flex;"><span>imgTransp[<span style="color:#f92672">...</span>, <span style="color:#ae81ff">3</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">255</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">is_inside</span>(point, center, radius):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34; This function returns True if point is inside/on the boundary, False otherwise &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    eqn <span style="color:#f92672">=</span> (point[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">-</span> center[<span style="color:#ae81ff">0</span>]) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">+</span> (point[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">-</span> center[<span style="color:#ae81ff">1</span>])<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">-</span> radius<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> eqn <span style="color:#f92672">&lt;=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Iterate through each face one by one</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> face <span style="color:#f92672">in</span> faces:
</span></span><span style="display:flex;"><span>    top_left_x, top_left_y, width, height <span style="color:#f92672">=</span> face[<span style="color:#ae81ff">0</span>], face[<span style="color:#ae81ff">1</span>], face[<span style="color:#ae81ff">2</span>], face[<span style="color:#ae81ff">3</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    radius <span style="color:#f92672">=</span> max(width, height)<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>    center <span style="color:#f92672">=</span> (top_left_x <span style="color:#f92672">+</span> width<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>, top_left_y <span style="color:#f92672">+</span> height<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Cropping circle code will come here</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Iterate through all the pixels in the image</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> row <span style="color:#f92672">in</span> range(img<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">0</span>]):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> col <span style="color:#f92672">in</span> range(img<span style="color:#f92672">.</span>shape[<span style="color:#ae81ff">1</span>]):
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> is_inside(img[row][col], center, radius):
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># Means the point is inside/on the face</span>
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># Make it opaque</span>
</span></span><span style="display:flex;"><span>                imgTransp[row][col][<span style="color:#ae81ff">3</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">255</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># Means the point is outside the face</span>
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># Make it transparent</span>
</span></span><span style="display:flex;"><span>                imgTransp[row][col][<span style="color:#ae81ff">3</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span></code></pre></div><p>If you notice, we have 3 nested for loops, which will result into really non-efficient code for HD Images (1920x1080 images? Think of the number of computations happening in this case). Suppose we have 3 faces detected and our input image is 1920 x 1080 (width x height). Total number of times the function <code>is_inside</code> called will be: 3 x 1920 x 1080, which is 6220800 (approx. 6.2 Million or 62 Lacs). It&rsquo;s a lot!</p>
<p>We can not avoid these loops though, but why iterate through the whole image when you know the circle is anyways gonna be within that rectangle (face)! Imagine the face is 200 x 200 now, and everything remains same (3 faces, HD input Image: 1920 x 1080). If we only iterate through the face everytime, the computations will be: 3 * 200 * 200, which is 120000 (120 thousand or 1.2 lacs). Much better. All we have to do is, pick the face ROI, and iterate through that region. Everything else remains same:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> row <span style="color:#f92672">in</span> range(tly, tly <span style="color:#f92672">+</span> height):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> col <span style="color:#f92672">in</span> range(tlx, tlx <span style="color:#f92672">+</span> width):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> is_inside(img[row][col], center, radius):
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Means the point is inside/on the face</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Make it opaque</span>
</span></span><span style="display:flex;"><span>            imgTransp[row][col][<span style="color:#ae81ff">3</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">255</span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Means the point is outside the face</span>
</span></span><span style="display:flex;"><span>            <span style="color:#75715e"># Make it transparent</span>
</span></span><span style="display:flex;"><span>            imgTransp[row][col][<span style="color:#ae81ff">3</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span></code></pre></div><p>So, the code should look like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Make sure to convert BGR to BGRA image first</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># To be used later</span>
</span></span><span style="display:flex;"><span>imgTransp <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>cvtColor(img, cv2<span style="color:#f92672">.</span>COLOR_BGR2BGRA)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Make the whole image transparent by default</span>
</span></span><span style="display:flex;"><span>imgTransp[<span style="color:#f92672">...</span>, <span style="color:#ae81ff">3</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">255</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">is_inside</span>(point, center, radius):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34; This function returns True if point is inside/on the boundary, False otherwise &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    eqn <span style="color:#f92672">=</span> (point[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">-</span> center[<span style="color:#ae81ff">0</span>]) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">+</span> (point[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">-</span> center[<span style="color:#ae81ff">1</span>])<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">-</span> radius<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> eqn <span style="color:#f92672">&lt;=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Iterate through each face one by one</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> face <span style="color:#f92672">in</span> faces:
</span></span><span style="display:flex;"><span>    top_left_x, top_left_y, width, height <span style="color:#f92672">=</span> face[<span style="color:#ae81ff">0</span>], face[<span style="color:#ae81ff">1</span>], face[<span style="color:#ae81ff">2</span>], face[<span style="color:#ae81ff">3</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    radius <span style="color:#f92672">=</span> max(width, height)<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>    center <span style="color:#f92672">=</span> (top_left_x <span style="color:#f92672">+</span> width<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>, top_left_y <span style="color:#f92672">+</span> height<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Cropping circle code will come here</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Iterate through all the pixels in the image</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> row <span style="color:#f92672">in</span> range(tly, tly <span style="color:#f92672">+</span> height):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> col <span style="color:#f92672">in</span> range(tlx, tlx <span style="color:#f92672">+</span> width):
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> is_inside((col, row), center, radius):
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># Means the point is inside/on the face</span>
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># Make it opaque</span>
</span></span><span style="display:flex;"><span>                imgTransp[row][col][<span style="color:#ae81ff">3</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">255</span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># Means the point is outside the face</span>
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># Make it transparent</span>
</span></span><span style="display:flex;"><span>                imgTransp[row][col][<span style="color:#ae81ff">3</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span></code></pre></div><p>Let&rsquo;s try to visualize <code>imgTransp</code> here and see how this looks like:</p>
<!-- raw HTML omitted -->
<p>This looks good so far! We have cropped the circle (face), and all we need to do now is - overlay this image on a blurred image. Let&rsquo;s head straight to Step 4.</p>
<h2 id="step-4-blurring-and-overlaying">Step 4: Blurring and overlaying</h2>
<p>In Step 3, we were able to crop the circle. But think about this, whenever we know the pixel is inside the face, let&rsquo;s just replace the blurred pixel with original image.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Blur the whole image first</span>
</span></span><span style="display:flex;"><span>img_blurred <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>GaussianBlur(img, (<span style="color:#ae81ff">11</span>, <span style="color:#ae81ff">11</span>), <span style="color:#ae81ff">0</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Iterate through the faces we were doing before</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Whenever the pixel is inside, replace the point at img_blurred with original img</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Make sure to convert BGR to BGRA image first</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># To be used later</span>
</span></span><span style="display:flex;"><span>imgTransp <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>cvtColor(img, cv2<span style="color:#f92672">.</span>COLOR_BGR2BGRA)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Make the whole image transparent by default</span>
</span></span><span style="display:flex;"><span>imgTransp[<span style="color:#f92672">...</span>, <span style="color:#ae81ff">3</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">255</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">is_inside</span>(point, center, radius):
</span></span><span style="display:flex;"><span>    <span style="color:#e6db74">&#34;&#34;&#34; This function returns True if point is inside/on the boundary, False otherwise &#34;&#34;&#34;</span>
</span></span><span style="display:flex;"><span>    eqn <span style="color:#f92672">=</span> (point[<span style="color:#ae81ff">0</span>] <span style="color:#f92672">-</span> center[<span style="color:#ae81ff">0</span>]) <span style="color:#f92672">**</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">+</span> (point[<span style="color:#ae81ff">1</span>] <span style="color:#f92672">-</span> center[<span style="color:#ae81ff">1</span>])<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">-</span> radius<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> eqn <span style="color:#f92672">&lt;=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Iterate through each face one by one</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> face <span style="color:#f92672">in</span> faces:
</span></span><span style="display:flex;"><span>    top_left_x, top_left_y, width, height <span style="color:#f92672">=</span> face[<span style="color:#ae81ff">0</span>], face[<span style="color:#ae81ff">1</span>], face[<span style="color:#ae81ff">2</span>], face[<span style="color:#ae81ff">3</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    radius <span style="color:#f92672">=</span> max(width, height)<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>    center <span style="color:#f92672">=</span> (top_left_x <span style="color:#f92672">+</span> width<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>, top_left_y <span style="color:#f92672">+</span> height<span style="color:#f92672">/</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Cropping circle code will come here</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Iterate through all the pixels in the image</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> row <span style="color:#f92672">in</span> range(tly, tly <span style="color:#f92672">+</span> height):
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span> col <span style="color:#f92672">in</span> range(tlx, tlx <span style="color:#f92672">+</span> width):
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">if</span> is_inside((col, row), center, radius):
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># Means the point is inside/on the face</span>
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># Make it opaque</span>
</span></span><span style="display:flex;"><span>                imgTransp[row][col][<span style="color:#ae81ff">3</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">255</span>
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># Replace pixel of blurred image with original image</span>
</span></span><span style="display:flex;"><span>                imgBlurred[row][col] <span style="color:#f92672">=</span> img[row][col]
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">else</span>:
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># Means the point is outside the face</span>
</span></span><span style="display:flex;"><span>                <span style="color:#75715e"># Make it transparent</span>
</span></span><span style="display:flex;"><span>                imgTransp[row][col][<span style="color:#ae81ff">3</span>] <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span></code></pre></div><p><strong>Note:</strong> The only reason we used <code>imgTransp</code> here, is to show how to crop a circle. For portrait bokeh, you don&rsquo;t need to have <code>imgTransp</code> and transparency channels.</p>
<p>Here is how the output looks like. While I understand that there is still some background, but we can definitely be better than this - and this will be our topic for the next blog!</p>
<!-- raw HTML omitted -->
<p>This should be it for this blog, and I hope you learnt something new today. If you liked the content, please leave a comment below. I would love to read your feedbacks, suggestions and if this helped you out in any way. I also go live on weekends, and upload videos on weekdays on my <a href="https://youtube.com/c/kushashwaraviShrimali">YouTube Channel</a>, so make sure to subscribe there and join me in if you find it interesting! Thank you for reading this blog.</p>
]]></content>
        </item>
        
        <item>
            <title>Implementing Portrait Bokeh in OpenCV using Face Detection (Part-1)</title>
            <link>https://krshrimali.github.io/posts/2020/12/implementing-portrait-bokeh-in-opencv-using-face-detection-part-1/</link>
            <pubDate>Mon, 07 Dec 2020 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2020/12/implementing-portrait-bokeh-in-opencv-using-face-detection-part-1/</guid>
            <description>OpenCV: Using face detection for Portrait Bokeh (Background Blur) (Part - 1) This blog discusses using Face Detection in OpenCV for Portrait Bokeh. We&amp;rsquo;ll be implementing Portrait Bokeh (blurring everything but faces) using 3 different methods in this series:
Using Face Detection (cropping a rectangle) Using Face Detection (cropping a circle) Using Facial Landmark Detection and Convex Hull Don&amp;rsquo;t lose hopes if you are confused. We will be going through each method one by one, and hopefully the road will be crearer from here.</description>
            <content type="html"><![CDATA[<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Dec_7_2020.jpg" alt=""></p>
<h1 id="opencv-using-face-detection-for-portrait-bokeh-background-blur-part---1">OpenCV: Using face detection for Portrait Bokeh (Background Blur) (Part - 1)</h1>
<p>This blog discusses using Face Detection in OpenCV for Portrait Bokeh. We&rsquo;ll be implementing Portrait Bokeh (blurring everything but faces) using 3 different methods in this series:</p>
<ol>
<li>Using Face Detection (cropping a rectangle)</li>
<li>Using Face Detection (cropping a circle)</li>
<li>Using Facial Landmark Detection and Convex Hull</li>
</ol>
<p>Don&rsquo;t lose hopes if you are confused. We will be going through each method one by one, and hopefully the road will be crearer from here.</p>
<h2 id="portrait-bokeh-discussing-problem-statement">Portrait Bokeh: Discussing Problem Statement</h2>
<p>Before moving ahead, let&rsquo;s talk about &ldquo;What is Portrait Bokeh?&rdquo;. It&rsquo;s important to talk about the problem before discussing solutions. Take a quick look at the two images below:</p>
<p><!-- raw HTML omitted --> <!-- raw HTML omitted --></p>
<p>As you might have spotted the difference already, the image on the left is our input (/original) image while the image on the right is our output image. If you haven&rsquo;t spotted the difference, everything except the face in the image on the right is blurred! This feature now comes in almost all smart phones, and is also termed as just Portrait mode. Whenever you want to highlight the people near to the camera (mostly you, your friends or anyone) and blur the background, this is the mode you will usually choose. While some blur everything except faces, others might choose to keep the body instead of just faces. Our problem statement will be limited to faces here.</p>
<h2 id="methodology-opted">Methodology opted</h2>
<p>Let&rsquo;s discuss on how we can go ahead to solve this problem. We surely need to know where the face is to avoid blurring it, so the first step has to be of face detection. And since we need to blur the background, so at some stage, we need to do blurring as well. Since this part is about the simplest step, we can just combine them and say:</p>
<ol>
<li>Detect face(s) from the given input image.</li>
<li>Crop the faces and store them as separate objects.</li>
<li>Blur the whole image.</li>
<li>Overlay the cropped faces from step-2 on the output from step-3.</li>
</ol>
<h2 id="video-tutorial">Video Tutorial</h2>
<p>I started a YouTube channel where I go live on the weekends, and upload videos on the week days (not so regularly) about Computer Vision, deploying models into production and more. If you haven&rsquo;t seen it before, please check it out <a href="https://youtube.com/c/kushashwaraviShrimali">here</a>. For this blog, I have already uploaded a detailed tutorial. Check it out <a href="https://www.youtube.com/watch?v=Nd3wFiSH-gw">here</a>.</p>

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden;">
  <iframe src="https://www.youtube.com/embed/Nd3wFiSH-gw" style="position: absolute; top: 0; left: 0; width: 100%; height: 100%; border:0;" allowfullscreen title="YouTube Video"></iframe>
</div>

<h2 id="step-1-detecting-faces-using-haarcascade">Step 1: Detecting Faces using Haarcascade</h2>
<p>We&rsquo;ll be using haarcascade model files to detect face in the image. To ease the computation and satisfy the input to the model, we need to first convert the image to GrayScale (if it&rsquo;s not already) - that is the image will now have only one channel instead of 3 (Blue, Green, Red). Download the model file to your directory from <a href="https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml">here</a>. Let&rsquo;s go ahead and initialize our Face Detector.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>model_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;haarcascade_frontalface_default.xml&#34;</span> <span style="color:#75715e"># Assuming this is in our current directory</span>
</span></span><span style="display:flex;"><span>face_detector <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>CascadeClassifier(model_path)
</span></span></code></pre></div><p>Once we have the model loaded, let&rsquo;s go ahead and detect faces from the given image. Remember, that we will also convert the image to grayscale.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Read input image (get image path first from command line, else take sample.png - default)</span>
</span></span><span style="display:flex;"><span>img_path <span style="color:#f92672">=</span> self<span style="color:#f92672">.</span>argv[<span style="color:#ae81ff">1</span>] <span style="color:#66d9ef">if</span> len(sys<span style="color:#f92672">.</span>argv) <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">1</span> <span style="color:#66d9ef">else</span> <span style="color:#e6db74">&#34;sample.png&#34;</span>
</span></span><span style="display:flex;"><span>img <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>imread(img_path, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Convert the image to grayscale</span>
</span></span><span style="display:flex;"><span>gray <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>cvtColor(img, cv2<span style="color:#f92672">.</span>COLOR_BGR2GRAY)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Get faces</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Use default arguments, scaleFactor can be tweaked depending on the image</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># The output will be in format: [ [&lt;top left x coord&gt;, &lt;top left y&gt;, &lt;width&gt;, &lt;height&gt; : for face 1], [ ... : for face 2], ... ]</span>
</span></span><span style="display:flex;"><span>faces <span style="color:#f92672">=</span> face_detector<span style="color:#f92672">.</span>detectMultiScale(gray, scaleFactor<span style="color:#f92672">=</span><span style="color:#ae81ff">1.1</span>, minNeighbors<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>)
</span></span></code></pre></div><p>Once we have the faces, we can crop them and use in the Step-4 again. The output from face detection should look like this:</p>
<!-- raw HTML omitted -->
<h2 id="step-2-crop-faces">Step 2: Crop faces</h2>
<p>To crop them and store in another object:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>cropped_faces <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> face <span style="color:#f92672">in</span> faces:
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Get points: tlx (top left x), tly (top left y), w (width), h (height)</span>
</span></span><span style="display:flex;"><span>    tlx, tly, w, h <span style="color:#f92672">=</span> face[<span style="color:#ae81ff">0</span>], face[<span style="color:#ae81ff">1</span>], face[<span style="color:#ae81ff">2</span>], face[<span style="color:#ae81ff">3</span>]
</span></span><span style="display:flex;"><span>    cropped_faces<span style="color:#f92672">.</span>append(
</span></span><span style="display:flex;"><span>        face[tly:tly<span style="color:#f92672">+</span>h, tlx:tlx<span style="color:#f92672">+</span>w]
</span></span><span style="display:flex;"><span>    )
</span></span></code></pre></div><p>The list <code>cropped_faces</code> will now contain only faces. We can use this list again in Step-4!</p>
<h2 id="step-3-and-step-4-blur-the-image-and-overlay-faces">Step 3 and Step 4: Blur the image and overlay faces</h2>
<p>Let&rsquo;s blur the whole image, and then overlay the images on the top of it. To blur, we will be using Gaussian Blur which works just fine.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>blur <span style="color:#f92672">=</span> cv2<span style="color:#f92672">.</span>GaussianBlur(img, (<span style="color:#ae81ff">11</span>, <span style="color:#ae81ff">11</span>)) <span style="color:#75715e"># Here, (11, 11) is the kernel size</span>
</span></span></code></pre></div><p>Once the whole image has been blurred, let&rsquo;s overlay the cropped faces from <code>Step 2</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#66d9ef">for</span> face_index, cropped_face <span style="color:#f92672">in</span> enumerate(cropped_faces):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Get face coordinates, to get ROI</span>
</span></span><span style="display:flex;"><span>    face_coords <span style="color:#f92672">=</span> faces[face_index]
</span></span><span style="display:flex;"><span>    tlx, tly, w, h <span style="color:#f92672">=</span> face_coords[<span style="color:#ae81ff">0</span>], face_coords[<span style="color:#ae81ff">1</span>], face_coords[<span style="color:#ae81ff">2</span>], face_coords[<span style="color:#ae81ff">3</span>]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Overlay the ROI of face to the cropped face</span>
</span></span><span style="display:flex;"><span>    blur[tly:tly<span style="color:#f92672">+</span>h, tlx:tlx<span style="color:#f92672">+</span>w] <span style="color:#f92672">=</span> cropped_face
</span></span></code></pre></div><p>Following image explains the procedure in details with visualization.</p>
<!-- raw HTML omitted -->
<p>And this is how the output (on the right) will look like (see below).</p>
<!-- raw HTML omitted -->
<p>While I know many of you will be thinking that it&rsquo;s not accurate at all (since we can see the rectangle there), and that will be a topic for the next blog where we will attempt to crop a circle. Make sure to leave a comment if you have any suggestions, feedback or if this blog helped you in any way - I would love to hear that!</p>
]]></content>
        </item>
        
        <item>
            <title>Releasing Docker Container and Binder for using Xeus-Cling, Libtorch and OpenCV in C&#43;&#43;</title>
            <link>https://krshrimali.github.io/posts/2020/09/releasing-docker-container-and-binder-for-using-xeus-cling-libtorch-and-opencv-in-c-/</link>
            <pubDate>Tue, 15 Sep 2020 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2020/09/releasing-docker-container-and-binder-for-using-xeus-cling-libtorch-and-opencv-in-c-/</guid>
            <description>Today, I am elated to share Docker image for OpenCV, Libtorch and Xeus-Cling. We&amp;rsquo;ll discuss how to use the dockerfile and binder.
Before I move on, the credits for creating and maintaining Docker image goes to Vishwesh Ravi Shrimali. He has been working on some cool stuff, please do get in touch with him if you&amp;rsquo;re interested to know.
First question in your mind would be, Why use Docker or Binder?</description>
            <content type="html"><![CDATA[<p>Today, I am elated to share Docker image for <code>OpenCV</code>, <code>Libtorch</code> and <code>Xeus-Cling</code>. We&rsquo;ll discuss how to use the <code>dockerfile</code> and <code>binder</code>.</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Cover-Docker-Binder.jpg" alt=""></p>
<p>Before I move on, the credits for creating and maintaining Docker image goes to <a href="https://github.com/vishwesh5">Vishwesh Ravi Shrimali</a>. He has been working on some cool stuff, please do get in touch with him if you&rsquo;re interested to know.</p>
<p>First question in your mind would be, <strong>Why use Docker or Binder?</strong> The answer to it lies in the frequency of queries on <a href="http://www.discuss.pytorch.org">the discussion forum of PyTorch</a> and Stackoverflow on <strong>Installation of Libtorch with OpenCV in Windows/Linux/OSX</strong>. I&rsquo;ve had nightmares setting up the Windows system myself for <code>Libtorch</code> and nothing could be better than using <code>Docker</code>. Read on, to know why.</p>
<h2 id="installing-docker-on-mac-os">Installing Docker on Mac OS</h2>
<p>To install docker (community edition - CE) desktop in Mac OS system, simply navigate to the Stable Channel section <a href="https://docs.docker.com/v17.12/docker-for-mac/install/#download-docker-for-mac">here</a>. Once setup, you can use docker (command line and desktop). Once done, navigate to <a href="https://docs.docker.com/v17.12/docker-for-mac/install/#install-and-run-docker-for-mac">Install and run Docker for Mac</a> section and get used to the commands.</p>
<h2 id="installing-docker-on-ubuntu">Installing Docker on Ubuntu</h2>
<p>Before moving on, please consider reading the requirements to install Docker Community Edition](<a href="https://docs.docker.com/v17.12/install/linux/docker-ce/ubuntu/)">https://docs.docker.com/v17.12/install/linux/docker-ce/ubuntu/)</a>. For the steps to install <code>Docker CE</code>, refer <a href="https://docs.docker.com/v17.12/install/linux/docker-ce/ubuntu/#install-docker-ce-1">this</a>.</p>
<h2 id="installing-docker-on-windows">Installing Docker on Windows</h2>
<p>To install Docker on Windows, download docker (stable channel) from <a href="https://docs.docker.com/v17.12/docker-for-windows/install/#download-docker-for-windows">here</a>. The installation steps to install <code>Docker Desktop</code> on Windows can be found <a href="https://docs.docker.com/v17.12/docker-for-windows/install/#install-docker-for-windows-desktop-app">here</a>.</p>
<h2 id="using-docker-image">Using Docker Image</h2>
<ol>
<li>Fetch the docker image: <code>docker pull vishwesh5/libtorch-opencv:opencv-4-1-0</code>. This shall take a lot of time, so sit back and relax.</li>
<li>Run: <code>docker run -p 5000:5000 -p 8888:8888 -it vishwesh5/libtorch-opencv:opencv-4-1-0 /bin/bash</code>.</li>
</ol>
<p>To know more about these commands, check out the references section.</p>
<p>Once done, you&rsquo;ll see your terminal showing another username: <code>jovyan</code>. You&rsquo;ve entered the docker image, congratulations! No need to setup <code>OpenCV</code> or <code>Libtorch</code>. Vishwesh has done it for you!</p>
<p>Now since you have entered the docker container successfully, it should look something similar to this:</p>
<!-- raw HTML omitted -->
<p>Time to test <code>Libtorch</code>. Let&rsquo;s go ahead and test a simple VGG-Net on MNIST dataset using Libtorch.</p>
<h2 id="testing-docker-image">Testing Docker Image</h2>
<ol>
<li>Clone the repository containing code for <strong>Digit Classification using Libtorch on MNIST dataset</strong>: <code>git clone https://github.com/krshrimali/Digit-Recognition-MNIST-SVHN-PyTorch-CPP.git</code>. Change directory to the cloned repository.</li>
<li>Download the MNIST data from <a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a>. Download <code>train-images-idx3-ubyte.gz</code> and <code>train-labels-idx1-ubyte.gz</code> files for training the VGG-Net. You can skip downloading the test data for now. Use <code>gunzip &lt;file_path&gt;</code> to extract the training images and labels, and put them in the <code>data/</code> folder inside the clones repository.</li>
<li>Create a <code>build</code> folder: <code>mkdir build</code></li>
<li>Run the CMake Configuration using: <code>cmake -DCMAKE_PREFIX_PATH=/opt/libtorch ..</code>. The result should be similar to something in the figure below.</li>
<li>Build the code using <code>make</code> command: <code>make</code>.</li>
<li>Execute the code, and that&rsquo;s it. Have fun learning.</li>
</ol>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Docker-Image-2.png" alt=""></p>
<h2 id="testing-docker-image-with-xeus-cling">Testing Docker Image with Xeus-Cling</h2>
<p>Let&rsquo;s test the Docker Image with Xeus-Cling.</p>
<ol>
<li>Run <code>jupyter notebook</code> command in the console and copy the token from the url provided.</li>
<li>Open <code>http://localhost:8888</code> in your browser. Note that the port address (<code>8888</code>) comes from <code>-p 8888:8888</code> in the <code>docker run</code> command. You can change that if you want. Enter the token when asked.</li>
<li>Start a new notebook using <code>C++XX</code> kernel.</li>
<li>Include and load libraries in the first cell using: <code>#include &quot;includeLibraries.h&quot;</code>. This should do all the stuff for you.</li>
<li>Start doing experiments using Xeus-Cling now.</li>
</ol>
<h2 id="using-binder">Using Binder</h2>
<p>And! What if you just want to try <code>Libtorch</code> or show it to the students? What if you are on a remote PC, and can&rsquo;t install Docker? Well, here is the <code>Binder</code>: <a href="https://mybinder.org/v2/gh/vishwesh5/torch-binder/master">https://mybinder.org/v2/gh/vishwesh5/torch-binder/master</a>.</p>
<p>Go to the above link and a notebook shall open.</p>
<p>Create a new notebook and start with: <code>#include &quot;includeLibraries.h&quot;</code> first and then start testing.</p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>Thanks to Vishwesh Ravi Shrimali, for creating the docker container and binder for this post.</p>
<h2 id="references">References</h2>
<ol>
<li><a href="https://www.learnopencv.com/install-opencv-docker-image-ubuntu-macos-windows">Install OpenCV Docker Image on Ubuntu, MacOS or Windows by Vishwesh Ravi Shrimali</a>.</li>
</ol>
]]></content>
        </item>
        
        <item>
            <title>Understanding how Vectors work in C&#43;&#43; (Part-2): What happens when you initialize a vector?</title>
            <link>https://krshrimali.github.io/posts/2020/04/understanding-how-vectors-work-in-c-part-2-what-happens-when-you-initialize-a-vector/</link>
            <pubDate>Sun, 26 Apr 2020 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2020/04/understanding-how-vectors-work-in-c-part-2-what-happens-when-you-initialize-a-vector/</guid>
            <description>In the last blog post, I realized there were a lot of methods inherited from the base struct _Vector_base_ and _Vector_impl_data. Instead of directly going to the source code of these structs, I&amp;rsquo;ll go through their methods and objects by explaining what happens when we initialize a vector.
That is, we will start from calling a vector constructor and then see how memory is allocated. If you haven&amp;rsquo;t looked at the previous blog post, please take a look here.</description>
            <content type="html"><![CDATA[<p>In the last blog post, I realized there were a lot of methods inherited from the base struct <code>_Vector_base_</code> and <code>_Vector_impl_data</code>. Instead of directly going to the source code of these structs, I&rsquo;ll go through their methods and objects by explaining what happens when we initialize a vector.</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Vector-Part-2.png" alt=""></p>
<p>That is, we will start from calling a vector constructor and then see how memory is allocated. If you haven&rsquo;t looked at the previous blog post, please take a look <a href="https://krshrimali.github.io/posts/2020/04/understanding-how-vectors-work-in-c-part-1-how-does-push_back-work/">here</a>. I want to be thorough with the blog post, so I&rsquo;ll divide this into multiple posts. By the end of this post, you&rsquo;ll go through the following structs:</p>
<ol>
<li><code>_Vector_impl_data</code> struct which contains pointers to memory locations (start, finish and end of storage).</li>
<li><code>_Vector_impl</code> struct (inherits <code>_Vector_impl_data</code> as well)).</li>
</ol>
<p>I usually opt for the bottom-up approach. Vectors can be initialized in many ways, three of them will be discussed in today&rsquo;s blog. We&rsquo;ll start from the very basic constructor of a vector using an initializer list and slowly reach to memory allocation and how the above 2 structs are used. Let&rsquo;s start!</p>
<h2 id="using-initializer-lists">Using Initializer Lists</h2>
<p>So what happens when we initialize a vector with an initializer list?</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> vec {<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>};
</span></span></code></pre></div><p>The vector class has many constructors in GCC depending on the type of inputs you give. Let&rsquo;s take a look at the constructor when the input is an initializer list:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>vector(initializer_list<span style="color:#f92672">&lt;</span>value_type<span style="color:#f92672">&gt;</span> __l, <span style="color:#66d9ef">const</span> allocator_type<span style="color:#f92672">&amp;</span> __a <span style="color:#f92672">=</span> allocator_type()) <span style="color:#f92672">:</span> _Base(__a) {
</span></span><span style="display:flex;"><span>    _M_range_initialize(__l.begin(), __l.end(), random_access_iterator_tag());
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>If you are curious what <code>_Base</code> is, <code>_Base</code> is declared as: <code>typedef _Vector_base&lt;_Tp, _Alloc&gt; _Base;</code>. Just so you know, where and how is <code>_Vector_base</code> used. When the constructor is called, it calls the constructor of <code>_Vector_base</code> with <code>__a</code> (allocator type). As you might have noticed, we are calling <code>_M_range_initialize</code> and passing 2 iterators (<code>__l.begin(), __l.end()</code>) and 1 forward iterator tag.</p>
<p>Note that the iterators are Forward Iterators, that is: we can use these iterators to access elements from begin (accessed using <code>.begin()</code>) till the end (accessed using <code>.end()</code>).</p>
<p>We are using <code>random_access_iterator_tag</code> as <code>forward_iterator_tag</code>. This tag helps us to categorize the iterator as random-access iterator. Random-access iterators allow accessing elements by passing arbitrary offset position (see: <a href="http://www.cplusplus.com/reference/iterator/RandomAccessIterator">documentation</a> for more details).</p>
<p>Let&rsquo;s go ahead and see what <code>_M_range_initialize</code> does.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> _ForwardIterator<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">void</span> _M_range_initialize(_ForwardIterator __first, _ForwardIterator __last, std<span style="color:#f92672">::</span>forward_iterator_tag) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">const</span> size_type __n <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>distance(__first, __last);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_start <span style="color:#f92672">=</span> <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_allocate(_S_check_init_len(__n, _M_get_Tp_allocator()));
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_end_of_storage <span style="color:#f92672">=</span> <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_start <span style="color:#f92672">+</span> __n;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_finish <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>__uninitialized_copy_a(__first, __last, <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_start, _M_get_Tp_allocator());
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Let&rsquo;s go line by line.</p>
<ul>
<li>First we find the distance using <code>std::distance</code> which takes first and last iterators, and returns size such as: <code>__last = __first + size</code>.</li>
<li>Next, we allocate memory for <code>__n</code> objects. The function <code>this-&gt;_M_allocate</code> returns pointer to the starting location of the memory allocated.
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">static</span> size_type <span style="color:#a6e22e">_S_check_init_len</span>(size_type __n, <span style="color:#66d9ef">const</span> allocator_type<span style="color:#f92672">&amp;</span> __a)
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (__n <span style="color:#f92672">&gt;</span> _S_max_size(_Tp_alloc_type(__a)))
</span></span><span style="display:flex;"><span>    __throw_length_error(
</span></span><span style="display:flex;"><span>        __N(<span style="color:#e6db74">&#34;cannot create std::vector larger than max_size()&#34;</span>));
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> __n;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><ul>
<li>The function <code>_S_check_init_len</code> is called by constructors to check size. If the requested size is greater than the maximum size for the allocator type, it throws length error (<code>&quot;cannot create std::vector larger than max_size()&quot;</code>). Else, it returns <code>__n</code>.</li>
<li>Once we have validated the size, <code>this-&gt;_M_allocate</code> call allocates the memory. Note that, <code>_M_allocate</code> is a part of <code>_Vector_base</code> struct. <code>_M_allocate</code> allocates memory for <code>__n</code> number of objects. This returns a pointer to the memory location (starting), to <code>_M_start</code>.</li>
<li>The end of storage pointer stores the end of memory location for the memory allocated for <code>__n</code> objects.</li>
<li>The function <code>std::__uninitialized_copy_a</code> copies the range <code>[__first, __last)</code> into the <code>this-&gt;_M_impl._M_start</code>. This returns a pointer to memory location starting at <code>this-&gt;_M_impl._M_start</code> with length of <code>__first - __last</code>.</li>
</ul>
</li>
</ul>
<p>To summarize, when we initialized vector with initializer list:</p>
<ol>
<li>It first calculates the number of objects to allocate memory for. This is assigned to <code>__n</code>.</li>
<li>Then, memory is allocated for <code>__n</code> objects (including a check if this much memory can be allocated based on the allocator type, if not then it returns a length error). The pointer <code>_M_start</code> points to the starting memory location.</li>
<li>The end of storage is the end location of the storage. Since we have passed the initializer list, so it knows the end of storage is starting location + len(initializer_list).</li>
<li>The elements are then copied the range <code>[__first, __last)</code> into the memory allocated.</li>
</ol>
<p>Depending on how you initialize your vectors, the process may change but overall, the intention is the same: to allocate memory (if valid) and set pointers (start, end of storage and finish).</p>
<h2 id="using-similar-value-and-specified-number-of-elements-fill">Using similar value and specified number of elements (fill)</h2>
<p>Let&rsquo;s take a look at an example of using</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> vec(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">0</span>);
</span></span></code></pre></div><p>The above constructor call will give you a vector of 10 elements with all zeros. You can print the elements using:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Instead of using auto, we can use
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// for (std::vector&lt;int&gt;::iterator it = vec.begin(); it != vec.end(); it++) {
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">//     std::cout &lt;&lt; *it &lt;&lt; &#34; &#34;;
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// }
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">for</span> (<span style="color:#66d9ef">auto</span> it <span style="color:#f92672">=</span> vec.begin(); it <span style="color:#f92672">!=</span> vec.end(); it<span style="color:#f92672">++</span>) {
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#f92672">*</span>it <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34; &#34;</span>;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span></code></pre></div><p>Let&rsquo;s see what changes when the vector is constructed in the above mentioned way. Let&rsquo;s take a look at the constructor which is called:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>vector(size_type __n, <span style="color:#66d9ef">const</span> value_type<span style="color:#f92672">&amp;</span> __value, <span style="color:#66d9ef">const</span> allocator_type<span style="color:#f92672">&amp;</span> __a <span style="color:#f92672">=</span> allocator_type()) <span style="color:#f92672">:</span> _Base(_S_check_init_len(__n, __a), __a {
</span></span><span style="display:flex;"><span>    _M_fill_initialize(__n, __value);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>As the documentation of the above constructor explains, this constructor fills the vector with <code>__n</code> copies of <code>__a</code> value. Note the use of <code>_S_check_init_len</code> here (we discussed this before). Instead of calling <code>_M_range_initialize</code>, <code>_M_fill_initialize</code> is called here. For our example, this function is passed with values: 10 (<code>__n</code>) and 0 (<code>__value</code>). Let&rsquo;s take a look at the definition of <code>_M_fill_initialize</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">_M_fill_initialize</span>(size_type __n, <span style="color:#66d9ef">const</span> value_type<span style="color:#f92672">&amp;</span> __value) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_finish <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>__uninitialized_fill_n_a(<span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_start, __n, __value, _M_get_Tp_allocator());
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The call <code>__uninitialized_fill_n</code> copies the value (<code>__value</code>, here 0) into the range <code>[this-&gt;_M_impl._M_start, this-&gt;_M_impl._M_start + __n)</code> and returns the end of it&rsquo;s range. As per the documentation, it is similar to <code>fill_n()</code> but does not require an initialized output range. Wait, you might be wondering, we didn&rsquo;t initialize <code>this-&gt;_M_impl._M_start</code>! We did! Note that we called <code>_Base(_S_check_init_len(__n, __a)</code> when the constructor is called. <code>_Base</code> is nothing but a typedef of <code>_Vector_base</code>. Let&rsquo;s take a look at this call:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>_Vector_base(size_t __n) <span style="color:#f92672">:</span> _M_impl() {
</span></span><span style="display:flex;"><span>    _M_create_storage(__n);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><ul>
<li><code>_M_impl</code> is an object of type <code>_Vector_impl</code> declared in <code>_Vector_base</code> struct.</li>
<li><code>_M_create_storage(__n)</code> is defined as:
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">_M_create_storage</span>(size_t __n) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_start <span style="color:#f92672">=</span> <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_allocate(__n);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_finish <span style="color:#f92672">=</span> <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_start;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_end_of_storage <span style="color:#f92672">=</span> <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_start <span style="color:#f92672">+</span> __n;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div>This will answer most of your queries. Let&rsquo;s start line by line.
<ul>
<li><code>this-&gt;_M_allocate(__n)</code> was discussed before, which allocates memory for <code>__n</code> objects. Please note that the constructor call <code>_M_impl()</code> had initialized these pointers for us. Here, the pointer is set to the starting memory location.</li>
<li>Since the function <code>_M_create_storage</code> creates storage, and doesn&rsquo;t copy elements to the memory location. So <code>this-&gt;_M_impl._M_finish</code> is set to <code>this-&gt;_M_impl._M_start</code>.</li>
<li>The end of storage is, as before, set to <code>this-&gt;_M_impl._M_start + __n</code>.</li>
</ul>
</li>
</ul>
<p>So, eventually, it&rsquo;s quite similar to what we saw when we initialized our vector with initializer list.</p>
<h2 id="using-another-vector-copy">Using another vector (copy)</h2>
<p>Let&rsquo;s take a look at another way to another initalize a vector:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> vec_copy {<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>};
</span></span><span style="display:flex;"><span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> vec(vec_copy);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Try printing the elements of vec
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">for</span> (<span style="color:#66d9ef">auto</span> it <span style="color:#f92672">=</span> vec.begin(); it <span style="color:#f92672">!=</span> vec.end(); it<span style="color:#f92672">++</span>) {
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#f92672">*</span>it <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>When you call <code>vec(vec_copy)</code>, the copy constructor is called. Let&rsquo;s take a look at it&rsquo;s definition:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>vector(<span style="color:#66d9ef">const</span> vector<span style="color:#f92672">&amp;</span> __x) <span style="color:#f92672">:</span> _Base(__x.size(), _Alloc_traits<span style="color:#f92672">::</span>_S_select_on_copy(__x._M_get_Tp_allocator()) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_finish <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>__uninitialized_copy_a(__x.begin(), __x.end(), <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_start, _M_get_Tp_allocator());
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The function body is similar to what we saw in the constructor definition when we initialized vector using <code>size_type __n, value_type value</code>. Notice how we initialize the base struct here. Let&rsquo;s take a look at <code>_S_select_on_copy(__x._M_get_Tp_allocator())</code> first. <code>_M_get_Tp_allocator()</code> returns <code>_M_impl</code> object.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">const</span> _Tp_alloc_type<span style="color:#f92672">&amp;</span> _M_get_Tp_allocator() {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Note that, here, <code>this-&gt;_M_impl</code> will already have the pointers set to the memory locations for start, finish and end of storage (as we use the allocator of <code>__x</code>). The objective is to use the copy of allocator object used by <code>__x</code>. Let&rsquo;s take a look at the constructor of Base struct:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>_Vector_base(size_t __n, <span style="color:#66d9ef">const</span> allocator_type<span style="color:#f92672">&amp;</span> __a) <span style="color:#f92672">:</span> _M_impl(__a) {
</span></span><span style="display:flex;"><span>    _M_create_storage(__n);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Overall, it&rsquo;s the same to what we saw before except that we use the copy of the alloactor of vector <code>__x</code>. The call <code>_M_create_storage(__n)</code> does the same task of setting pointers <code>_M_start, M_end_of_storage, _M_finish</code> as we observed before.</p>
<p>For today&rsquo;s blog, we discussed 3 popular ways to initialize a vector in C++ and went through how memory is allocated when the constructors are called. As we move forward, we will slowly get familiar with the design patterns and methods used in GCC.</p>
<p>As always, I would love to hear your feedback on my blogs. Correct me if I was wrong anywhere, no one is perfect afterall. If this helped you, please let me know - it keeps me going! See you all in the next blog!</p>
]]></content>
        </item>
        
        <item>
            <title>Understanding how Vectors work in C&#43;&#43; (Part-3): Diving deep into member functions of vectors</title>
            <link>https://krshrimali.github.io/posts/2020/04/understanding-how-vectors-work-in-c-part-3-diving-deep-into-member-functions-of-vectors/</link>
            <pubDate>Sun, 26 Apr 2020 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2020/04/understanding-how-vectors-work-in-c-part-3-diving-deep-into-member-functions-of-vectors/</guid>
            <description>In this blog, we&amp;rsquo;ll continue diving deep into the source code of Vector Containers in GCC compiler. Today, we will be discussing some of the most commonly used methods of vectors, and how they are implemented.
Before we start, if you haven&amp;rsquo;t looked at the previous blogs in the C++ series, please take a look here. If you are already familiar with memory allocation in vector containers and vector&amp;rsquo;s base structs, then you can skip reading the previous blogs and continue here.</description>
            <content type="html"><![CDATA[<p>In this blog, we&rsquo;ll continue diving deep into the source code of Vector Containers in GCC compiler. Today, we will be discussing some of the most commonly used methods of vectors, and how they are implemented.</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Vector-Part-3.png" alt=""></p>
<p>Before we start, if you haven&rsquo;t looked at the previous blogs in the C++ series, please take a look <a href="https://krshrimali.github.io/categories/cpp/">here</a>. If you are already familiar with memory allocation in vector containers and vector&rsquo;s base structs, then you can skip reading the previous blogs and continue here. If not, I suggest you reading them.</p>
<p>Let&rsquo;s start off with <code>pop_back</code> member function, which essentially deletes the last element from the vector and reduces the size by one. Let&rsquo;s take a look how it is used:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e"># Initialize a vector using initializer list
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> X {<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>};
</span></span><span style="display:flex;"><span>X.pop_back();
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> (<span style="color:#66d9ef">auto</span> <span style="color:#66d9ef">const</span><span style="color:#f92672">&amp;</span> element: X) {
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> element <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34; &#34;</span>;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>You will see the output as: <code>1 2</code>. If you are wondering how this works in the case of a 2D vector, let&rsquo;s take a look:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e"># Initialize a 2D vector using initializer list
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;&gt;</span> X { {<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">3</span>}, {<span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">5</span>, <span style="color:#ae81ff">6</span>} };
</span></span><span style="display:flex;"><span>X.pop_back();
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> (<span style="color:#66d9ef">auto</span> <span style="color:#66d9ef">const</span><span style="color:#f92672">&amp;</span> element: X) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> (<span style="color:#66d9ef">auto</span> <span style="color:#66d9ef">const</span><span style="color:#f92672">&amp;</span> _element: element) {
</span></span><span style="display:flex;"><span>        std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> _element <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34; &#34;</span>;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">&#34;</span>;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>You will see the output as: <code>1 2 3</code>. As you can notice, it popped back the last element which was indeed a vector. Let&rsquo;s start diving deep in the source code now, starting with declaration:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">pop_back</span>()
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    __glibcxx_required_nonempty();
</span></span><span style="display:flex;"><span>    __this<span style="color:#f92672">-&gt;</span>_M_impl._M_finish;
</span></span><span style="display:flex;"><span>    _Alloc_traits<span style="color:#f92672">::</span>destroy(<span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl, <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_finish);
</span></span><span style="display:flex;"><span>    _GLIBCXX_ASAN_ANNOTATE_SHRINK(<span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>A short note on <code>_GLIBCXX_NOEXCEPT</code> operator (<code>noexcept</code> since C++11): It returns true if the expression or member function is required to not throw any exceptions. <code>_GLIBCXX_NOEXCEPT</code> is defined as <code>noexcept</code> for C++ versions &gt;= 2011:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">if</span> __cplusplus <span style="color:#f92672">&gt;=</span> <span style="color:#ae81ff">201103L</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># define _GLIBCXX_NOEXCEPT noexcept
</span></span></span></code></pre></div><p>You can use a condition by using <code>_GLIBCXX_NOEXCEPT_IF(condition)</code> which essentially calls <code>noexcept(condition)</code>. One use of this is when you want to access a particular index in a vector, you can avoid check if the location exists or not by using <code>noexcept</code>.</p>
<p>When you call <code>pop_back</code> the design rule first checks if the vector is empty or not. If it&rsquo;s nonempty, only then it makes sense to pop the last element, right? This is done by using <code>__glibcxx_required_nonempty()</code> call. The definition of this macro is:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e"># define __glibcxx_requires_nonempty() __glibcxx_check_nonempty()
</span></span></span></code></pre></div><p>As you can see, it&rsquo;s calling <code>__glibcxx_check_nonempty()</code> macro which checks using <code>this-&gt;empty()</code> call:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e"># define __glibcxx_check_nonempty() \
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">_GLIBCXX_DEBUG_VERIFY(! this-&gt;empty(), _M_message(::__gnu_debug::__msg_empty)._M_sequence(*this, &#34;this))
</span></span></span></code></pre></div><p>These are typical GCC macros for assertions. If we the vector is nonempty, we now move forward in fetching the last location in the memory of our vector container (using <code>_M_impl._M_finish</code> pointer), please take a look at the previous blogs if you aren&rsquo;t aware of <code>_M_impl</code> struct. As the term suggests, we attempt to destroy the memory location using <code>_Alloc_traits::destroy(this-&gt;_M_impl, this-&gt;_M_impl._M_finish)</code>. <code>_Alloc_traits</code> allows us to access various properties of the allocator used.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// This function destroys an object of type _Tp
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> _Tp<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">static</span> <span style="color:#66d9ef">void</span> destroy(_Alloc<span style="color:#f92672">&amp;</span> __a, _Tp<span style="color:#f92672">&amp;</span> __p)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">noexcept</span>(<span style="color:#66d9ef">noexcept</span>(_S_destroy(__a, __p, <span style="color:#ae81ff">0</span>))
</span></span><span style="display:flex;"><span>{ _S_destroy(__a, __p, <span style="color:#ae81ff">0</span>); }
</span></span></code></pre></div><p>According to the official documentation of <code>destroy</code> static function: It calls <code>__a.destroy(__p) if that expression is well-formed, other wise calls __p-&gt;~_Tp()</code>. If we take a look at the existing overloads of <code>_S_destroy</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> _Alloc2, <span style="color:#66d9ef">typename</span> _Tp<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">static</span> <span style="color:#66d9ef">auto</span> _S_destroy(_Alloc2<span style="color:#f92672">&amp;</span> __a, _Tp<span style="color:#f92672">*</span> __p, <span style="color:#66d9ef">int</span>) <span style="color:#66d9ef">noexcept</span>(<span style="color:#66d9ef">noexcept</span>(__a.destroy(__p)))
</span></span><span style="display:flex;"><span><span style="color:#f92672">-&gt;</span> <span style="color:#66d9ef">decltype</span>(__a.destroy(__p))
</span></span><span style="display:flex;"><span>{ __a.destroy(__p); }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> _Alloc2, <span style="color:#66d9ef">typename</span> _Tp<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">static</span> <span style="color:#66d9ef">void</span> _S<span style="color:#f92672">-</span>destroy(_Alloc2<span style="color:#f92672">&amp;</span> __a, _Tp<span style="color:#f92672">*</span> __p, ...) <span style="color:#66d9ef">noexcept</span>(<span style="color:#66d9ef">noexcept</span>(__p<span style="color:#f92672">-&gt;~</span>_Tp()))
</span></span><span style="display:flex;"><span>{ __p<span style="color:#f92672">-&gt;~</span>_Tp(); }
</span></span></code></pre></div><p>So clearly, if the expression is well-formed, it will call our allocator&rsquo;s destroy method and pass the pointer location in that call. Otherwise, it calls the destructor of the pointer itself (<code>__p-&gt;~_Tp()</code>). Once successfully done, we reduce the size by 1 using:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e"># define _GLIBCXX_ASAN_ANNOTATE_SHRINK(n) \
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">  _Base::_Vector_impl::template _Asan&lt;&gt;::_S_shrink(this-&gt;_M_impl, n)
</span></span></span></code></pre></div><p>As you would see, the macro calls <code>_S_shrink</code> function to sanitize the vector container (i.e. reduce the size by n, here 1):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> _Up<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">_Asan</span><span style="color:#f92672">&lt;</span>allocator<span style="color:#f92672">&lt;</span>_Up<span style="color:#f92672">&gt;&gt;</span>
</span></span><span style="display:flex;"><span>  {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">static</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">_S_adjust</span>(_Vector_impl<span style="color:#f92672">&amp;</span> __impl, pointer __prev, pointer _curr)
</span></span><span style="display:flex;"><span>    { __sanitizer_annotate_contiguous_container(__impl._M_start, __impl._M_end_of_storage, __prev, __curr); }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">static</span> <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">_S_shrink</span>(_Vector_impl<span style="color:#f92672">&amp;</span> __impl, size_type __n)
</span></span><span style="display:flex;"><span>    { _S_adjust(__impl, __impl._M_finish <span style="color:#f92672">+</span> __n, __impl._M_finish); }
</span></span><span style="display:flex;"><span>  }
</span></span></code></pre></div><p>We don&rsquo;t need to go deeper into these calls, but (as per official documentation), the call <code>_S_adjust</code> adjusts ASan annotation for <code>[_M_start, _M_end_of_storage)</code> to mark end of valid region as <code>__curr</code> instead of <code>__prev</code> (note that we already had deleted the last element, so <code>__impl.__M_finish + __n</code> (here <code>__n</code> is 1) will be the old pointer).</p>
<p>A good useful note here is, that <code>pop_back</code> function isn&rsquo;t marked <code>noexcept</code> as we already have conditions to check the container being non-empty. In case there is any failure, the debug macros are called and throw necessary exceptions.</p>
<p>Let&rsquo;s go ahead and take a look at a few other member functions (there are many, take a look here: <a href="https://en.cppreference.com/w/cpp/container/vector">https://en.cppreference.com/w/cpp/container/vector</a>, I only discuss those which are commonly used)</p>
<ol>
<li>
<p><code>back()</code>: Let&rsquo;s take a look at <code>back</code> call. As the name suggests (and as we saw before), this returns the last element in the vector container. It can be used as <code>X.back()</code> where <code>X</code> is a valid vector container. Let&rsquo;s take a look at how it is implemented in GCC:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>reference <span style="color:#a6e22e">back</span>()
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    _glibcxx_requires_nonempty();
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#f92672">*</span>(end() <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// definition of end()
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>iterator <span style="color:#a6e22e">end</span>()
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> iterator(<span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_finish);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Note that <code>end()</code> points to one past the last element in the vector. That&rsquo;s why we do <code>end()-1</code> in the definition of <code>back</code> function. This should now be pretty obvious, that why use assertion <code>_glibcxx_requires_nonempty()</code> as we want to make sure that we are returning valid memory location.</p>
</li>
<li>
<p><code>front()</code>: It should be very similar to what we saw with <code>back()</code>. This returns reference to the first element of the vector.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>reference <span style="color:#a6e22e">front</span>()
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    _glibcxx_requires_nonempty();
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> <span style="color:#f92672">*</span>begin();
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// definition of begin()
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>iterator <span style="color:#a6e22e">begin</span>()
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> iterator(<span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_start);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Note how we use the pointers <code>_M_start</code> and <code>_M_finish</code> to access first and the last elements of the vector container respectively.</p>
</li>
<li>
<p><code>reserve()</code>: Some times we want to pre-allocate memory to a vector container. You can do that using <code>X.reserve(10)</code> to reserve enough size for 10 elements (integers if X is <code>std::vector&lt;int&gt;</code> type).</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">reserve</span>(size_type __n)
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (__n <span style="color:#f92672">&gt;</span> max_size())
</span></span><span style="display:flex;"><span>        _throw_length_error(__N(<span style="color:#e6db74">&#34;vector::reserve&#34;</span>));
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (capacity() <span style="color:#f92672">&lt;</span> __n)
</span></span><span style="display:flex;"><span>        _M_reallocate(__n);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>So when you want to pre-allocate memory, there are 3 possibilities:</p>
<ul>
<li>There is already enough memory allocated. No need to allocate. (Case of <code>capacity() &gt; __n</code>)</li>
<li>There is not enough memory allocated. Need to reallocate memory. (Case of <code>capacity() &lt; __n</code>)</li>
<li>The required size is greater than maximum size possible, then lenght error is thrown. (Case of <code>__n &gt; max_size()</code>)</li>
</ul>
</li>
<li>
<p><code>size()</code>: This will return the size of the vector container:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>size_type <span style="color:#a6e22e">size</span>() <span style="color:#66d9ef">const</span>
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> size_type(end() <span style="color:#f92672">-</span> begin());
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>So, let&rsquo;s say you have reserved memory for 10 elements, then <code>size()</code> will return 10.</p>
</li>
<li>
<p><code>capacity()</code>: This returns the size the container can store currently.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>size_type <span style="color:#a6e22e">capacity</span>() <span style="color:#66d9ef">const</span>
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> size_type(const_iterator(<span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_end_addr(), <span style="color:#ae81ff">0</span>) <span style="color:#f92672">-</span> begin());
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Here, <code>_M_end_addr()</code> returns address of (end of storage + 1) location (if the pointer to <code>this-&gt;_M_impl._M_end_of_storage</code> exists).</p>
</li>
</ol>
<p>There maybe a few member functions that I missed, but I&rsquo;m sure the tutorials so far in the Vectors series are (hopefully) enough to help you out with understanding the source code.</p>
<p>With this blog post, we are also done with the vector series in C++, and coming up next, we will take a look on using all of this knowledge to implement useful utilities for vectors while implementing libraries and projects, and also other design patterns in C++.</p>
<h2 id="acknowledgement">Acknowledgement</h2>
<p>I have received a lot of love and support for these blogs, and I am grateful to each and everyone of you! I write these blogs to share what I know with others and in a hope to motivate people to not fear when looking at the source code of any library. I think, reading codes is a good practice.</p>
<p>I am thankful to <a href="https://krshrimali.github.io/categories/cpp/">Martin York</a> (aka Loki Astari on <a href="https://stackoverflow.com/users/14065/martin-york%22%3Estackoverflow">stackoverflow</a>) for his constructive feedback on my blogs. Special thanks to <a href="https://www.linkedin.com/in/ujval-kapasi">Ujval Kapasi</a> for taking time to read through my blogs and giving valuable feedback.</p>
<p>I was, am and will always be grateful to my elder brother <a href="https://www.linkedin.com/in/vishwesh5/">Vishwesh Ravi Shrimali</a> (also my all time mentor) who helped me getting started with C++, AI and whatever I have been doing recently. He inspires me.</p>
]]></content>
        </item>
        
        <item>
            <title>Understanding how Vectors work in C&#43;&#43; (Part-1): How does push_back work?</title>
            <link>https://krshrimali.github.io/posts/2020/04/understanding-how-vectors-work-in-c-part-1-how-does-push_back-work/</link>
            <pubDate>Sat, 18 Apr 2020 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2020/04/understanding-how-vectors-work-in-c-part-1-how-does-push_back-work/</guid>
            <description>This blog is focused to explain how vectors work in the backend, and we&amp;rsquo;ll specially look at push_back method of the vector container. Looking at the source code helps to understand the implementation, and how vectors can be used efficiently.
Vector Containers are type of sequenced containers in C++ commonly uses as a better alternative of arrays. They are also known as dynamic arrays, and as the term suggests - it&amp;rsquo;s one of the advantages they hold over native arrays in C++.</description>
            <content type="html"><![CDATA[<p>This blog is focused to explain how vectors work in the backend, and we&rsquo;ll specially look at <code>push_back</code> method of the vector container. Looking at the source code helps to understand the implementation, and how vectors can be used efficiently.</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Vector-Part-1.png" alt=""></p>
<p>Vector Containers are type of sequenced containers in C++ commonly uses as a better alternative of arrays. They are also known as dynamic arrays, and as the term suggests - it&rsquo;s one of the advantages they hold over native arrays in C++. You might have heard of Standard Library containers like <code>vector</code>, <code>set</code>, <code>queue</code>, <code>priority_queue</code> before. They all implement methods defined by the Container Concept.</p>
<p><strong>A few important notes before we start:</strong></p>
<ul>
<li>I&rsquo;m using GCC 10.0.1 which is in the development stage. I&rsquo;ve built GCC 10.0.1 from source on my local system. But everything I discuss here, should be same with GCC 8.4 or GCC 9.3 releases.</li>
<li>I assume you are at least using C++11. If for any reason you are using C++98, there might be a few differences (for example, variadic arguments were not present in C++98). To not include lots of macros to check C++ versions, I&rsquo;ve at times assumed the reader is using C++11 or greater.</li>
<li>This blog uses lots of C++ Design Patterns that many would not be aware of. I understand it might just be a good idea to explain them first in a blog, but for now - I assume you have at least heard of them and know a thing or two about C++. I&rsquo;ll cover these in future.</li>
</ul>
<p>Let&rsquo;s start with a basic comparison of using arrays and vectors in C++:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Create an array of fixed size: 10
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">int</span><span style="color:#f92672">*</span> InputArray <span style="color:#f92672">=</span> <span style="color:#66d9ef">new</span> <span style="color:#66d9ef">int</span>[<span style="color:#ae81ff">10</span>];
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> (<span style="color:#66d9ef">int</span> i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>; i <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">10</span>; i<span style="color:#f92672">++</span>) {
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Let&#39;s assign values to the array
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// Values are same as indices
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    InputArray[i] <span style="color:#f92672">=</span> i;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>We can do the same (from what you see above) using <code>vector</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Include this to be able to use vector container
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;vector&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> InputVector {};
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> (<span style="color:#66d9ef">int</span> i <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>; i <span style="color:#f92672">&lt;</span> <span style="color:#ae81ff">10</span>; i<span style="color:#f92672">++</span>) {
</span></span><span style="display:flex;"><span>    InputVector.push_back(i);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>While both do the same, but there are many important differences that happen in the backend. Let&rsquo;s start with performance.</p>
<ul>
<li>The piece of code using vector containers in C++ took 23.834 microseconds.</li>
<li>The piece of code using arrays in C++ took 3.26 microseconds.</li>
</ul>
<p>If we had to do this for 10k numbers, the performance might be significant:</p>
<ul>
<li>The piece of code using vector containers in C++ (for 10k numbers) took 713 microseconds.</li>
<li>The piece of code using arrays in C++ took 173 microseconds.</li>
</ul>
<p>As in software development, there is always a tradeoff. Since vectors aim to provide dynamic memory allocation, they lose some performance while trying to <code>push_back</code> elements in the vectors since the memory is not allocated before. This can be constant if memory is allocated before.</p>
<p>Let&rsquo;s try to infer this from the source code of vector container. The signature of a vector container looks like this:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">template</span><span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> _Tp, <span style="color:#66d9ef">typename</span> _Alloc <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>allocator<span style="color:#f92672">&lt;</span>_Tp<span style="color:#f92672">&gt;</span> <span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">class</span> <span style="color:#a6e22e">vector</span> <span style="color:#f92672">:</span> <span style="color:#66d9ef">protected</span> _Vector_base<span style="color:#f92672">&lt;</span>_Tp, _Alloc<span style="color:#f92672">&gt;</span>
</span></span></code></pre></div><p>Where <code>_Tp</code> is the type of element, and <code>_Alloc</code> is the allocator type (defaults to <code>std::allocator&lt;_Tp&gt;</code>). Let&rsquo;s start from the constructor of <code>vector</code> (when no parameter is passed):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">#if __cplusplus &gt;= 201103L
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>      vector() <span style="color:#f92672">=</span> <span style="color:#66d9ef">default</span>;
</span></span><span style="display:flex;"><span><span style="color:#75715e">#else
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>      vector() { }
</span></span><span style="display:flex;"><span><span style="color:#75715e">#endif
</span></span></span></code></pre></div><p>The constructor when called with no params, creates a vector with no elements. As always, there are various ways to initialize a vector object.</p>
<p>I want to focus more on <code>push_back</code> today, so let&rsquo;s take a look at it&rsquo;s signature. It&rsquo;s located in <code>stl_vector.h</code> file.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Note that value_type is defined as: typedef _Tp value_type as a public type
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">push_back</span>(<span style="color:#66d9ef">const</span> value_type<span style="color:#f92672">&amp;</span> __x)
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> (<span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_finish <span style="color:#f92672">!=</span> <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_end_of_storage)
</span></span><span style="display:flex;"><span>    {
</span></span><span style="display:flex;"><span>        _GLIBCXX_ASAN_ANNOTATE_GROW(<span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>        _Alloc_traits<span style="color:#f92672">::</span>construct(<span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl, <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_finish,
</span></span><span style="display:flex;"><span>                        __x);
</span></span><span style="display:flex;"><span>        <span style="color:#f92672">++</span><span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_finish;
</span></span><span style="display:flex;"><span>        _GLIBCXX_ASAN_ANNOTATE_GREW(<span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">else</span>
</span></span><span style="display:flex;"><span>        _M_realloc_insert(end(), __x);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>A few notes to take:</p>
<ul>
<li>
<p><code>value_type</code>: This is the type of the elements in the vector container. That is, if the vector is <code>std::vector&lt;std::vector&lt;int&gt; &gt;</code>, then value_type of the given vector will be <code>std::vector&lt;int&gt;</code>. This comes handy later for type checking and more.</p>
</li>
<li>
<p><code>_GLIBCXX_ASAN_ANNOTATE_GROW(1)</code>: The definition of this macro is:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">#define _GLIBCXX_ASAN_ANNOTATE_GROW(n) \
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">    typename _Base::_Vector_impl::template _Asan&lt;&gt;::_Grow \
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">        __attribute__((__unused__)) __grow_guard(this-&gt;_M_impl, (n))
</span></span></span></code></pre></div><ul>
<li>The base struct <code>_Vector_base</code> defines these functions and structs. Let&rsquo;s take a look at struct <code>_Asan</code>. Essentially, all we want to do with the above macro is to grow the vector container memory by n. Since when we insert an element, we only need to grow by 1, so we pass 1 to the macro call.</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">template</span><span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> <span style="color:#f92672">=</span> _Tp_alloc_type<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">_Asan</span>
</span></span><span style="display:flex;"><span>    {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">typedef</span> <span style="color:#66d9ef">typename</span> __gnu_cxx<span style="color:#f92672">::</span>__alloc_traits<span style="color:#f92672">&lt;</span>_Tp_alloc_type<span style="color:#f92672">&gt;::</span>size_type size_type;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">_Grow</span>
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            _Grow(_Vector_impl<span style="color:#f92672">&amp;</span>, size_type) { }
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">void</span> <span style="color:#a6e22e">_M_grew</span>(size_type) { }
</span></span><span style="display:flex;"><span>        };
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    };
</span></span></code></pre></div><p>If usage of Macros is new to you, please leave it for now as we&rsquo;ll discuss more about these design patterns in future.</p>
</li>
<li>
<p>A note on usage of <code>_M_impl</code>. It is declared as: <code>_Vector_impl&amp; _M_impl</code> in the header file. <code>_Vector_impl</code> is a struct defined as:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">_Vector_impl</span> <span style="color:#f92672">:</span> <span style="color:#66d9ef">public</span> _Tp_alloc_type, <span style="color:#66d9ef">public</span> _Vector_impl_data
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    _Vector_impl() _GLIBCXX_NOEXCEPT_IF(is_nothrow_default_constructible<span style="color:#f92672">&lt;</span>_Tp_alloc_type<span style="color:#f92672">&gt;::</span>value) <span style="color:#f92672">:</span> _Tp_alloc_type() { }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span><span style="color:#75715e">// more overloads for the constructor
</span></span></span></code></pre></div><p>The base struct <code>_Vector_impl_data</code> gives you helpful pointers to access later on:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">_Vector_impl_data</span>
</span></span><span style="display:flex;"><span>{
</span></span><span style="display:flex;"><span>    pointer _M_start;
</span></span><span style="display:flex;"><span>    pointer _M_finish;
</span></span><span style="display:flex;"><span>    pointer _M_end_of_storage;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// overloads of constructors
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>}
</span></span></code></pre></div><p>To go deep into the details is not useful here, but as you would have sensed, this helps us to access pointer to the start, finish and end of storage of the vector.</p>
</li>
</ul>
<p>You would have guessed by now, that <code>push_back</code> call will add the element to the end (observe <code>_Alloc_traits::construct(this-&gt;_M_impl, this-&gt;_M_impl._M_finish, __x);</code>) and will then increment the variable <code>_M_finish</code> by 1.</p>
<p>Note how <code>push_back</code> first checks if there is memory available. Of course we have limited memory available with us, and it checks if the end location of the current vector container equals the end storage capacity:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">if</span> (<span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_finish <span style="color:#f92672">!=</span> <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_end_of_storage) {
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>} <span style="color:#66d9ef">else</span> {
</span></span><span style="display:flex;"><span>    _M_realloc_insert(end(), __x);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>So if we have reached the end of storage, it calls <code>_M_realloc_insert(end(), __x)</code>. Now what is this? Let&rsquo;s take a look at it&rsquo;s definition:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">template</span> <span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span> _Tp, <span style="color:#66d9ef">typename</span> _Alloc<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">template</span><span style="color:#f92672">&lt;</span><span style="color:#66d9ef">typename</span>... _Args<span style="color:#f92672">&gt;</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">void</span> vector<span style="color:#f92672">&lt;</span>_Tp, _Alloc<span style="color:#f92672">&gt;::</span>_M_realloc_insert(iterator __position, _Args<span style="color:#f92672">&amp;&amp;</span>... __args) {
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// ...
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        pointer __old_start <span style="color:#f92672">=</span> <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_start;
</span></span><span style="display:flex;"><span>        pointer __old_finish <span style="color:#f92672">=</span> <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_finish;
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Here we have passed __position as end()
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#75715e">// So __elems_before will be total number of elements in our original vector
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#66d9ef">const</span> size_type __elems_before <span style="color:#f92672">=</span> __position <span style="color:#f92672">-</span> begin();
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Declare new starting and finishing pointers
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        pointer <span style="color:#a6e22e">__new_start</span>(<span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_allocate(__len));
</span></span><span style="display:flex;"><span>        pointer <span style="color:#a6e22e">__new_finish</span>(__new_start);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">__try</span>
</span></span><span style="display:flex;"><span>        {
</span></span><span style="display:flex;"><span>            <span style="color:#75715e">// Allocate memory and copy original vector to the new memory locations
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        }
</span></span><span style="display:flex;"><span>        __catch(...)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Destroy the original memory location
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        std<span style="color:#f92672">::</span>_Destroy(__old_start, __old_finish, _M_get_Tp_allocator());
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Change starting, finishing and end of storage pointers to new pointers
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_start <span style="color:#f92672">=</span> __new_start;
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_finish <span style="color:#f92672">=</span> __new_finish;
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// here __len is 1
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#66d9ef">this</span><span style="color:#f92672">-&gt;</span>_M_impl._M_end_of_storage <span style="color:#f92672">=</span> __new_start <span style="color:#f92672">+</span> __len;
</span></span><span style="display:flex;"><span>    }
</span></span></code></pre></div><p>Even though the above piece of code might scare a few (it did scare me when I looked at it for the first time), but just saying - this is just 10% of the definition of <code>_M_realloc_insert</code>.</p>
<p>If you haven&rsquo;t noticed so far, there is something very puzzling in the code: <code>template&lt;typename... _Args&gt;</code> &ndash; these are variadic arguments introduced in C++11. We&rsquo;ll talk about them later in the series of blogs.</p>
<p>Intuitively, by calling <code>_M_realloc_insert(end(), __x)</code> all we are trying to do is reallocate memory (end_of_storage + 1), copy the original vector data to the new memory locations, add <code>__x</code> and deallocate (or destroy) the original memory in the heap. This also allows to keep vector to have contiguous memory allocation.</p>
<p>For today, I think we discussed a lot about vectors and their implementation in GCC. We&rsquo;ll continue to cover rest of the details in the next part of the blog. I&rsquo;m sure, the next time you plan to use <code>push_back</code> - you&rsquo;ll know how things are happening in the backend. Till then, have fun and take care! :)</p>
<h2 id="a-request">A request</h2>
<p>For the past year, I&rsquo;ve been writing blogs on <a href="https://krshrimali.github.io/categories/pytorch/">PyTorch C++ API</a>. I&rsquo;ve been overwhelmed with your feedback, help and comments. Thank you! This series of blogs on C++, is experimental for now. I love reading source codes, and explaining it to readers. I hope this helps. Please leave your comment and feedback here, or reach out to me at <a href="mailto:kushashwaravishrimali@gmail.com">kushashwaravishrimali@gmail.com</a> if you wish. Even if you don&rsquo;t like this, say it! I promise, I&rsquo;ll be better next time.</p>
]]></content>
        </item>
        
        <item>
            <title>[Training and Results] Deep Convolutional Generative Adversarial Networks on CelebA Dataset using PyTorch C&#43;&#43; API</title>
            <link>https://krshrimali.github.io/posts/2020/02/training-and-results-deep-convolutional-generative-adversarial-networks-on-celeba-dataset-using-pytorch-c-api/</link>
            <pubDate>Sun, 23 Feb 2020 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2020/02/training-and-results-deep-convolutional-generative-adversarial-networks-on-celeba-dataset-using-pytorch-c-api/</guid>
            <description>It&amp;rsquo;s been around 5 months since I released my last blog on DCGAN Review and Implementation using PyTorch C++ API and I&amp;rsquo;ve missed writing blogs badly! Straight the to the point, I&amp;rsquo;m back!
But before we start, the PyTorch C++ Frontend has gone through several changes and thanks to the awesome contributors around the world, it resembles the Python API more than it ever did! Since a lot of things have changed, I have also updated my previous blogs (tested on 1.</description>
            <content type="html"><![CDATA[<p>It&rsquo;s been around 5 months since I released my last blog on <a href="https://krshrimali.github.io/posts/2019/09/deep-convolutional-generative-adversarial-networks-review-and-implementation-using-pytorch-c-api/">DCGAN Review and Implementation using PyTorch C++ API</a> and I&rsquo;ve missed writing blogs badly! Straight the to the point, I&rsquo;m back!</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Cover-DCGAN-2.jpg" alt=""></p>
<p>But before we start, the PyTorch C++ Frontend has gone through several changes and thanks to the awesome contributors around the world, it resembles the Python API more than it ever did! Since a lot of things have changed, I have also updated my previous blogs (tested on 1.4 Stable build).</p>
<h2 id="what-has-changed">What has changed?</h2>
<p>There have been major changes in the PyTorch C++ Frontend API (Libtorch) and we&rsquo;ll be discussing some of them which were related to our implementation on DCGAN. Let&rsquo;s see, what parts of our code have changed in the recent Libtorch version. Well, the frontend API of PyTorch in C++ resembles closely to Python now:</p>
<p>For what concerns our code on DCGAN, quoting the author (Will Feng) of PR <a href="https://github.com/pytorch/pytorch/pull/28917">#28917</a>.</p>
<blockquote>
<p>In Conv{1,2,3}dOptions:
- with_bias is renamed to bias.
- input_channels is renamed to in_channels.
- output_channels is renamed to out_channels.
- The value of transposed doesn&rsquo;t affect the behavior of Conv{1,2,3}d layers anymore. Users should migrate their code to use ConvTranspose{1,2,3}d layers instead.</p>
</blockquote>
<p>So, starting first, we need to change <code>with_bias</code> to <code>bias</code> in our model definitions. The generator class in DCGAN uses Transposed Convolutions, and that&rsquo;s why we need to migrate from <code>torch::nn::Conv2dOptions</code> class to <code>torch::nn::ConvTranspose2dOptions</code> (this is because using <code>.transposed(true/false)</code> does not work anymore on <code>torch::nn::Conv2dOptions</code>).</p>
<p>That is all for the changes we needed to make. To make it easy to track changes and use the code I wrote, I&rsquo;ve made the project public on <a href="https://github.com/BuffetCodes/DCGAN-CelebA-PyTorch-CPP.git">GitHub</a>. Feel free to file an issue in case you hit a bug/error.</p>
<p>Time to talk about results!</p>
<h2 id="results">Results</h2>
<p>The aim of this blog is to get DCGAN running on our celebA dataset using PyTorch C++ Frontend API. I&rsquo;m in no way aiming to produce the best possible results. I trained the DCGAN network on celebA dataset for 10 epochs. In order to visualize results, for every checkpoint (where we save our models), we pass a sample noise image (64 images here) to the generator and save the output:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// equivalent to using torch.no_grad() in Python
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">auto</span> options <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>TensorOptions().device(device).requires_grad(false);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// netG is our sequential generator network
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">// args.nz = 100 in my case
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>torch<span style="color:#f92672">::</span>Tensor samples <span style="color:#f92672">=</span> netG<span style="color:#f92672">-&gt;</span>forward(torch<span style="color:#f92672">::</span>randn({<span style="color:#ae81ff">64</span>, args.nz, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>}, options));
</span></span><span style="display:flex;"><span><span style="color:#75715e">// save the output
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>torch<span style="color:#f92672">::</span>save(samples, torch<span style="color:#f92672">::</span>str(<span style="color:#e6db74">&#34;dcgan-sample-&#34;</span>, <span style="color:#f92672">++</span>checkpoint_counter, <span style="color:#e6db74">&#34;.pt&#34;</span>));
</span></span></code></pre></div><p>Once we have the saved output, we can load the file and produce output (find the <code>display_samples.py</code> file in the <a href="https://krshrimali.github.io/posts/2019/09/deep-convolutional-generative-adversarial-networks-review-and-implementation-using-pytorch-c-api/">GitHub repo for this blog</a>). Here is how the output looks like, after 10 epochs of training:</p>
<!-- raw HTML omitted -->
<p>And how about an animation?</p>
<!-- raw HTML omitted -->
<p>Isn&rsquo;t this amazing?</p>
<p>That&rsquo;s it for this blog. See you around! :)</p>
]]></content>
        </item>
        
        <item>
            <title>Deep Convolutional Generative Adversarial Networks: Review and Implementation using PyTorch C&#43;&#43; API</title>
            <link>https://krshrimali.github.io/posts/2019/09/deep-convolutional-generative-adversarial-networks-review-and-implementation-using-pytorch-c-api/</link>
            <pubDate>Sun, 15 Sep 2019 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2019/09/deep-convolutional-generative-adversarial-networks-review-and-implementation-using-pytorch-c-api/</guid>
            <description>I&amp;rsquo;m pleased to start a series of blogs on GANs and their implementation with PyTorch C++ API. We&amp;rsquo;ll be starting with one of the initial GANs - DCGANs (Deep Convolutional Generative Adversarial Networks).
The authors (Soumith Chintala, Radford and Luke Metz) in this Seminal Paper on DCGANs introduced DCGANs to the world like this:
We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning.</description>
            <content type="html"><![CDATA[<p>I&rsquo;m pleased to start a series of blogs on GANs and their implementation with PyTorch C++ API. We&rsquo;ll be starting with one of the initial GANs - DCGANs (Deep Convolutional Generative Adversarial Networks).</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Cover-DCGAN.jpg" alt=""></p>
<p>The authors (Soumith Chintala, Radford and Luke Metz) in <a href="https://arxiv.org/pdf/1511.06434.pdf">this</a> Seminal Paper on DCGANs introduced DCGANs to the world like this:</p>
<blockquote>
<p>We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.</p>
</blockquote>
<p>Even though, the introduction to DCGANs is quite lucid, but here are some points to note:</p>
<ol>
<li>DCGANs are a class of Convolutional Neural Networks.</li>
<li>They are a strong candidate for Unsupervised Learning.</li>
<li>They are applicable as general image representations as well.</li>
</ol>
<p>Let&rsquo;s go ahead and see what exactly is DCGAN?</p>
<h2 id="introduction-to-dcgan">Introduction to DCGAN</h2>
<p>At the time when this paper was released, there was quite a focus on Supervised Learning. The paper aimed at bridging the gap between Unsupervised Learning and Supervised Learning. DCGANs are a way to understand and extract important feature representations from a dataset and generate good image representations by training.</p>
<p>Any Generative Adversarial Network has 2 major components: a Generator and a Discriminator. The tasks for both of them are simple.</p>
<ol>
<li><strong>Generator</strong>: Generates Images similar to the data distribution such that Discriminator can not distinguish it with the original data.</li>
<li><strong>Discriminator</strong>: Discriminator has a task on accurately distinguishing between the image from the generator and from the data distribution. It basically has to recognize an image as fake or real, correctly.</li>
</ol>
<p>Both Generator and Discriminator tasks can be represented beautifully with the following equation:</p>
<!-- raw HTML omitted -->
<p>The above equation, shows how the Generator and Discriminator plays min-max game.</p>
<ol>
<li>The <strong>Generator tries to minimize the loss function.</strong> It follows up with two cases:
<ol>
<li><strong>When the data is from the data distribution:</strong> Generator has a task of forcing the Discriminator to predict the data as fake.</li>
<li><strong>When data is from the Generator:</strong> Generator has a task of forcing the Discriminator to predict the data as real.</li>
</ol>
</li>
<li>The <strong>Discriminator tries to maximize the loss function.</strong> It follows up with two cases:
<ol>
<li><strong>When the data is from the data distribution:</strong> Discriminator tries to predict the data as real.</li>
<li><strong>When the data is from the Generator:</strong> Discriminator tries to predict the data as fake.</li>
</ol>
</li>
</ol>
<p>Fundamentally, the Generator is trying to fool the Discriminator and the Discriminator is trying not to get fooled with. Because of it&rsquo;s analogy, it&rsquo;s also called a police-thief game. (Police is the Discriminator and thief is the Generator).</p>
<p>We have good enough discussion on GANs, to kickstart discussion on DCGANs. Let&rsquo;s go ahead and see what changes they proposed on common CNNs:</p>
<p>Changes in the <strong>Generator</strong>:</p>
<ol>
<li>Spatial Pooling Layers such as MaxPool Layers were replaced with Fractional-Strided Convolutions (a.k.a Transposed Convolutions). This allows the network to learn it&rsquo;s own spatial downsampling, instead of explicitly mentioning the downsampling parameters by Max Pooling.</li>
<li>Use BatchNorm in the Generator.</li>
<li>Remove Fully Connected layers for deeper architectures.</li>
<li>Use ReLU activation function for all the layers except the output layer (which uses Tanh activation function).</li>
</ol>
<p>Changes in the <strong>Discriminator</strong>:</p>
<ol>
<li>Spatial Pooling Layers such as MaxPool layers were replaced with Strided Convolutions.</li>
<li>Use BatchNorm in the Discriminator.</li>
<li>Remove FC layers for deeper architectures.</li>
<li>Use LeakyReLU activation function for all the layers in the Discriminator.</li>
</ol>
<p><!-- raw HTML omitted --><!-- raw HTML omitted -->Generator of the DCGAN used for LSUN scene modeling. Source: <a href="https://arxiv.org/pdf/1511.06434.pdf">https://arxiv.org/pdf/1511.06434.pdf</a><!-- raw HTML omitted --></p>
<p>As you would note in the above architecture, there is absence of spatial pooling layers and fully connected layers.</p>
<p><!-- raw HTML omitted --><!-- raw HTML omitted -->Discriminator of the DCGAN used for LSUN scene modeling. Source: <a href="https://github.com/ChengBinJin/DCGAN-TensorFlow">https://github.com/ChengBinJin/DCGAN-TensorFlow</a><!-- raw HTML omitted --></p>
<p>Notably again, there are no pooling and fully connected layers (except the last layer).</p>
<p>Let&rsquo;s start with defining the architectures of both Generators and Discriminators using PyTorch C++ API. I used the Object Oriented approach by making class, each for Generator and Discriminator. Note that each of them are a type of CNNs, and also inherit functions (or methods) from <code>torch::nn::Module</code> class.</p>
<p>As mentioned before, Generator uses Transposed Convolutional Layers and has no pooling and FC layers. It also uses ReLU Activation Function (except the last layer). The parameters used for the Generator include:</p>
<ol>
<li><code>dataroot</code>: (type: <code>std::string</code>) Path of the dataset&rsquo;s root directory.</li>
<li><code>workers</code>: (type: <code>int</code>) Having more <code>workers</code> will increase CPU memory usage. (Check this link <a href="https://discuss.pytorch.org/t/guidelines-for-assigning-num-workers-to-dataloader/813/2">for more details</a>)</li>
<li><code>batch_size</code>: (type: <code>int</code>) Batch Size to consider.</li>
<li><code>image_size</code>: (type: <code>int</code>) Size of the image to resize it to.</li>
<li><code>nc</code>: (type: <code>int</code>) Number of channels in the Input Image.</li>
<li><code>nz</code>: (type: <code>int</code>) Length of latent vector, from which the input image is taken.</li>
<li><code>ngf</code>: (type <code>int</code>) Depth of feature maps carried through the generator.</li>
<li><code>num_epochs</code>: (type <code>int</code>) Number of epochs for which the model is trained.</li>
<li><code>lr</code>: (type <code>float</code>) Learning Rate for training. Authors described it to be 0.0002</li>
<li><code>beta1</code>: (type: <code>float</code>) Hyperparameter for Optimizer used (Adam).</li>
<li><code>ngpu</code>: (type: <code>int</code>) Number of GPUs available to use. (use <code>0</code> if no GPU available)</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Generator</span> <span style="color:#f92672">:</span> <span style="color:#66d9ef">public</span> torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Module {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">private</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>string dataroot;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> workers;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> batch_size;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> image_size;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> nc;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> nz;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> ngf;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> num_epochs;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> lr;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> beta1;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> ngpu;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential main;
</span></span><span style="display:flex;"><span>    Generator(std<span style="color:#f92672">::</span>string dataroot_ <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;data/celeba&#34;</span>, <span style="color:#66d9ef">int</span> workers_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>, <span style="color:#66d9ef">int</span> batch_size_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">128</span>, <span style="color:#66d9ef">int</span> image_size_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">64</span>, <span style="color:#66d9ef">int</span> nc_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>, <span style="color:#66d9ef">int</span> nz_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>, <span style="color:#66d9ef">int</span> ngf_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">64</span>, <span style="color:#66d9ef">int</span> ndf_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">64</span>, <span style="color:#66d9ef">int</span> num_epochs_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span>, <span style="color:#66d9ef">float</span> lr_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0002</span>, <span style="color:#66d9ef">float</span> beta1_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.5</span>, <span style="color:#66d9ef">int</span> ngpu_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>) {
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Set the arguments
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        dataroot <span style="color:#f92672">=</span> dataroot_;
</span></span><span style="display:flex;"><span>        workers <span style="color:#f92672">=</span> workers_;
</span></span><span style="display:flex;"><span>        batch_size <span style="color:#f92672">=</span> batch_size_;
</span></span><span style="display:flex;"><span>        image_size <span style="color:#f92672">=</span> image_size_;
</span></span><span style="display:flex;"><span>        nc <span style="color:#f92672">=</span> nc_;
</span></span><span style="display:flex;"><span>        nz <span style="color:#f92672">=</span> nz_;
</span></span><span style="display:flex;"><span>        ngf <span style="color:#f92672">=</span> ngf_;
</span></span><span style="display:flex;"><span>        ndf <span style="color:#f92672">=</span> ndf_;
</span></span><span style="display:flex;"><span>        num_epochs <span style="color:#f92672">=</span> num_epochs_;
</span></span><span style="display:flex;"><span>        lr <span style="color:#f92672">=</span> lr_;
</span></span><span style="display:flex;"><span>        beta1 <span style="color:#f92672">=</span> beta1_;
</span></span><span style="display:flex;"><span>        ngpu <span style="color:#f92672">=</span> ngpu_;
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        main <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential(
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(nz, ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">1</span>).padding(<span style="color:#ae81ff">0</span>).with_bias(false).transposed(true)),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>BatchNorm(ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">8</span>),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>relu),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">8</span>, ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false).transposed(true)),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>BatchNorm(ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>relu),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>, ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false).transposed(true)),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>BatchNorm(ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>relu),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ngf<span style="color:#f92672">*</span><span style="color:#ae81ff">2</span>, ngf, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false).transposed(true)),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>BatchNorm(ngf),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>relu),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ngf, nc, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false).transposed(true)),
</span></span><span style="display:flex;"><span>             torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>tanh)
</span></span><span style="display:flex;"><span>        );
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential main_func() {
</span></span><span style="display:flex;"><span>    	<span style="color:#75715e">// Returns Sequential Model of the Generator
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#66d9ef">return</span> main;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p>Note how we used Transposed Convolution, by passing <code>.transposed(true)</code>.</p>
<p>Similarly, we define the class for Discriminator.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Discriminator</span> <span style="color:#f92672">:</span> <span style="color:#66d9ef">public</span> torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Module {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">private</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>string dataroot;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> workers;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> batch_size;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> image_size;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> nc;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> nz;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> ndf;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> num_epochs;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> lr;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> beta1;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">int</span> ngpu;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential main;
</span></span><span style="display:flex;"><span>    Discriminator(std<span style="color:#f92672">::</span>string dataroot_ <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;data/celeba&#34;</span>, <span style="color:#66d9ef">int</span> workers_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>, <span style="color:#66d9ef">int</span> batch_size_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">128</span>, <span style="color:#66d9ef">int</span> image_size_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">64</span>, <span style="color:#66d9ef">int</span> nc_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">3</span>, <span style="color:#66d9ef">int</span> nz_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span>, <span style="color:#66d9ef">int</span> ngf_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">64</span>, <span style="color:#66d9ef">int</span> ndf_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">64</span>, <span style="color:#66d9ef">int</span> num_epochs_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">5</span>, <span style="color:#66d9ef">float</span> lr_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0002</span>, <span style="color:#66d9ef">float</span> beta1_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.5</span>, <span style="color:#66d9ef">int</span> ngpu_ <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span>) {
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        dataroot <span style="color:#f92672">=</span> dataroot_;
</span></span><span style="display:flex;"><span>        workers <span style="color:#f92672">=</span> workers_;
</span></span><span style="display:flex;"><span>        batch_size <span style="color:#f92672">=</span> batch_size_;
</span></span><span style="display:flex;"><span>        image_size <span style="color:#f92672">=</span> image_size_;
</span></span><span style="display:flex;"><span>        nc <span style="color:#f92672">=</span> nc_;
</span></span><span style="display:flex;"><span>        nz <span style="color:#f92672">=</span> nz_;
</span></span><span style="display:flex;"><span>        ngf <span style="color:#f92672">=</span> ngf_;
</span></span><span style="display:flex;"><span>        ndf <span style="color:#f92672">=</span> ndf_;
</span></span><span style="display:flex;"><span>        num_epochs <span style="color:#f92672">=</span> num_epochs_;
</span></span><span style="display:flex;"><span>        lr <span style="color:#f92672">=</span> lr_;
</span></span><span style="display:flex;"><span>        beta1 <span style="color:#f92672">=</span> beta1_;
</span></span><span style="display:flex;"><span>        ngpu <span style="color:#f92672">=</span> ngpu_;
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        main <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential(
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(nc, ndf, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false)),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>leaky_relu, <span style="color:#ae81ff">0.2</span>),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ndf, ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false)),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>BatchNorm(ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">2</span>),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>leaky_relu, <span style="color:#ae81ff">0.2</span>),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">2</span>, ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false)),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>BatchNorm(ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>leaky_relu, <span style="color:#ae81ff">0.2</span>),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>, ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">2</span>).padding(<span style="color:#ae81ff">1</span>).with_bias(false)),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>BatchNorm(ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">8</span>),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>leaky_relu, <span style="color:#ae81ff">0.2</span>),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(ndf<span style="color:#f92672">*</span><span style="color:#ae81ff">8</span>, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">4</span>).stride(<span style="color:#ae81ff">1</span>).padding(<span style="color:#ae81ff">0</span>).with_bias(false)),
</span></span><span style="display:flex;"><span>           torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Functional(torch<span style="color:#f92672">::</span>sigmoid)
</span></span><span style="display:flex;"><span>        );
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential main_func() {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> main;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p>We can initialize these networks as shown below:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Uses default arguments if no args passed
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>Generator gen <span style="color:#f92672">=</span> Generator()
</span></span><span style="display:flex;"><span>Discriminator dis <span style="color:#f92672">=</span> Discriminator()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential gen_model <span style="color:#f92672">=</span> gen.main_func()
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Sequential dis_model <span style="color:#f92672">=</span> dis.main_func()
</span></span></code></pre></div><p>In case you are using a GPU, you can convert the models:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>Device device <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>kCPU;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span>(torch<span style="color:#f92672">::</span>cuda<span style="color:#f92672">::</span>is_available()) {
</span></span><span style="display:flex;"><span>    device <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>kCUDA;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>gen_model<span style="color:#f92672">-&gt;</span>to(device);
</span></span><span style="display:flex;"><span>dis_model<span style="color:#f92672">-&gt;</span>to(device);
</span></span></code></pre></div><p><strong>Note on Data Loading</strong>: In the past blogs, I&rsquo;ve discussed on loading custom data. Please refer to the previous blogs for a quick review on loading data.</p>
<p>Let&rsquo;s go ahead and define optimizers and train our model. We use the parameters defined by the authors, for optimizer (Adam, <code>beta</code> = 0.5) and learning rate of <code>2e-4</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>Adam gen_optimizer(gen_model<span style="color:#f92672">-&gt;</span>parameters(), torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>AdamOptions(<span style="color:#ae81ff">2e-4</span>).beta1(<span style="color:#ae81ff">0.5</span>));
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>Adam dis_optimizer(dis_model<span style="color:#f92672">-&gt;</span>parameters(), torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>AdamOptions(<span style="color:#ae81ff">2e-4</span>).beta1(<span style="color:#ae81ff">0.5</span>));
</span></span></code></pre></div><p>Time to write our training code. We are using <code>CelebA</code> dataset which looks like this:</p>
<!-- raw HTML omitted -->
<p>The dataset is huge, and contains 10,177 number of identities and around ~200k number of face images. It also contains annotations, but since GANs are a way of unsupervised learning, so they don&rsquo;t actually consider annotations. Before we move on, we&rsquo;ll see a quick step by step review on training the Discriminator and Generator simultaneously:</p>
<ol>
<li><strong>Step-1: Train Discriminator</strong>. Remember from above, the discriminator tries to maximize the loss function such that it predicts the fake images as fake and real images as real.
<ol>
<li>As the first step for every training process, we set the gradients to zero. This helps in calculating correct gradients, and not getting confused with gradients stored in the previous iteration.</li>
<li>First calculate <strong>discriminator loss on real images</strong> (that is, data from our dataset). We do this by getting data from the batch and labels as anything between 0.8 and 1.0 (since it&rsquo;s real, we approximate it from 0.8 to 1.0).</li>
<li>Do a forward pass to the discriminator network, and calculate output on the batch of data from our dataset.</li>
<li>Calculate loss by using <code>torch::binary_cross_entropy</code> and backpropagate the loss.</li>
<li>We now calculate <strong>discriminator loss on fake images</strong> (that is, data from the generator). For this, we take a noise of shape similar to the batch of data, and pass that noise to the generator.</li>
<li>The labels are given zero values (as the images are fake).</li>
<li>Again, calculate the loss by using <code>torch::binary_cross_entropy</code> and backpropagate the loss.</li>
<li>Sum both the losses, <strong>discriminator loss on real images</strong> + <strong>discriminator loss on fake images</strong>. This will be our discriminator loss.</li>
<li>We then update our parameters using the optimizer.</li>
</ol>
</li>
<li><strong>Step-2: Train Generator</strong>. The task of a Generator is to minimize the loss function. Since it has to produce images which can fool the discriminator, so it only has to consider fake images.
<ol>
<li>As the first step for every training process, we set the gradients to zero. This helps in calculating correct gradients, and not getting confused with gradients stored in the previous iteration.</li>
<li>We use the fake images produced in the Step-1 and pass it to the discriminator.</li>
<li>Fill the labels with 1. (since generator wants to fool the discriminator, by making it predict as real images).</li>
<li>Calculate loss, by using <code>torch::binary_cross_entropy</code> and backpropagate the loss.</li>
<li>Update the parameters using optimizer of the Generator.</li>
</ol>
</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">int</span> epoch<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; epoch<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">10</span>; epoch<span style="color:#f92672">++</span>) {
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Store batch count in a variable
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">int</span> batch_count <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// You can use torch::data::Example&lt;&gt;&amp; batch: *data_loader
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">auto</span><span style="color:#f92672">&amp;</span> batch: <span style="color:#f92672">*</span>data_loader) {
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Step-1: Train the Discriminator
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#75715e">// Set gradients to zero
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        netD<span style="color:#f92672">-&gt;</span>zero_grad();
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Calculating discriminator loss on real images
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor images_real <span style="color:#f92672">=</span> batch.data.to(device);
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">::</span>Tensor labels_real <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>empty(batch.data.size(<span style="color:#ae81ff">0</span>), device).uniform_(<span style="color:#ae81ff">0.8</span>, <span style="color:#ae81ff">1.0</span>));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Do a forward pass to the Discriminator network
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor output_D_real <span style="color:#f92672">=</span> netD<span style="color:#f92672">-&gt;</span>forward(images_real);
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Calculate the loss
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor loss_real_D <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>binary_cross_entropy(output_D_real, labels_real);
</span></span><span style="display:flex;"><span>        loss_real_D.backward();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Calculate discriminator loss on fake images
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#75715e">// Generate noise and do forward pass to generate fake images
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch:Tensor fake_random <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>randn({batch.data.size(<span style="color:#ae81ff">0</span>), args.nz, <span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>}, device);
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">::</span>Tensor images_fake <span style="color:#f92672">=</span> netG<span style="color:#f92672">-&gt;</span>forward(images_fake);
</span></span><span style="display:flex;"><span>        torch<span style="color:#f92672">::</span>Tensor labels_fake <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>zeros(batch.data.size(<span style="color:#ae81ff">0</span>), device);
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Do a forward pass to the Discriminator network
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor output_D_fake <span style="color:#f92672">=</span> netD<span style="color:#f92672">-&gt;</span>forward(images_fake);
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Calculate the loss
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor loss_fake_D <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>binary_cross_entropy(output_D_fake, labels_fake);
</span></span><span style="display:flex;"><span>        loss_fake_D.backward();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Total discriminator loss
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor loss_discriminator <span style="color:#f92672">=</span> loss_real_D <span style="color:#f92672">+</span> loss_fake_D;
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Update the parameters
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        dis_optimizer.step();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Step-2: Train the Generator
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#75715e">// Set gradients to zero
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        netG<span style="color:#f92672">-&gt;</span>zero_grad();
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// calculating generator loss on fake images
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#75715e">// Change labels_fake from all zeros to all ones
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        labels_fake.fill_(<span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Do forward pass to the Discriminator on the fake images generated above
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor output_G_fake <span style="color:#f92672">=</span> netD<span style="color:#f92672">-&gt;</span>forward(images_fake);
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Calculate loss
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        torch<span style="color:#f92672">::</span>Tensor loss_generator <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>binary_cross_entropy(output_G_fake, labels_fake);
</span></span><span style="display:flex;"><span>        loss_generator.backward();
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Update the parameters
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        gen_optimizer.step();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Epoch: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> epoch <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;, Batch: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> batch_count <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;, Gen Loss: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> loss_generator.item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>() <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;, Discriminator Loss: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> loss_discriminator.item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>() <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>	
</span></span><span style="display:flex;"><span>        batch_count<span style="color:#f92672">++</span>;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>We are all set to train our first DCGAN in C++ using Libtorch. How amazing it is?</p>
<p>In the coming blog, I&rsquo;ll share the results and answer a few common questions on the architecture of DCGAN.</p>
<h2 id="acknowledgement-and-references">Acknowledgement and References</h2>
<p>I would like to thank <a href="https://github.com/yf225">Will Feng</a> and <a href="https://discuss.pytorch.org/u/ptrblck/summary">Piotr</a> for their useful suggestions. The code used in this blog, is partially analogous to the official <a href="https://github.com/pytorch/examples/tree/master/cpp/dcgan">PyTorch examples repo on DCGAN using LibTorch</a>. I&rsquo;ve also referred the original paper by <a href="https://twitter.com/soumithchintala">Soumith Chintala</a> and others. The sources of reference images (for Network architectures) have been acknowledged in the captions of respective images.</p>
]]></content>
        </item>
        
        <item>
            <title>Setting up Jupyter Notebook (Xeus Cling) for Libtorch and OpenCV Libraries</title>
            <link>https://krshrimali.github.io/posts/2019/08/setting-up-jupyter-notebook-xeus-cling-for-libtorch-and-opencv-libraries/</link>
            <pubDate>Wed, 28 Aug 2019 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2019/08/setting-up-jupyter-notebook-xeus-cling-for-libtorch-and-opencv-libraries/</guid>
            <description>Introduction to Xeus Cling Today, we are going to run our C++ codes in the Jupyter Notebook. Sounds ambitious? Not much. Let&amp;rsquo;s see how we do it using Xeus Cling.
I&amp;rsquo;ll quote the definition of Xeus Cling on the official documentation website.
xeus-cling is a Jupyter kernel for C++ based on the C++ interpreter cling and the native implementation of the Jupyter protocol xeus.
Just like we use Python Kernel in the Jupyter Notebook, we can also use a C++ based interpreter cling combined with a Jupyter protocol called Xeus to reach closer to implementing C++ code in the notebook.</description>
            <content type="html"><![CDATA[<h2 id="introduction-to-xeus-cling">Introduction to Xeus Cling</h2>
<p>Today, we are going to run our C++ codes in the Jupyter Notebook. Sounds ambitious? Not much. Let&rsquo;s see how we do it using Xeus Cling.</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Cover-Xeus-Cling.jpg" alt=""></p>
<p>I&rsquo;ll quote the definition of Xeus Cling on the official <a href="https://xeus-cling.readthedocs.io/en/latest/#targetText=xeus%2Dcling%20is%20a%20Jupyter,of%20the%20Jupyter%20protocol%20xeus">documentation website</a>.</p>
<blockquote>
<p>xeus-cling is a Jupyter kernel for C++ based on the C++ interpreter cling and the native implementation of the Jupyter protocol xeus.</p>
</blockquote>
<p>Just like we use Python Kernel in the Jupyter Notebook, we can also use a C++ based interpreter cling combined with a Jupyter protocol called Xeus to reach closer to implementing C++ code in the notebook.</p>
<h2 id="installing-xeus-cling-using-anaconda">Installing Xeus Cling using Anaconda</h2>
<p>It&rsquo;s pretty straight forward to install Xeus Cling using Anaconda. I&rsquo;m assuming the user has Anaconda installed.  Use this command to install <code>Xeus Cling</code> using Anaconda: <code>conda install -c conda-forge xeus-cling</code>.</p>
<p><strong>Note</strong>: Before using <code>conda</code> commands, you need to have it in your <code>PATH</code> variable. Use this command to add the path to <code>conda</code> to your system <code>PATH</code> variable: <code>export PATH=~/anaconda3/bin/:$PATH</code>.</p>
<p>The conventional way to install any such library which can create conflicts with existing libraries, is to create an environment and then install it in the environment.</p>
<ol>
<li>Create a <code>conda</code> environment: <code>conda create -n cpp-xeus-cling</code>.</li>
<li>Activate the environment you just created: <code>source activate cpp-xeus-cling</code>.</li>
<li>Install <code>xeus-cling</code> using <code>conda</code>: <code>conda install -c conda-forge xeus-cling</code>.</li>
</ol>
<p>Once setup, let&rsquo;s go ahead and get started with Jupyter Notebook. When creating a new notebook, you will see different options for the kernel. One of them would be <code>C++XX</code> where XX is the <code>C++</code> version.</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/kernels-available.png" alt=""></p>
<p>Click on any of the kernel for C++ and let&rsquo;s start setting up environment for PyTorch C++ API.</p>
<p>You can try and implement some of the basic commands in C++.</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Jupyter-Notebook-Sample.png" alt=""></p>
<p>This looks great, right? Let&rsquo;s go ahead and set up the Deep Learning environment.</p>
<h2 id="setting-up-libtorch-in-xeus-cling">Setting up Libtorch in Xeus Cling</h2>
<p>Just like we need to give path to <code>Libtorch</code> libraries in <code>CMakeLists.txt</code> or while setting up <code>XCode</code> (for OS X users) or <code>Visual Studio</code> (for Windows Users), we will also load the libraries in Xeus Cling.</p>
<p>We will first give the <code>include_path</code> of Header files and <code>library_path</code> for the libraries. We will also do the same for <code>OpenCV</code> as we need it to load images.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">#pragma cling add_library_path(&#34;/Users/krshrimali/Downloads/libtorch/lib/&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling add_include_path(&#34;/Users/krshrimali/Downloads/libtorch/include&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling add_include_path(&#34;/Users/krshrimali/Downloads/libtorch/include/torch/csrc/api/include/&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling add_library_path(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling add_include_path(&#34;/usr/local/Cellar/opencv/4.1.0_2/include/opencv4&#34;)
</span></span></span></code></pre></div><p>For OS X, the libtorch libraries will be in the format of <code>.dylib</code>. Ignore the <code>.a</code> files as we only need to load the <code>.dylib</code> files. Similarly for Linux, load the libraries in <code>.so</code> format located in the <code>lib/</code> folder.</p>
<p><strong>For Mac</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/Users/krshrimali/Downloads/libtorch/lib/libiomp5.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/Users/krshrimali/Downloads/libtorch/lib/libmklml.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/Users/krshrimali/Downloads/libtorch/lib/libc10.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/Users/krshrimali/Downloads/libtorch/lib/libtorch.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/Users/krshrimali/Downloads/libtorch/lib/libshm.dylib&#34;)
</span></span></span></code></pre></div><p><strong>For Linux</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/opt/libtorch/lib/libc10.so&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/opt/libtorch/lib/libgomp-4f651535.so.1&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/opt/libtorch/lib/libtorch.so&#34;)
</span></span></span></code></pre></div><p>For OpenCV, the list of libraries is long.</p>
<p><strong>For Mac</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_datasets.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_aruco.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_bgsegm.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_bioinspired.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_calib3d.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_ccalib.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_core.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_dnn_objdetect.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_dnn.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_dpm.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_face.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_features2d.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_flann.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_freetype.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_fuzzy.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_gapi.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_hfs.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_highgui.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_img_hash.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_imgcodecs.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_imgproc.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_line_descriptor.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_ml.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_objdetect.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_optflow.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_phase_unwrapping.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_photo.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_plot.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_quality.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_reg.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_rgbd.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_saliency.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_sfm.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_shape.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_stereo.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_stitching.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_structured_light.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_superres.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_surface_matching.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_text.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_tracking.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_video.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_videoio.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_videostab.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_xfeatures2d.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_ximgproc.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_xobjdetect.4.1.0.dylib&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/Cellar/opencv/4.1.0_2/lib/libopencv_xphoto.4.1.0.dylib&#34;)
</span></span></span></code></pre></div><p><strong>For Linux</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_aruco.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_bgsegm.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_bioinspired.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_calib3d.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_ccalib.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_core.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_datasets.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_dnn_objdetect.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_dnn.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_dpm.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_face.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_features2d.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_flann.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_freetype.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_fuzzy.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_gapi.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_hdf.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_hfs.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_highgui.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_imgcodecs.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_img_hash.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_imgproc.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_line_descriptor.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_ml.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_objdetect.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_optflow.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_phase_unwrapping.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_photo.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_plot.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_reg.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_rgbd.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_saliency.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_sfm.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_shape.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_stereo.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_stitching.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_structured_light.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_superres.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_surface_matching.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_text.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_tracking.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_videoio.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_video.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_videostab.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_xfeatures2d.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_ximgproc.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_xobjdetect.so.4.1.0&#34;)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#pragma cling load(&#34;/usr/local/lib/libopencv_xphoto.so.4.1.0&#34;)
</span></span></span></code></pre></div><p>Once done, run the cell and that&rsquo;s it. We have successfully setup the environment for <code>Libtorch</code> and <code>OpenCV</code>.</p>
<h2 id="testing-xeus-cling-notebook">Testing Xeus Cling Notebook</h2>
<p>Let&rsquo;s go ahead and include the libraries. I&rsquo;ll be sharing the code snippets as well as the screenshots to make it easy for the readers to reproduce results.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;torch/torch.h&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;torch/script.h&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;iostream&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;dirent.h&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;opencv2/opencv.hpp&gt;</span><span style="color:#75715e">
</span></span></span></code></pre></div><p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Include-Libraries.png" alt=""></p>
<p>After successfully importing libraries, we can define functions, write code and use the utilities Jupyter provides. Let&rsquo;s start with playing with Tensors and the code snippets mentioned in the official <a href="https://pytorch.org/cppdocs">PyTorch C++ Frontend Docs</a>.</p>
<p>Starting with using <code>ATen</code> tensor library. We&rsquo;ll create two tensors and add them together. <code>ATen</code> comes up with functionalities of mathematical operations on the Tensors.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;ATen/ATen.h&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span>at<span style="color:#f92672">::</span>Tensor a <span style="color:#f92672">=</span> at<span style="color:#f92672">::</span>ones({<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>}, at<span style="color:#f92672">::</span>kInt);
</span></span><span style="display:flex;"><span>at<span style="color:#f92672">::</span>Tensor b <span style="color:#f92672">=</span> at<span style="color:#f92672">::</span>randn({<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>});
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> c <span style="color:#f92672">=</span> a <span style="color:#f92672">+</span> b.to(at<span style="color:#f92672">::</span>kInt);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;a: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> a <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;b: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> b <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;c: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> c <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span></code></pre></div><p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/ATen-Example.png" alt=""></p>
<p>One of the reasons why <code>Xeus-Cling</code> is useful is, that you can print the outputs of intermediate steps and debug. Let&rsquo;s go ahead and experiment with <code>Autograd</code> system of PyTorch C++ API.</p>
<p>For those who don&rsquo;t know, automatic differentiation is the most important function of Deep Learning algorithms to backpropagte the loss we calculate.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;torch/csrc/autograd/variable.h&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;torch/csrc/autograd/function.h&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>Tensor a_tensor <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>ones({<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>}, torch<span style="color:#f92672">::</span>requires_grad());
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>Tensor b_tensor <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>randn({<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">2</span>});
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> a_tensor <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> b_tensor <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> c_tensor <span style="color:#f92672">=</span> a_tensor <span style="color:#f92672">+</span> b_tensor;
</span></span><span style="display:flex;"><span>c_tensor.backward(); <span style="color:#75715e">// a.grad() will now hold the gradient of c w.r.t a
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span>std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> c_tensor <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span></code></pre></div><p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Autograd-Example-1.png" alt="">
<img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Autograd-Example-2.png" alt=""></p>
<p>How about debugging? As you can see in the figure below, I get an error stating <code>no member named 'size' in namespace 'cv'</code>. This is because namespace <code>cv</code> has member called <code>Size</code> and not <code>size</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>Tensor read_images(std<span style="color:#f92672">::</span>string location) {
</span></span><span style="display:flex;"><span>	cv<span style="color:#f92672">::</span>Mat img <span style="color:#f92672">=</span> cv<span style="color:#f92672">::</span>imread(location, <span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>	cv<span style="color:#f92672">::</span>resize(img, img, cv<span style="color:#f92672">::</span>size(<span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">224</span>), cv<span style="color:#f92672">::</span>INTER_CUBIC);
</span></span><span style="display:flex;"><span>	torch<span style="color:#f92672">::</span>Tensor img_tensor <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>from_blob(img.data, {img.rows, img.cols, <span style="color:#ae81ff">3</span>}, torch<span style="color:#f92672">::</span>kByte);
</span></span><span style="display:flex;"><span>	img_tensor <span style="color:#f92672">=</span> img_tensor.permute({<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>});
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> img_tensor.clone();
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Debug-Example.png" alt=""></p>
<p>To solve, we can simply change the member from <code>size</code> to <code>Size</code>. One important point to consider is, that since this works on the top of Jupyter Interface, so whenever you re-run a cell, the variable names need to be changed as it will return an error of re-defining the variables which have already been defined.</p>
<p>For testing, I have implemented Transfer Learning example that we discussed in the <a href="https://krshrimali.github.io/posts/2019/08/applying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api/">previous blog</a>. This comes handy as I don&rsquo;t need to load the dataset again and again.</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Training-Image.png" alt=""></p>
<h2 id="bonus">Bonus!</h2>
<p>With this blog, I&rsquo;m also happy to share a Notebook file with implementation of Transfer Learning using ResNet18 Model on Dogs vs Cats Dataset. Additionally, I&rsquo;m elated to open source the code for Transfer Learning using ResNet18 Model using PyTorch C++ API.</p>
<p>The source code and the notebook file can be found <a href="https://github.com/krshrimali/Transfer-Learning-Dogs-Cats-Libtorch.git">here</a>.</p>
<h2 id="debugging---osx-systems">Debugging - OSX Systems</h2>
<p>In case of OSX Systems, if you see any errors similar to: <code>You are probably missing the definition of &lt;function_name&gt;</code>, then try any (or all) of the following points:</p>
<ol>
<li>Use <code>Xeus-Cling</code> on a virtual environment as this might be because of conflicts with the existing libraries.</li>
<li>Although, OSX Systems shouldn&rsquo;t have <code>C++ ABI Compatability</code> Issues but you can still try this if problem persists.
<ol>
<li>Go to <code>TorchCONFIG.cmake</code> file (it should be present in <code>&lt;torch_folder&gt;/share/cmake/Torch/</code>).</li>
<li>Change <code>set(TORCH_CXX_FLAGS &quot;-D_GLIBCXX_USE_CXX11_ABI=&quot;)</code> to <code>set(TORCH_CXX_FLAGS &quot;-D_GLIBCXX_USE_CXX11_ABI=1&quot;)</code> and reload the libraries and header files.</li>
</ol>
</li>
</ol>
<h2 id="references">References</h2>
<ol>
<li><a href="https://www.learnopencv.com/xeus-cling-run-c-code-in-jupyter-notebook/">Xeus-Cling: Run C++ code in Jupyter Notebook by Vishwesh Ravi Shrimali</a>.</li>
<li><a href="https://xeus-cling.readthedocs.io/en/latest">Documentation of Xeus-Cling</a>.</li>
</ol>
]]></content>
        </item>
        
        <item>
            <title>Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C&#43;&#43; API</title>
            <link>https://krshrimali.github.io/posts/2019/08/applying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api/</link>
            <pubDate>Fri, 16 Aug 2019 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2019/08/applying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api/</guid>
            <description>Transfer Learning &amp;ndash; Before we go ahead and discuss the Why question of Transfer Learning, let&amp;rsquo;s have a look at What is Transfer Learning? Let&amp;rsquo;s have a look at the Notes from CS231n on Transfer Learning:
In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.</description>
            <content type="html"><![CDATA[<h2 id="transfer-learning">Transfer Learning</h2>
<p>&ndash;
Before we go ahead and discuss the <strong>Why</strong> question of Transfer Learning, let&rsquo;s have a look at <strong>What is Transfer Learning?</strong> Let&rsquo;s have a look at the <a href="http://cs231n.github.io/transfer-learning">Notes</a> from CS231n on Transfer Learning:</p>
<blockquote>
<p>In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest.</p>
</blockquote>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Cover-Transfer-Learning.jpg" alt=""></p>
<p>There are 3 scenarios possible:</p>
<ol>
<li>When the data you have is similar (but not enough) to data trained on pre-trained model: Take an example of a pre-trained model trained on ImageNet dataset (containing 1000 classes). And the data we have has Dogs and Cats classes. Fortunate enough, ImageNet has some of the classes of Dog and Cat breeds and thus the model must have learned important features from the data. Let&rsquo;s say we don&rsquo;t have enough data but since the data is similar to the breeds in the ImageNet data set, we can simply use the ConvNet (except the last FC layer) to extract features from our dataset and train only the last Linear (FC) layer.</li>
<li>When you have enough data (and is similar to the data trained with pre-trained model): Then you might go for fine tuning the weights of all the layers in the network. This is largely due to the reason that we know we won&rsquo;t overfit because we have enough data.</li>
<li>Using pre-trained models might just be enough if you have the data which matches the classes in the original data set.</li>
</ol>
<p>Transfer Learning came into existence (the answer of <strong>Why Transfer Learning?</strong>) because of some major reasons, which include:</p>
<ol>
<li>Lack of resources or data set to train a CNN. At times, we either don&rsquo;t have enough data or we don&rsquo;t have enough resources to train a CNN from scratch.</li>
<li>Random Initialization of weights vs Initialization of weights from the pre-trained model. Sometimes, it&rsquo;s just better to initialize weights from the pre-trained model (as it must have learned the generic features from it&rsquo;s data set) instead of randomly initializing the weights.</li>
</ol>
<h2 id="setting-up-the-data-with-pytorch-c-api">Setting up the data with PyTorch C++ API</h2>
<p>At every stage, we will compare the Python and C++ codes to do the same thing, to make the analogy easier and understandable. Starting with setting up the data we have. Note that we do have enough data and it is also similar to the original data set of ImageNet, but since I don&rsquo;t have enough resources to fine tune through the whole network, we perform Transfer Learning on the final FC layer only.</p>
<p>Starting with loading the dataset, as discussed in the blogs before, I&rsquo;ll just post a flow chart of procedure.</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Steps-Loading-Data-PyTorch.png" alt=""></p>
<p>Once done, we can initialize the <code>CustomDataset</code> class:</p>
<p><strong>C++</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// List of images of Dogs and Cats, use load_data_from_folder function explained in previous blogs
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span>std<span style="color:#f92672">::</span>string<span style="color:#f92672">&gt;</span> list_images; 
</span></span><span style="display:flex;"><span><span style="color:#75715e">// List of labels of the images
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> list_labels; 
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> custom_dataset <span style="color:#f92672">=</span> CustomDataset(list_images, list_labels).map(torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>transforms<span style="color:#f92672">::</span>Stack<span style="color:#f92672">&lt;&gt;</span>());
</span></span></code></pre></div><p><strong>Python</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> torchvision <span style="color:#f92672">import</span> datasets, transforms
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> torch
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>folder_path <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;/Users/krshrimali/Documents/dataset/train/&#34;</span>
</span></span><span style="display:flex;"><span>transform <span style="color:#f92672">=</span> transforms<span style="color:#f92672">.</span>Compose([transforms<span style="color:#f92672">.</span>CenterCrop(<span style="color:#ae81ff">224</span>), transforms<span style="color:#f92672">.</span>ToTensor())
</span></span><span style="display:flex;"><span>data <span style="color:#f92672">=</span> datasets<span style="color:#f92672">.</span>ImageFolder(root <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>path<span style="color:#f92672">.</span>join(folder_path), transform <span style="color:#f92672">=</span> transform)
</span></span></code></pre></div><p>We then use <code>RandomSampler</code> to make our data loader: (Note: it&rsquo;s important to use <code>RandomSampler</code> as we load the images sequentially and we want mixture of images in each batch of data passed to the network in an epoch)</p>
<p><strong>C++</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">int</span> batch_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">4</span>;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> data_loader <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>make_data_loader<span style="color:#f92672">&lt;</span>torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>samplers<span style="color:#f92672">::</span>RandomSampler<span style="color:#f92672">&gt;</span>(std<span style="color:#f92672">::</span>move(custom_dataset), batch_size);
</span></span></code></pre></div><p><strong>Python</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>batch_size <span style="color:#f92672">=</span> <span style="color:#ae81ff">4</span>
</span></span><span style="display:flex;"><span>data_loader <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>DataLoader(dataset<span style="color:#f92672">=</span>data, batch_size <span style="color:#f92672">=</span> batch_size, shuffle <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>)
</span></span></code></pre></div><h2 id="loading-the-pre-trained-model">Loading the pre-trained model</h2>
<p>The steps to load the pre-trained model and perform Transfer Learning are listed below:</p>
<ol>
<li>Download the pre-trained model of <strong>ResNet18</strong>.</li>
<li>Load pre-trained model.</li>
<li>Change output features of the final FC layer of the model loaded. (Number of classes would change from 1000 - ImageNet to 2 - Dogs vs Cats).</li>
<li>Define optimizer on parameters from the final FC layer to be trained.</li>
<li>Train the FC layer on Dogs vs Cats dataset.</li>
<li>Save the model.</li>
</ol>
<p>Let&rsquo;s go step by step.</p>
<h3 id="step-1-download-the-pre-trained-model-of-resnet18">Step-1: Download the pre-trained model of ResNet18</h3>
<p>Thanks to the developers, we do have C++ models available in torchvision
(<a href="https://github.com/pytorch/vision/pull/728">https://github.com/pytorch/vision/pull/728</a>) but for this tutorial, transferring the pre- trained model from Python to C++ using torch.jit is a good idea, as most PyTorch models in the wild are written in Python right now, and people can use this tutorial to learn how to trace their Python model and transfer it to C++.</p>
<p>First we download the pre-trained model and save it in the form of <code>torch.jit.trace</code> format to our local drive.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Reference: #TODO- Add Link</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> torchvision <span style="color:#f92672">import</span> models
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Download and load the pre-trained model</span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> models<span style="color:#f92672">.</span>resnet18(pretrained<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Set upgrading the gradients to False</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> param <span style="color:#f92672">in</span> model<span style="color:#f92672">.</span>parameters():
</span></span><span style="display:flex;"><span>	param<span style="color:#f92672">.</span>requires_grad <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Save the model except the final FC Layer</span>
</span></span><span style="display:flex;"><span>resnet18 <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Sequential(<span style="color:#f92672">*</span>list(resnet18<span style="color:#f92672">.</span>children())[:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>example_input <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>rand(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">224</span>, <span style="color:#ae81ff">224</span>)
</span></span><span style="display:flex;"><span>script_module <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>jit<span style="color:#f92672">.</span>trace(resnet18, example_input)
</span></span><span style="display:flex;"><span>script_module<span style="color:#f92672">.</span>save(<span style="color:#e6db74">&#39;resnet18_without_last_layer.pt&#39;</span>)
</span></span></code></pre></div><p>We will be using <code>resnet18_without_last_layer.pt</code> model file as our pre-trained model for transfer learning.</p>
<h3 id="step-2-load-the-pre-trained-model">Step-2: Load the pre-trained model</h3>
<p>Let&rsquo;s go ahead and load the pre-trained model using <code>torch::jit</code> module. Note that the reason we have converted <code>torch.nn.Module</code> to <code>torch.jit.ScriptModule</code> type, is because C++ API currently does not support loading Python <code>torch.nn.Module</code> models directly.</p>
<p><strong>C++</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>jit<span style="color:#f92672">::</span>script<span style="color:#f92672">::</span>Module module;
</span></span><span style="display:flex;"><span><span style="color:#75715e">// argv[1] should be the path to the model
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>module <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>jit<span style="color:#f92672">::</span>load(argv[<span style="color:#ae81ff">1</span>]); 
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">/* We need to convert last layer input and output features from (512, 1000) to (512, 2) since we only have 2 classes */</span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear linear_layer(<span style="color:#ae81ff">512</span>, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Define the optimizer on parameters of linear_layer with learning_rate = 1e-3
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>Adam optimizer(linear_layer<span style="color:#f92672">-&gt;</span>parameters(), torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>AdamOptions(<span style="color:#ae81ff">1e-3</span>))
</span></span></code></pre></div><p><strong>Python</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># We will directly load the torch.nn pre-trained model</span>
</span></span><span style="display:flex;"><span>model <span style="color:#f92672">=</span> models<span style="color:#f92672">.</span>resnet18(pretrained <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> param <span style="color:#f92672">in</span> model<span style="color:#f92672">.</span>parameters():
</span></span><span style="display:flex;"><span>    param<span style="color:#f92672">.</span>requires_grad <span style="color:#f92672">=</span> <span style="color:#66d9ef">False</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>model<span style="color:#f92672">.</span>fc <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>Linear(<span style="color:#ae81ff">512</span>, <span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> param <span style="color:#f92672">in</span> model<span style="color:#f92672">.</span>fc<span style="color:#f92672">.</span>parameters():
</span></span><span style="display:flex;"><span>	param<span style="color:#f92672">.</span>requires_grad <span style="color:#f92672">=</span> <span style="color:#66d9ef">True</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>optimizer <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>optim<span style="color:#f92672">.</span>Adam(model<span style="color:#f92672">.</span>fc<span style="color:#f92672">.</span>parameters())
</span></span><span style="display:flex;"><span>cost <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>nn<span style="color:#f92672">.</span>CrossEntropyLoss()
</span></span></code></pre></div><h2 id="trainining-the-fc-layer">Trainining the FC Layer</h2>
<p>Let&rsquo;s first have a look at ResNet18 Network Architecture</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/ResNet18-Architecture.png" alt="https://www.researchgate.net/figure/ResNet-18-Architecture_tbl1_322476121"></p>
<p>The final step is to train the Fully Connected layer that we inserted at the end of the network (<code>linear_layer</code>). This one should be pretty straight forward, let&rsquo;s see how to do it.</p>
<p><strong>C++</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">train</span>(torch<span style="color:#f92672">::</span>jit<span style="color:#f92672">::</span>script<span style="color:#f92672">::</span>Module net, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear lin, Dataloader<span style="color:#f92672">&amp;</span> data_loader, torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>Optimizer<span style="color:#f92672">&amp;</span> optimizer, size_t dataset_size) {
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">/*
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     This function trains the network on our data loader using optimizer for given number of epochs.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     Parameters
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     ==================
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     torch::jit::script::Module net: Pre-trained model
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     torch::nn::Linear lin: Linear layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     DataLoader&amp; data_loader: Training data loader
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     torch::optim::Optimizer&amp; optimizer: Optimizer like Adam, SGD etc.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     size_t dataset_size: Size of training dataset
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">     */</span>
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> batch_index <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">int</span> i<span style="color:#f92672">=</span><span style="color:#ae81ff">0</span>; i<span style="color:#f92672">&lt;</span><span style="color:#ae81ff">15</span>; i<span style="color:#f92672">++</span>) {
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">float</span> mse <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">float</span> Acc <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>;
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">auto</span><span style="color:#f92672">&amp;</span> batch: <span style="color:#f92672">*</span>data_loader) {
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">auto</span> data <span style="color:#f92672">=</span> batch.data;
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">auto</span> target <span style="color:#f92672">=</span> batch.target.squeeze();
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#75715e">// Should be of length: batch_size
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>            data <span style="color:#f92672">=</span> data.to(torch<span style="color:#f92672">::</span>kF32);
</span></span><span style="display:flex;"><span>            target <span style="color:#f92672">=</span> target.to(torch<span style="color:#f92672">::</span>kInt64);
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span>torch<span style="color:#f92672">::</span>jit<span style="color:#f92672">::</span>IValue<span style="color:#f92672">&gt;</span> input;
</span></span><span style="display:flex;"><span>            input.push_back(data);
</span></span><span style="display:flex;"><span>            optimizer.zero_grad();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">auto</span> output <span style="color:#f92672">=</span> net.forward(input).toTensor();
</span></span><span style="display:flex;"><span>            <span style="color:#75715e">// For transfer learning
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>            output <span style="color:#f92672">=</span> output.view({output.size(<span style="color:#ae81ff">0</span>), <span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>});
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            output <span style="color:#f92672">=</span> lin(output);
</span></span><span style="display:flex;"><span>            <span style="color:#75715e">// Explicitly calculate torch::log_softmax of output from the FC Layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>            <span style="color:#66d9ef">auto</span> loss <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>nll_loss(torch<span style="color:#f92672">::</span>log_softmax(output, <span style="color:#ae81ff">1</span>), target);
</span></span><span style="display:flex;"><span>           	
</span></span><span style="display:flex;"><span>            loss.backward();
</span></span><span style="display:flex;"><span>            optimizer.step();
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            <span style="color:#66d9ef">auto</span> acc <span style="color:#f92672">=</span> output.argmax(<span style="color:#ae81ff">1</span>).eq(target).sum();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>            Acc <span style="color:#f92672">+=</span> acc.<span style="color:#66d9ef">template</span> item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>();
</span></span><span style="display:flex;"><span>            mse <span style="color:#f92672">+=</span> loss.<span style="color:#66d9ef">template</span> item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>();
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>            batch_index <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>;
</span></span><span style="display:flex;"><span>        }
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        mse <span style="color:#f92672">=</span> mse<span style="color:#f92672">/</span><span style="color:#66d9ef">float</span>(batch_index); <span style="color:#75715e">// Take mean of loss
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Epoch: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> i  <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;, &#34;</span> <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Accuracy: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> Acc<span style="color:#f92672">/</span>dataset_size <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;, &#34;</span> <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;MSE: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> mse <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>        net.save(<span style="color:#e6db74">&#34;model.pt&#34;</span>);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p><strong>Python</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>n_epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">15</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> epoch <span style="color:#f92672">in</span> range(n_epochs):
</span></span><span style="display:flex;"><span>    mse <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>
</span></span><span style="display:flex;"><span>    acc <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    batch_index <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> data_batch <span style="color:#f92672">in</span> data_loader:
</span></span><span style="display:flex;"><span>        batch_index <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        image, label <span style="color:#f92672">=</span> data_batch
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        optimizer<span style="color:#f92672">.</span>zero_grad()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        output <span style="color:#f92672">=</span> model(image)
</span></span><span style="display:flex;"><span>        _, predicted_label <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>max(output<span style="color:#f92672">.</span>data, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        loss <span style="color:#f92672">=</span> cost(output, label)
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        loss<span style="color:#f92672">.</span>backward()
</span></span><span style="display:flex;"><span>        optimizer<span style="color:#f92672">.</span>step()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        mse <span style="color:#f92672">+=</span> loss<span style="color:#f92672">.</span>item() <span style="color:#75715e"># data[0]</span>
</span></span><span style="display:flex;"><span>        acc <span style="color:#f92672">+=</span> torch<span style="color:#f92672">.</span>sum(predicted_label <span style="color:#f92672">==</span> label<span style="color:#f92672">.</span>data)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    mse <span style="color:#f92672">=</span> mse<span style="color:#f92672">/</span>len(data)
</span></span><span style="display:flex;"><span>    acc <span style="color:#f92672">=</span> <span style="color:#ae81ff">100</span><span style="color:#f92672">*</span>acc<span style="color:#f92672">/</span>len(data)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">&#34;Epoch: </span><span style="color:#e6db74">{}</span><span style="color:#e6db74">/</span><span style="color:#e6db74">{}</span><span style="color:#e6db74">, Loss: </span><span style="color:#e6db74">{:.4f}</span><span style="color:#e6db74">, Accuracy: </span><span style="color:#e6db74">{:.4f}</span><span style="color:#e6db74">&#34;</span><span style="color:#f92672">.</span>format(epoch<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>, n_epochs, mse, acc))
</span></span></code></pre></div><p>The code to test should also not change much except the need of optimizer.</p>
<h2 id="results">Results</h2>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Training-Results.png" alt="Results using PyTorch C++ API">
<img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Training-Results-Python.png" alt="Results using PyTorch in Python"></p>
<p>On a set of 400 images for training data, the maximum training Accuracy I could achieve was 91.25% in just less than 15 epochs using PyTorch C++ API and 89.0% using Python. (Note that this doesn&rsquo;t conclude superiority in terms of accuracy between any of the two backends - C++ or Python)</p>
<p>Let&rsquo;s have a look at correct and wrong predictions.</p>
<p><strong>Correct Predictions - Dogs</strong>
<img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/correct-predictions-dogs-transfer-learning.png" alt=""></p>
<p><strong>Wrong Predictions - Dogs</strong>
<img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/wrong-predictions-dogs-transfer-learning.png" alt=""></p>
<p><strong>Correct Predictions - Cats</strong>
<img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/correct-predictions-cats-transfer-learning.png" alt=""></p>
<p><strong>Wrong Predictions - Cats</strong>
<img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/wrong-predictions-cats-transfer-learning.png" alt=""></p>
<h2 id="acknowledgements">Acknowledgements</h2>
<p>I would like to thank a few people to help me bring this out to the community. Thanks to <a href="https://github.com/ptrblck">Piotr</a> for his comments and answers in the PyTorch Discussion forum. Thanks to <a href="https://github.com/yf225">Will Feng</a> for reviewing the blog and the code and also his constant motivation to bring this out to you all. Would like to thank my constant motivation behind all my work, <a href="https://github.com/vishwesh5">Vishwesh Ravi Shrimali</a> for all his help to start with PyTorch C++ API and help the community. Special thanks to <a href="https://github.com/krutikabapat">Krutika Bapat</a> as well, for reviewing the Python equivalent code and suggesting modifications.</p>
<p>And shout out to all the readers, please share your feedback with me in the comments below. I would love to hear if this blog helped you!</p>
<p>In the upcoming blog, I&rsquo;ll be sharing something very exciting. Till then, happy learning!</p>
]]></content>
        </item>
        
        <item>
            <title>Classifying Dogs vs Cats using PyTorch C&#43;&#43;: Part 2</title>
            <link>https://krshrimali.github.io/posts/2019/07/classifying-dogs-vs-cats-using-pytorch-c-part-2/</link>
            <pubDate>Wed, 31 Jul 2019 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2019/07/classifying-dogs-vs-cats-using-pytorch-c-part-2/</guid>
            <description>In the last blog, we had discussed all but training and results of our custom CNN network on Dogs vs Cats dataset. Today, we&amp;rsquo;ll be making some small changes in the network and discussing training and results of the task.
I&amp;rsquo;ll start with the network overview again, where we used a network similar to VGG-16 (with one extra Fully Connected Layer in the end). While there are absolutely no problems with that network, but since the dataset contains a lot of images (25000 in training dataset) and we were using (200x200x3) input shape to the network (which is 120,000 floating point numbers), this leads to high memory consumption.</description>
            <content type="html"><![CDATA[<p>In the last blog, we had discussed all but training and results of our custom CNN network on Dogs vs Cats dataset. Today, we&rsquo;ll be making some small changes in the network and discussing training and results of the task.</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Classify-Dogs-Cats-Blog-05.jpg" alt=""></p>
<p>I&rsquo;ll start with the network overview again, where we used a network similar to VGG-16 (with one extra Fully Connected Layer in the end). While there are absolutely no problems with that network, but since the dataset contains a lot of images (25000 in training dataset) and we were using (200x200x3) input shape to the network (which is 120,000 floating point numbers), this leads to high memory consumption. In short, I was out of RAM to store these many images during program execution.</p>
<p>So, I decided to change some minute things:</p>
<ol>
<li>Input Shape to the network is now <code>64x64x3</code> (12,288 parameters - around 10 times lesser than for <code>200x200x3</code>). So, all the images are now resized to <code>64x64x3</code>.</li>
<li>Now, we only use 2 Convolutional Layers and 2 Max Pooling Layers to train our dataset. This helps to reduce the parameters for training, and also fastens the training process.</li>
</ol>
<p>But this comes with a tradeoff in accuracy, which will suffice for now as our target is not to get some X accuracy, but to learn how to train the network on our dataset using PyTorch C++ API.</p>
<p><strong>Question</strong>: Does reducing input resolution, affects accuracy?
<strong>Answer</strong>: In this case, it will. The objects in our dataset (dogs and cats) have both high level and low level features, which are visible (provides more details) more to the network with high resolution. In this way, the network is allowed to learn more features out of the dataset. However, in cases like of MNIST, it&rsquo;s just fine to use <code>64x64</code> input resolution as it still allows the network to look at details of a digit and learn robust features.</p>
<p>Let&rsquo;s go ahead and see what has changed in the Network.</p>
<h2 id="network-overview">Network Overview</h2>
<p>If you don&rsquo;t remember from the last time, this is how our network looked.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">NetImpl</span><span style="color:#f92672">:</span> <span style="color:#66d9ef">public</span> torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Module {
</span></span><span style="display:flex;"><span>    NetImpl() {
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Initialize the network
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#75715e">// On how to pass strides and padding: https://github.com/pytorch/pytorch/issues/12649#issuecomment-430156160
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv1_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv1_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv1_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv1_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv2_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv2_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">30</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv2_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv2_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">30</span>, <span style="color:#ae81ff">40</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv3_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv3_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">40</span>, <span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv3_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv3_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">60</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv3_3 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv3_3&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">60</span>, <span style="color:#ae81ff">70</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv4_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv4_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">70</span>, <span style="color:#ae81ff">80</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv4_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv4_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">80</span>, <span style="color:#ae81ff">90</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv4_3 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv4_3&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">90</span>, <span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv5_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv5_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">110</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv5_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv5_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">110</span>, <span style="color:#ae81ff">120</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv5_3 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv5_3&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">120</span>, <span style="color:#ae81ff">130</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        fc1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">130</span><span style="color:#f92672">*</span><span style="color:#ae81ff">6</span><span style="color:#f92672">*</span><span style="color:#ae81ff">6</span>, <span style="color:#ae81ff">2000</span>));
</span></span><span style="display:flex;"><span>        fc2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">2000</span>, <span style="color:#ae81ff">1000</span>));
</span></span><span style="display:flex;"><span>        fc3 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc3&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">1000</span>, <span style="color:#ae81ff">100</span>));
</span></span><span style="display:flex;"><span>        fc4 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc4&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">2</span>));
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Implement Algorithm
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    torch<span style="color:#f92672">::</span>Tensor forward(torch<span style="color:#f92672">::</span>Tensor x) {
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv1_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv1_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv2_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv2_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv3_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv3_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv3_3<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv4_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv4_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv4_3<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv5_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv5_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv5_3<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> x.view({<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">130</span><span style="color:#f92672">*</span><span style="color:#ae81ff">6</span><span style="color:#f92672">*</span><span style="color:#ae81ff">6</span>});
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(fc1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(fc2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(fc3<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> fc4<span style="color:#f92672">-&gt;</span>forward(x);
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> torch<span style="color:#f92672">::</span>log_softmax(x, <span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Declare layers
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv1_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv1_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv2_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv2_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv3_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv3_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv3_3{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv4_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv4_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv4_3{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv5_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv5_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv5_3{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear fc1{<span style="color:#66d9ef">nullptr</span>}, fc2{<span style="color:#66d9ef">nullptr</span>}, fc3{<span style="color:#66d9ef">nullptr</span>}, fc4{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p>As it&rsquo;s visible, we had 13 Convolutional Layers, 5 Max Pooling Layers and 4 Fully Connected Layers. This leads of a lot of parameters to be trained.</p>
<p>Therefore, our new network for experimentation purposes will be:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">NetworkImpl</span> <span style="color:#f92672">:</span> <span style="color:#66d9ef">public</span> torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Module {
</span></span><span style="display:flex;"><span>	NetImpl(<span style="color:#66d9ef">int64_t</span> channels, <span style="color:#66d9ef">int64_t</span> height, <span style="color:#66d9ef">int64_t</span> width) {
</span></span><span style="display:flex;"><span>		conv1_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">3</span>, <span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">5</span>).stride(<span style="color:#ae81ff">2</span>)));
</span></span><span style="display:flex;"><span>		conv2_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">7</span>).stride(<span style="color:#ae81ff">2</span>)));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		<span style="color:#75715e">// Used to find the output size till previous convolutional layers
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>		n(get_output_shape(channels, height, width));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		fc1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(n, <span style="color:#ae81ff">120</span>));
</span></span><span style="display:flex;"><span>		fc2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">120</span>, <span style="color:#ae81ff">100</span>));
</span></span><span style="display:flex;"><span>		fc3 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc3&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">2</span>));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>		register_module(<span style="color:#e6db74">&#34;conv1&#34;</span>, conv1);
</span></span><span style="display:flex;"><span>		register_module(<span style="color:#e6db74">&#34;conv2&#34;</span>, conv2);
</span></span><span style="display:flex;"><span>		register_module(<span style="color:#e6db74">&#34;fc1&#34;</span>, fc1);
</span></span><span style="display:flex;"><span>		register_module(<span style="color:#e6db74">&#34;fc2&#34;</span>, fc2);
</span></span><span style="display:flex;"><span>		register_module(<span style="color:#e6db74">&#34;fc3&#34;</span>, fc3);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Implement forward pass of each batch to the network
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    torch<span style="color:#f92672">::</span>Tensor forward(torch<span style="color:#f92672">::</span>Tensor x) {
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(torch<span style="color:#f92672">::</span>max_pool2d(conv1(x), <span style="color:#ae81ff">2</span>));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(torch<span style="color:#f92672">::</span>max_pool2d(conv2(x), <span style="color:#ae81ff">2</span>));
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Flatten
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        x <span style="color:#f92672">=</span> x.view({<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, n});
</span></span><span style="display:flex;"><span>		
</span></span><span style="display:flex;"><span>		x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(fc1(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(fc2(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>log_softmax(fc3(x), <span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> x;
</span></span><span style="display:flex;"><span>    };
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Function to calculate output size of input tensor after Convolutional layers
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">int64_t</span> <span style="color:#a6e22e">get_output_shape</span>(<span style="color:#66d9ef">int64_t</span> channels, <span style="color:#66d9ef">int64_t</span> height, <span style="color:#66d9ef">int64_t</span> width) {
</span></span><span style="display:flex;"><span>    	<span style="color:#75715e">// Initialize a Tensor with zeros of input shape
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    	torch<span style="color:#f92672">::</span>Tensor x_sample <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>zeros({<span style="color:#ae81ff">1</span>, channels, height, width});
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    	x_sample <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(conv1(x_sample), <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>        x_sample <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(conv2(x_sample), <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Return batch_size (here, 1) * channels * height * width of x_sample
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#66d9ef">return</span> x_sample.numel();
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p>In our new network, we use 2 Convolutional Layers with Max Pooling and ReLU Activation, and 3 Fully Connected Layers. This, as we mentioned above, reduces the number of parameters for training.</p>
<p>Let us train our network on the dataset now.</p>
<h2 id="training">Training</h2>
<p>Let&rsquo;s discuss steps of training a CNN on our dataset:</p>
<ol>
<li>Set network to training mode using <code>net-&gt;train()</code>.</li>
<li>Iterate through every batch of our data loader:
<ol>
<li>Extract data and labels using:
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> data <span style="color:#f92672">=</span> batch.data;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> target <span style="color:#f92672">=</span> batch.target.squeeze();
</span></span></code></pre></div></li>
<li>Clear gradients of optimizer: <code>optimizer.zero_grad()</code></li>
<li>Forward pass the batch of data to the network: <code>auto output = net-&gt;forward(data);</code></li>
<li>Calculate Negative Log Likelihood loss (since we use <code>log_softmax()</code> layer at the end): <code>auto loss = torch::nll_loss(output, target);</code></li>
<li>Backpropagate Loss: <code>auto loss = loss.backward()</code></li>
<li>Update the weights: <code>optimizer.step();</code></li>
<li>Calculate Training Accuracy and Mean Squared Error:
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> acc <span style="color:#f92672">=</span> output.argmax(<span style="color:#ae81ff">1</span>).eq(target).sum();
</span></span><span style="display:flex;"><span>mse <span style="color:#f92672">+=</span> loss.<span style="color:#66d9ef">template</span> item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>();
</span></span></code></pre></div></li>
</ol>
</li>
<li>Save the model using <code>torch::save(net, &quot;model.pt&quot;);</code>.</li>
</ol>
<p>Let&rsquo;s try to convert the above steps to a <code>train()</code> function.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">train</span>(ConvNet<span style="color:#f92672">&amp;</span> net, DataLoader<span style="color:#f92672">&amp;</span> data_loader, torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>Optimizer<span style="color:#f92672">&amp;</span> optimizer, size_t dataset_size, <span style="color:#66d9ef">int</span> epoch) {
</span></span><span style="display:flex;"><span>	<span style="color:#75715e">/*
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	This function trains the network on our data loader using optimizer for given number of epochs.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	Parameters
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	==================
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	ConvNet&amp; net: Network struct
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	DataLoader&amp; data_loader: Training data loader
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	torch::optim::Optimizer&amp; optimizer: Optimizer like Adam, SGD etc.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	size_t dataset_size: Size of training dataset
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	int epoch: Number of epoch for training
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">	*/</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	net<span style="color:#f92672">-&gt;</span>train();
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    size_t batch_index <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> mse <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">float</span> Acc <span style="color:#f92672">=</span> <span style="color:#ae81ff">0.0</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">auto</span><span style="color:#f92672">&amp;</span> batch: <span style="color:#f92672">*</span>data_loader) {
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">auto</span> data <span style="color:#f92672">=</span> batch.data;
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">auto</span> target <span style="color:#f92672">=</span> batch.target.squeeze();
</span></span><span style="display:flex;"><span>      
</span></span><span style="display:flex;"><span>      <span style="color:#75715e">// Should be of length: batch_size
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>      data <span style="color:#f92672">=</span> data.to(torch<span style="color:#f92672">::</span>kF32);
</span></span><span style="display:flex;"><span>      target <span style="color:#f92672">=</span> target.to(torch<span style="color:#f92672">::</span>kInt64);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      optimizer.zero_grad();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">auto</span> output <span style="color:#f92672">=</span> net<span style="color:#f92672">-&gt;</span>forward(data);
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">auto</span> loss <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>nll_loss(output, target);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      loss.backward();
</span></span><span style="display:flex;"><span>      optimizer.step();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      <span style="color:#66d9ef">auto</span> acc <span style="color:#f92672">=</span> output.argmax(<span style="color:#ae81ff">1</span>).eq(target).sum();
</span></span><span style="display:flex;"><span>      Acc <span style="color:#f92672">+=</span> acc.<span style="color:#66d9ef">template</span> item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>();
</span></span><span style="display:flex;"><span>      mse <span style="color:#f92672">+=</span> loss.<span style="color:#66d9ef">template</span> item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>      batch_index <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>;
</span></span><span style="display:flex;"><span>      count<span style="color:#f92672">++</span>;
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>    mse <span style="color:#f92672">=</span> mse<span style="color:#f92672">/</span><span style="color:#66d9ef">float</span>(batch_index); <span style="color:#75715e">// Take mean of loss
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span>    std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Epoch: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> epoch <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;, &#34;</span> <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Accuracy: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> Acc<span style="color:#f92672">/</span>dataset_size <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;, &#34;</span> <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;MSE: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> mse <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>save(net, <span style="color:#e6db74">&#34;best_model_try.pt&#34;</span>);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Similarly, we also define a Test Function to test our network on the test dataset. The steps include:</p>
<ol>
<li>Set network to <code>eval</code> mode: <code>network-&gt;eval()</code>.</li>
<li>Iterate through every batch of test data.
<ol>
<li>Extract data and labels.</li>
<li>Forward pass the batch of data to the network.</li>
<li>Calculate NLL Loss and Accuracy</li>
</ol>
</li>
<li>Print test loss and accuracy.</li>
</ol>
<p>The code for the <code>test()</code> function is below:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">void</span> <span style="color:#a6e22e">test</span>(ConvNet<span style="color:#f92672">&amp;</span> network, DataLoader<span style="color:#f92672">&amp;</span> loader, size_t data_size) {
</span></span><span style="display:flex;"><span>  size_t batch_index <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  network<span style="color:#f92672">-&gt;</span>eval();
</span></span><span style="display:flex;"><span>  
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">float</span> Loss <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>, Acc <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span> (<span style="color:#66d9ef">const</span> <span style="color:#66d9ef">auto</span><span style="color:#f92672">&amp;</span> batch : <span style="color:#f92672">*</span>loader) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> data <span style="color:#f92672">=</span> batch.data;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> targets <span style="color:#f92672">=</span> batch.target.view({<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>});
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    data <span style="color:#f92672">=</span> data.to(torch<span style="color:#f92672">::</span>kF32);
</span></span><span style="display:flex;"><span>	targets <span style="color:#f92672">=</span> targets.to(torch<span style="color:#f92672">::</span>kInt64);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> output <span style="color:#f92672">=</span> network<span style="color:#f92672">-&gt;</span>forward(data);
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> loss <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>nll_loss(output, targets);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> acc <span style="color:#f92672">=</span> output.argmax(<span style="color:#ae81ff">1</span>).eq(targets).sum();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    Loss <span style="color:#f92672">+=</span> loss.<span style="color:#66d9ef">template</span> item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>();
</span></span><span style="display:flex;"><span>    Acc <span style="color:#f92672">+=</span> acc.<span style="color:#66d9ef">template</span> item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>();
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Test Loss: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> Loss<span style="color:#f92672">/</span>data_size <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;, Acc:&#34;</span> <span style="color:#f92672">&lt;&lt;</span> Acc<span style="color:#f92672">/</span>data_size <span style="color:#f92672">&lt;&lt;</span> endl;
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h2 id="results">Results</h2>
<p>I trained my network on the dataset for 100 Epochs.</p>
<p>The best training and testing accuracies are given below:</p>
<ol>
<li><strong>Best Training Accuracy:</strong> 99.82%</li>
<li><strong>Best Testing Accuracy:</strong> 82.43%</li>
</ol>
<p>Let&rsquo;s look at some of the correct and wrong predictions.</p>
<h2 id="correct-predictions-dogs">Correct Predictions (Dogs)</h2>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Correct-Predictions-Dogs.png" alt="Correct Predictions of Dogs"></p>
<h2 id="correct-predictions-cats">Correct Predictions (Cats)</h2>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Correct-Predictions-Cats.png" alt="Correct Predictions of Cats">
<img src="/assets/Correct-Predictions-Cats.png" alt="Correct Predictions of Cats"></p>
<h2 id="wrong-predictions-dogs">Wrong Predictions (Dogs)</h2>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Wrong-Predictions-Dog.png" alt="Wrong Predictions of Dogs"></p>
<h2 id="wrong-predictions-cats">Wrong Predictions (Cats)</h2>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Wrong-Predictions-Cats.png" alt="Wrong Predictions of Cats"></p>
<p>Clearly, the network has done well for just a 2 Convolutional and 3 FC Layer Network. It seems to have focused more on the posture of the animal (and body). We can make the network learn more robust features, with a more deeper CNN (like VGG-16). We&rsquo;ll be discussing on using pretrained weights on Dogs vs Cats Dataset using PyTorch C++ API and also Transfer Learning Approach in C++.</p>
<p>Happy Learning!</p>
]]></content>
        </item>
        
        <item>
            <title>Classifying Dogs vs Cats using PyTorch C&#43;&#43; API: Part-1</title>
            <link>https://krshrimali.github.io/posts/2019/07/classifying-dogs-vs-cats-using-pytorch-c-api-part-1/</link>
            <pubDate>Tue, 23 Jul 2019 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2019/07/classifying-dogs-vs-cats-using-pytorch-c-api-part-1/</guid>
            <description>&lt;p&gt;Hi Everyone! So excited to be back with another blog in the series of PyTorch C++ Blogs.&lt;/p&gt;
&lt;p&gt;Today, we are going to see a practical example of applying a CNN to a Custom Dataset - Dogs vs Cats. This is going to be a short post of showing results and discussion about hyperparameters and loss functions for the task, as code snippets and explanation has been provided &lt;a href=&#34;https://krshrimali.github.io/Training-Network-Using-Custom-Dataset-PyTorch-CPP/&#34;&gt;here&lt;/a&gt;, &lt;a href=&#34;https://krshrimali.github.io/Custom-Data-Loading-Using-PyTorch-CPP-API/&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://krshrimali.github.io/PyTorch-C++-API/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img src=&#34;https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Cover-Dogs-Cats.jpg&#34; alt=&#34;&#34;&gt;&lt;/p&gt;</description>
            <content type="html"><![CDATA[<p>Hi Everyone! So excited to be back with another blog in the series of PyTorch C++ Blogs.</p>
<p>Today, we are going to see a practical example of applying a CNN to a Custom Dataset - Dogs vs Cats. This is going to be a short post of showing results and discussion about hyperparameters and loss functions for the task, as code snippets and explanation has been provided <a href="https://krshrimali.github.io/Training-Network-Using-Custom-Dataset-PyTorch-CPP/">here</a>, <a href="https://krshrimali.github.io/Custom-Data-Loading-Using-PyTorch-CPP-API/">here</a> and <a href="https://krshrimali.github.io/PyTorch-C++-API/">here</a>.</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Cover-Dogs-Cats.jpg" alt=""></p>
<p><strong>Note</strong>: This is Part-1 of the blog on Dogs vs Cats Classification using PyTorch C++ API.</p>
<h2 id="dataset-overview">Dataset Overview</h2>
<p>Let&rsquo;s have a look at the dataset and it&rsquo;s statistics. <strong>Dogs vs Cats</strong> dataset has been taken from the famous <a href="https://www.kaggle.com/c/dogs-vs-cats">Kaggle Competition</a>.</p>
<p>The training set contains 25k images combined of dogs and cats. The data can be downloaded from <a href="https://www.kaggle.com/c/dogs-vs-cats/data">this</a> link.</p>
<p>Let&rsquo;s have a look at sample of the data:</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/krshrimali.github.io/master/assets/dogs-dataset.jpg" alt="Figure 1: Sample of Dog Images in the Dataset"></p>
<p><img src="https://raw.githubusercontent.com/krshrimali/krshrimali.github.io/master/assets/cats-dataset.jpg" alt="Figure 2: Sample of Cat Images in the Dataset"></p>
<p>As we can see, the dataset contains images of cats and dogs with multiple instances in the same sample as well.</p>
<h2 id="loading-data">Loading Data</h2>
<p>Although we have discussed this before (<a href="https://krshrimali.github.io/Custom-Data-Loading-Using-PyTorch-CPP-API/">here</a>), but let&rsquo;s just see how we load the data. Since this is a binary classification problem (2 classes: Dog and Cat), we will have labels as 0 (for a Cat) and 1 (for a Dog). The data comes in two zip files:</p>
<ol>
<li><code>train.zip</code>: Data to be used for training</li>
<li><code>test.zip</code>: Data to be used for testing</li>
</ol>
<p>The <code>train.zip</code> file contains files with filenames like <code>&lt;class&gt;.&lt;number&gt;.jpg</code> where:</p>
<ul>
<li><code>class</code> can be either cat or dog.</li>
<li><code>number</code> represents the count of the sample.</li>
</ul>
<p>For example: <code>cat.100.jpg</code> and <code>dog.1.jpg</code>. In order to load the data, we will move the cat images to <code>train/cat</code> folder and dog images to <code>train/dog</code> folder. You can accomplish this using <code>shutil</code> module:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># This code moves cat and dog images to train/cat and train/dog folders respectively</span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> shutil<span style="color:#f92672">,</span> os
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>files <span style="color:#f92672">=</span> os<span style="color:#f92672">.</span>listdir(<span style="color:#e6db74">&#39;train/&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>count_cat <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#75715e"># Number representing count of the cat image</span>
</span></span><span style="display:flex;"><span>count_dog <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span> <span style="color:#75715e"># Number representing count of the dog image</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> file <span style="color:#f92672">in</span> files:
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">if</span>(file<span style="color:#f92672">.</span>startswith(<span style="color:#e6db74">&#39;cat&#39;</span>) <span style="color:#f92672">and</span> file<span style="color:#f92672">.</span>endswith(<span style="color:#e6db74">&#39;jpg&#39;</span>)):
</span></span><span style="display:flex;"><span>		count_cat <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>		shutil<span style="color:#f92672">.</span>copy(<span style="color:#e6db74">&#39;train/&#39;</span> <span style="color:#f92672">+</span> file, <span style="color:#e6db74">&#39;train/cat/&#39;</span> <span style="color:#f92672">+</span> str(count_cat) <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;.jpg&#34;</span>)
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">elif</span>(file<span style="color:#f92672">.</span>startswith(<span style="color:#e6db74">&#39;dog&#39;</span>) <span style="color:#f92672">and</span> file<span style="color:#f92672">.</span>endswith(<span style="color:#e6db74">&#39;jpg&#39;</span>)):
</span></span><span style="display:flex;"><span>		count_dog <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>		shutil<span style="color:#f92672">.</span>copy(<span style="color:#e6db74">&#39;test/&#39;</span> <span style="color:#f92672">+</span> file, <span style="color:#e6db74">&#39;train/dog/&#39;</span> <span style="color:#f92672">+</span> str(count_dog) <span style="color:#f92672">+</span> <span style="color:#e6db74">&#39;.jpg&#39;</span>)
</span></span></code></pre></div><p>Once done, let&rsquo;s go ahead and load this data. Since we have discussed this <a href="https://krshrimali.github.io/posts/2019/07/custom-data-loading-using-pytorch-c-api/">before</a>, I&rsquo;ll just paste the snippet here.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>Tensor read_data(std<span style="color:#f92672">::</span>string loc) {
</span></span><span style="display:flex;"><span>	<span style="color:#75715e">// Read Image from the location of image
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>	cv<span style="color:#f92672">::</span>Mat img <span style="color:#f92672">=</span> cv<span style="color:#f92672">::</span>imread(loc, <span style="color:#ae81ff">0</span>);
</span></span><span style="display:flex;"><span>	cv<span style="color:#f92672">::</span>resize(img, img, cv<span style="color:#f92672">::</span>Size(<span style="color:#ae81ff">200</span>, <span style="color:#ae81ff">200</span>), cv<span style="color:#f92672">::</span>INTER_CUBIC);
</span></span><span style="display:flex;"><span>	std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Sizes: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> img.size() <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>	torch<span style="color:#f92672">::</span>Tensor img_tensor <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>from_blob(img.data, {img.rows, img.cols, <span style="color:#ae81ff">1</span>}, torch<span style="color:#f92672">::</span>kByte);
</span></span><span style="display:flex;"><span>	img_tensor <span style="color:#f92672">=</span> img_tensor.permute({<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>}); <span style="color:#75715e">// Channels x Height x Width
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> img_tensor.clone();
</span></span><span style="display:flex;"><span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>Tensor read_label(<span style="color:#66d9ef">int</span> label) {
</span></span><span style="display:flex;"><span>	torch<span style="color:#f92672">::</span>Tensor label_tensor <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>full({<span style="color:#ae81ff">1</span>}, label);
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> label_tensor.clone();
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vector<span style="color:#f92672">&lt;</span>torch<span style="color:#f92672">::</span>Tensor<span style="color:#f92672">&gt;</span> process_images(vector<span style="color:#f92672">&lt;</span>string<span style="color:#f92672">&gt;</span> list_images) {
</span></span><span style="display:flex;"><span>	cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Reading images...&#34;</span> <span style="color:#f92672">&lt;&lt;</span> endl;
</span></span><span style="display:flex;"><span>	vector<span style="color:#f92672">&lt;</span>torch<span style="color:#f92672">::</span>Tensor<span style="color:#f92672">&gt;</span> states;
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> (std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span>string<span style="color:#f92672">&gt;::</span>iterator it <span style="color:#f92672">=</span> list_images.begin(); it <span style="color:#f92672">!=</span> list_images.end(); <span style="color:#f92672">++</span>it) {
</span></span><span style="display:flex;"><span>        cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Location being read: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> <span style="color:#f92672">*</span>it <span style="color:#f92672">&lt;&lt;</span> endl;
</span></span><span style="display:flex;"><span>		torch<span style="color:#f92672">::</span>Tensor img <span style="color:#f92672">=</span> read_data(<span style="color:#f92672">*</span>it);
</span></span><span style="display:flex;"><span>		states.push_back(img);
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Reading and Processing images done!&#34;</span> <span style="color:#f92672">&lt;&lt;</span> endl;
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> states;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>vector<span style="color:#f92672">&lt;</span>torch<span style="color:#f92672">::</span>Tensor<span style="color:#f92672">&gt;</span> process_labels(vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> list_labels) {
</span></span><span style="display:flex;"><span>	cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Reading labels...&#34;</span> <span style="color:#f92672">&lt;&lt;</span> endl;
</span></span><span style="display:flex;"><span>	vector<span style="color:#f92672">&lt;</span>torch<span style="color:#f92672">::</span>Tensor<span style="color:#f92672">&gt;</span> labels;
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> (std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;::</span>iterator it <span style="color:#f92672">=</span> list_labels.begin(); it <span style="color:#f92672">!=</span> list_labels.end(); <span style="color:#f92672">++</span>it) {
</span></span><span style="display:flex;"><span>		torch<span style="color:#f92672">::</span>Tensor label <span style="color:#f92672">=</span> read_label(<span style="color:#f92672">*</span>it);
</span></span><span style="display:flex;"><span>		labels.push_back(label);
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Labels reading done!&#34;</span> <span style="color:#f92672">&lt;&lt;</span> endl;
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> labels;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">/* This function returns a pair of vector of images paths (strings) and labels (integers) */</span>
</span></span><span style="display:flex;"><span>std<span style="color:#f92672">::</span>pair<span style="color:#f92672">&lt;</span>vector<span style="color:#f92672">&lt;</span>string<span style="color:#f92672">&gt;</span>,vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;&gt;</span> load_data_from_folder(vector<span style="color:#f92672">&lt;</span>string<span style="color:#f92672">&gt;</span> folders_name) {
</span></span><span style="display:flex;"><span>	vector<span style="color:#f92672">&lt;</span>string<span style="color:#f92672">&gt;</span> list_images;
</span></span><span style="display:flex;"><span>	vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> list_labels;
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">int</span> label <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">auto</span> <span style="color:#66d9ef">const</span><span style="color:#f92672">&amp;</span> value: folders_name) {
</span></span><span style="display:flex;"><span>		string base_name <span style="color:#f92672">=</span> value <span style="color:#f92672">+</span> <span style="color:#e6db74">&#34;/&#34;</span>;
</span></span><span style="display:flex;"><span>		cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Reading from: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> base_name <span style="color:#f92672">&lt;&lt;</span> endl;
</span></span><span style="display:flex;"><span>		DIR<span style="color:#f92672">*</span> dir;
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">dirent</span> <span style="color:#f92672">*</span>ent;
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">if</span>((dir <span style="color:#f92672">=</span> opendir(base_name.c_str())) <span style="color:#f92672">!=</span> NULL) {
</span></span><span style="display:flex;"><span>			<span style="color:#66d9ef">while</span>((ent <span style="color:#f92672">=</span> readdir(dir)) <span style="color:#f92672">!=</span> NULL) {
</span></span><span style="display:flex;"><span>				string filename <span style="color:#f92672">=</span> ent<span style="color:#f92672">-&gt;</span>d_name;
</span></span><span style="display:flex;"><span>				<span style="color:#66d9ef">if</span>(filename.length() <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">4</span> <span style="color:#f92672">&amp;&amp;</span> filename.substr(filename.length() <span style="color:#f92672">-</span> <span style="color:#ae81ff">3</span>) <span style="color:#f92672">==</span> <span style="color:#e6db74">&#34;jpg&#34;</span>) {
</span></span><span style="display:flex;"><span>					cout <span style="color:#f92672">&lt;&lt;</span> base_name <span style="color:#f92672">+</span> ent<span style="color:#f92672">-&gt;</span>d_name <span style="color:#f92672">&lt;&lt;</span> endl;
</span></span><span style="display:flex;"><span>					<span style="color:#75715e">// cv::Mat temp = cv::imread(base_name + &#34;/&#34; + ent-&gt;d_name, 1);
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>					list_images.push_back(base_name <span style="color:#f92672">+</span> ent<span style="color:#f92672">-&gt;</span>d_name);
</span></span><span style="display:flex;"><span>					list_labels.push_back(label);
</span></span><span style="display:flex;"><span>				}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>			}
</span></span><span style="display:flex;"><span>			closedir(dir);
</span></span><span style="display:flex;"><span>		} <span style="color:#66d9ef">else</span> {
</span></span><span style="display:flex;"><span>			cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Could not open directory&#34;</span> <span style="color:#f92672">&lt;&lt;</span> endl;
</span></span><span style="display:flex;"><span>			<span style="color:#75715e">// return EXIT_FAILURE;
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>		}
</span></span><span style="display:flex;"><span>		label <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>;
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> std<span style="color:#f92672">::</span>make_pair(list_images, list_labels);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The above snippet has the utility functions we need. Here is a quick summary of what they do:</p>
<ol>
<li>
<p><strong>load_data_from_folder</strong>: This function returns a tuple of list of image paths (string) and list of labels (int). It takes a vector of folders names (string type) as parameter.</p>
</li>
<li>
<p><strong>process_images</strong>: This function returns a vector of Tensors (images). This function calls <code>read_data</code> function which reads, resizes and converts an image to a Torch Tensor. It takes a vector of image paths (string) as parameter.</p>
</li>
<li>
<p><strong>process_labels</strong>: Similar to <code>process_images</code> function, this function returns a vector of Tensors (labels). This function calls <code>read_label</code> function which takes an <code>int</code> as a parameter (label: 0 or 1) and returns a Tensor.</p>
</li>
</ol>
<p>Let&rsquo;s now go ahead and see how we load the data. For this, we first need to define the <code>Dataset</code> class. This class should initialize two variables: one for images and one for labels. As discussed <a href="https://krshrimali.github.io/posts/2019/07/custom-data-loading-using-pytorch-c-api/">here</a>, we&rsquo;ll also define <code>get()</code> and <code>size()</code> functions.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">CustomDataset</span> <span style="color:#f92672">:</span> <span style="color:#66d9ef">public</span> torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>Dataset<span style="color:#f92672">&lt;</span>CustomDataset<span style="color:#f92672">&gt;</span> {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">private</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>	<span style="color:#75715e">/* data */</span>
</span></span><span style="display:flex;"><span>	<span style="color:#75715e">// Should be 2 tensors
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>	vector<span style="color:#f92672">&lt;</span>torch<span style="color:#f92672">::</span>Tensor<span style="color:#f92672">&gt;</span> states, labels;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>	CustomDataset(vector<span style="color:#f92672">&lt;</span>string<span style="color:#f92672">&gt;</span> list_images, vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> list_labels) {
</span></span><span style="display:flex;"><span>		states <span style="color:#f92672">=</span> process_images(list_images);
</span></span><span style="display:flex;"><span>		labels <span style="color:#f92672">=</span> process_labels(list_labels);
</span></span><span style="display:flex;"><span>	};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>	torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>Example<span style="color:#f92672">&lt;&gt;</span> get(size_t index) <span style="color:#66d9ef">override</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#75715e">/* This should return {torch::Tensor, torch::Tensor} */</span>
</span></span><span style="display:flex;"><span>		torch<span style="color:#f92672">::</span>Tensor sample_img <span style="color:#f92672">=</span> states.at(index);
</span></span><span style="display:flex;"><span>		torch<span style="color:#f92672">::</span>Tensor sample_label <span style="color:#f92672">=</span> labels.at(index);
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">return</span> {sample_img.clone(), sample_label.clone()};
</span></span><span style="display:flex;"><span>	};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  torch<span style="color:#f92672">::</span>optional<span style="color:#f92672">&lt;</span>size_t<span style="color:#f92672">&gt;</span> size() <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">override</span> {
</span></span><span style="display:flex;"><span>		<span style="color:#66d9ef">return</span> states.size();
</span></span><span style="display:flex;"><span>  };
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p>Once done, we can go ahead and initialize the Dataset in our <code>main()</code> function.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>(<span style="color:#66d9ef">int</span> argc, <span style="color:#66d9ef">char</span> <span style="color:#66d9ef">const</span> <span style="color:#f92672">*</span>argv[]) {
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Load the model.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#75715e">// Read Data
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  vector<span style="color:#f92672">&lt;</span>string<span style="color:#f92672">&gt;</span> folders_name;
</span></span><span style="display:flex;"><span>  folders_name.push_back(<span style="color:#e6db74">&#34;/home/krshrimali/Documents/data-dogs-cats/train/cat&#34;</span>);
</span></span><span style="display:flex;"><span>  folders_name.push_back(<span style="color:#e6db74">&#34;/home/krshrimali/Documents/data-dogs-cats/train/dog&#34;</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>pair<span style="color:#f92672">&lt;</span>vector<span style="color:#f92672">&lt;</span>string<span style="color:#f92672">&gt;</span>, vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;&gt;</span> pair_images_labels <span style="color:#f92672">=</span> load_data_from_folder(folders_name);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  vector<span style="color:#f92672">&lt;</span>string<span style="color:#f92672">&gt;</span> list_images <span style="color:#f92672">=</span> pair_images_labels.first;
</span></span><span style="display:flex;"><span>  vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> list_labels <span style="color:#f92672">=</span> pair_images_labels.second;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">auto</span> custom_dataset <span style="color:#f92672">=</span> CustomDataset(list_images, list_labels).map(torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>transforms<span style="color:#f92672">::</span>Stack<span style="color:#f92672">&lt;&gt;</span>());
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h2 id="network-overview">Network Overview</h2>
<p>To make things easy to read (a programmer&rsquo;s mantra), we define our network in a header file. We will use a CNN network initially for this binary classification task. Since I&rsquo;m not using a GPU, the training is slow and that&rsquo;s why I experimented it only for 10 epochs. The whole objective is to discuss and show how to use PyTorch C++ API for this. You can always run it for more epochs or change the network parameters.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">NetImpl</span><span style="color:#f92672">:</span> <span style="color:#66d9ef">public</span> torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Module {
</span></span><span style="display:flex;"><span>    NetImpl() {
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Initialize the network
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#75715e">// On how to pass strides and padding: https://github.com/pytorch/pytorch/issues/12649#issuecomment-430156160
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv1_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv1_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv1_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv1_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv2_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv2_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">30</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv2_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv2_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">30</span>, <span style="color:#ae81ff">40</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv3_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv3_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">40</span>, <span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv3_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv3_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">60</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv3_3 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv3_3&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">60</span>, <span style="color:#ae81ff">70</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv4_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv4_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">70</span>, <span style="color:#ae81ff">80</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv4_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv4_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">80</span>, <span style="color:#ae81ff">90</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv4_3 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv4_3&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">90</span>, <span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv5_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv5_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">110</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv5_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv5_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">110</span>, <span style="color:#ae81ff">120</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv5_3 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv5_3&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">120</span>, <span style="color:#ae81ff">130</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        fc1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">130</span><span style="color:#f92672">*</span><span style="color:#ae81ff">6</span><span style="color:#f92672">*</span><span style="color:#ae81ff">6</span>, <span style="color:#ae81ff">2000</span>));
</span></span><span style="display:flex;"><span>        fc2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">2000</span>, <span style="color:#ae81ff">1000</span>));
</span></span><span style="display:flex;"><span>        fc3 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc3&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">1000</span>, <span style="color:#ae81ff">100</span>));
</span></span><span style="display:flex;"><span>        fc4 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc4&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">2</span>));
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Implement Algorithm
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    torch<span style="color:#f92672">::</span>Tensor forward(torch<span style="color:#f92672">::</span>Tensor x) {
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv1_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv1_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv2_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv2_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv3_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv3_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv3_3<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv4_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv4_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv4_3<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv5_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv5_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv5_3<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> x.view({<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">130</span><span style="color:#f92672">*</span><span style="color:#ae81ff">6</span><span style="color:#f92672">*</span><span style="color:#ae81ff">6</span>});
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(fc1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(fc2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(fc3<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> fc4<span style="color:#f92672">-&gt;</span>forward(x);
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> torch<span style="color:#f92672">::</span>log_softmax(x, <span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Declare layers
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv1_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv1_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv2_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv2_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv3_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv3_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv3_3{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv4_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv4_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv4_3{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv5_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv5_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv5_3{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear fc1{<span style="color:#66d9ef">nullptr</span>}, fc2{<span style="color:#66d9ef">nullptr</span>}, fc3{<span style="color:#66d9ef">nullptr</span>}, fc4{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p>We will initialize this network and pass each batch of our data once in an epoch.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Initialize the Network
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">auto</span> net <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>make_shared<span style="color:#f92672">&lt;</span>NetImpl<span style="color:#f92672">&gt;</span>();
</span></span></code></pre></div><h2 id="training-the-network-on-dogs-vs-cats-dataset">Training the Network on Dogs vs Cats Dataset</h2>
<p>We had before discussed code for training <a href="https://krshrimali.github.io/posts/2019/07/training-a-network-on-custom-dataset-using-pytorch-c-api/">here</a>. I suggest the reader to go through that blog in order to train the dataset. I&rsquo;ll give more insights on training in the next blog!</p>
<p>That&rsquo;s it for today. I&rsquo;ll be back with Part-2 of this &ldquo;Dogs vs Cats Classification&rdquo; with training, experimentation and results. We&rsquo;ll also discuss on using different networks, and in the Part-3, we&rsquo;ll discuss using <strong>Transfer Learning</strong> for this classification task.</p>]]></content>
        </item>
        
        <item>
            <title>Training a Network on Custom Dataset using PyTorch C&#43;&#43; API</title>
            <link>https://krshrimali.github.io/posts/2019/07/training-a-network-on-custom-dataset-using-pytorch-c-api/</link>
            <pubDate>Fri, 05 Jul 2019 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2019/07/training-a-network-on-custom-dataset-using-pytorch-c-api/</guid>
            <description>&lt;h2 id=&#34;recap-of-the-last-blog&#34;&gt;Recap of the last blog&lt;/h2&gt;
&lt;p&gt;Before we move on, it&amp;rsquo;s important what we covered in the last blog. We&amp;rsquo;ll be going forward from loading Custom Dataset to now using the dataset to train our VGG-16 Network. Previously, we were able to load our custom dataset using the following template:&lt;/p&gt;</description>
            <content type="html"><![CDATA[<h2 id="recap-of-the-last-blog">Recap of the last blog</h2>
<p>Before we move on, it&rsquo;s important what we covered in the last blog. We&rsquo;ll be going forward from loading Custom Dataset to now using the dataset to train our VGG-16 Network. Previously, we were able to load our custom dataset using the following template:</p>
<p><strong>Note</strong>: Those who are already aware of loading a custom dataset can skip this section.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">CustomDataset</span> <span style="color:#f92672">:</span> <span style="color:#66d9ef">public</span> torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>dataset<span style="color:#f92672">&lt;</span>CustomDataset<span style="color:#f92672">&gt;</span> {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">private</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Declare 2 vectors of tensors for images and labels
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  vector<span style="color:#f92672">&lt;</span>torch<span style="color:#f92672">::</span>Tensor<span style="color:#f92672">&gt;</span> images, labels;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Constructor
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  CustomDataset(vector<span style="color:#f92672">&lt;</span>string<span style="color:#f92672">&gt;</span> list_images, vector<span style="color:#f92672">&lt;</span>string<span style="color:#f92672">&gt;</span> list_labels) {
</span></span><span style="display:flex;"><span>    images <span style="color:#f92672">=</span> process_images(list_images);
</span></span><span style="display:flex;"><span>    labels <span style="color:#f92672">=</span> process_labels(list_labels);
</span></span><span style="display:flex;"><span>  };
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Override get() function to return tensor at location index
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>Example<span style="color:#f92672">&lt;&gt;</span> get(size_t index) <span style="color:#66d9ef">override</span> {
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>Tensor sample_img <span style="color:#f92672">=</span> images.at(index);
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>Tensor sample_label <span style="color:#f92672">=</span> labels.at(index);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> {sample_img.clone(), sample_label.clone()};
</span></span><span style="display:flex;"><span>  };
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Return the length of data
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  torch<span style="color:#f92672">::</span>optional<span style="color:#f92672">&lt;</span>size_t<span style="color:#f92672">&gt;</span> size() <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">override</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> labels.size();
</span></span><span style="display:flex;"><span>  };
</span></span><span style="display:flex;"><span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>(<span style="color:#66d9ef">int</span> argc, <span style="color:#66d9ef">char</span><span style="color:#f92672">**</span> argv) {
</span></span><span style="display:flex;"><span>  vector<span style="color:#f92672">&lt;</span>string<span style="color:#f92672">&gt;</span> list_images; <span style="color:#75715e">// list of path of images
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> list_labels; <span style="color:#75715e">// list of integer labels
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Dataset init and apply transforms - None!
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">auto</span> custom_dataset <span style="color:#f92672">=</span> CustomDataset(list_images, list_labels).map(torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>transforms<span style="color:#f92672">::</span>Stack<span style="color:#f92672">&lt;&gt;</span>());
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>These were the steps we followed last time:</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Steps-Loading-Custom-Data.PNG" alt=""></p>
<h2 id="overview-how-to-pass-batches-to-our-network">Overview: How to pass batches to our network?</h2>
<p>Since we have our dataset loaded, let&rsquo;s see how to pass batches of data to our network. Before we go on and see how PyTorch C++ API does it, let&rsquo;s see how it&rsquo;s done in Python.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>dataset_loader <span style="color:#f92672">=</span> torch<span style="color:#f92672">.</span>utils<span style="color:#f92672">.</span>data<span style="color:#f92672">.</span>DataLoader(custom_dataset,
</span></span><span style="display:flex;"><span>                                             batch_size<span style="color:#f92672">=</span><span style="color:#ae81ff">4</span>, shuffle<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)
</span></span></code></pre></div><p>Just a short review of what <code>DataLoader()</code> class does: It loads the data and returns single or multiple iterators over the dataset. We pass in our object from <code>Dataset</code> class (here, <code>custom_dataset</code>). We will do the same process in C++ using the following template:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> data_loader <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>make_data_loader<span style="color:#f92672">&lt;</span>torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>samplers<span style="color:#f92672">::</span>SequentialSampler<span style="color:#f92672">&gt;</span>(
</span></span><span style="display:flex;"><span>  std<span style="color:#f92672">::</span>move(custom_dataset),
</span></span><span style="display:flex;"><span>  batch_size
</span></span><span style="display:flex;"><span>);
</span></span></code></pre></div><p>In brief, we are loading our data using <code>SequentialSampler</code> class which samples our data in the same order that we provided it with. Have a look at the <code>SequentialSampler</code> class <a href="https://pytorch.org/docs/stable/data.html#torch.utils.data.SequentialSampler">here</a>.</p>
<p>For the definition of this function: <code>torch::data::make_data_loader</code> <a href="https://pytorch.org/cppdocs/api/function_namespacetorch_1_1data_1a0d29ca9900cae66957c5cc5052ecc122.html#exhale-function-namespacetorch-1-1data-1a0d29ca9900cae66957c5cc5052ecc122">here</a>. A short screenshot from the documentation is given below.</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Data-Loader-Function.PNG" alt=""></p>
<p>Let&rsquo;s go ahead and learn to iterate through our data loader and pass each batch of data and labels to our network. For once, imagine that we have a <code>struct</code> named <code>Net</code> which defines our network and <code>forward()</code> function which parses the data through each layer and returns the output.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">auto</span><span style="color:#f92672">&amp;</span> batch: <span style="color:#f92672">*</span>data_loader) {
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">auto</span> data <span style="color:#f92672">=</span> batch.data;
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">auto</span> target <span style="color:#f92672">=</span> batch.target.squeeze();
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>So we have retrieved our <code>data</code> and label (<code>target</code>) - which also depends on the batch size. If you have <code>batch_size</code> as 4 in the <code>torch::data::make_data_loader()</code> function, then size of the target and data will be 4.</p>
<h2 id="defining-the-hyperparameters-in-libtorch">Defining the Hyperparameters in Libtorch</h2>
<p>Remember the Hyperparameters we need to define for training? Let&rsquo;s take a quick review of what they are:</p>
<ol>
<li><strong>Batch Size</strong></li>
<li><strong>Optimizer</strong></li>
<li><strong>Loss Function</strong></li>
</ol>
<p>We have used <code>batch_size</code> parameter above while making the data loader. For defining optimizer, we&rsquo;ll go for <code>Adam</code> Optimizer here:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// We need to define the network first
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">auto</span> net <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>make_shared<span style="color:#f92672">&lt;</span>Net<span style="color:#f92672">&gt;</span>();
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>Adam optimizer(net<span style="color:#f92672">-&gt;</span>parameters(), torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>AdamOptions(<span style="color:#ae81ff">1e-3</span>));
</span></span></code></pre></div><p><strong>Note that the PyTorch C++ API supports below listed optimizers:</strong></p>
<ol>
<li><a href="https://pytorch.org/cppdocs/api/classtorch_1_1optim_1_1_r_m_sprop.html#exhale-class-classtorch-1-1optim-1-1-r-m-sprop">RMSprop</a></li>
<li><a href="https://pytorch.org/cppdocs/api/classtorch_1_1optim_1_1_s_g_d.html#exhale-class-classtorch-1-1optim-1-1-s-g-d">SGD</a></li>
<li><a href="https://pytorch.org/cppdocs/api/classtorch_1_1optim_1_1_adam.html#exhale-class-classtorch-1-1optim-1-1-adam">Adam</a></li>
<li><a href="https://pytorch.org/cppdocs/api/classtorch_1_1optim_1_1_adagrad.html#exhale-class-classtorch-1-1optim-1-1-adagrad">Adagrad</a></li>
<li><a href="https://pytorch.org/cppdocs/api/classtorch_1_1optim_1_1_l_b_f_g_s.html#exhale-class-classtorch-1-1optim-1-1-l-b-f-g-s">LBFGS</a></li>
<li><a href="https://pytorch.org/cppdocs/api/classtorch_1_1optim_1_1_loss_closure_optimizer.html#exhale-class-classtorch-1-1optim-1-1-loss-closure-optimizer">LossClosureOptimizer</a></li>
</ol>
<p>As mentioned in the documentation of <code>torch.optim</code> package:</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/Use-Optim.PNG" alt=""></p>
<p>The documentation is self explanatory, so all we need to do is pass parameters of our Network which will be optimized using our optimizer, and pass in the learning rate like above. To know about parameters we can pass through <code>AdamOptions</code>, check out this <a href="https://pytorch.org/cppdocs/api/structtorch_1_1optim_1_1_adam_options.html#exhale-struct-structtorch-1-1optim-1-1-adam-options">documentation page</a>.</p>
<p>Let&rsquo;s go ahead and learn to define <strong>Loss Function</strong> in PyTorch C++ API. For an example, we&rsquo;ll define <code>nll_loss</code> (Negative Log Likelihood Loss Function):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> output <span style="color:#f92672">=</span> net<span style="color:#f92672">-&gt;</span>forward(data);
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> loss <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>nll_loss(output, target);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// To backpropagate loss
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>loss.backward()
</span></span></code></pre></div><p>If you need to output the loss, use: <code>loss.item&lt;float&gt;()</code>.</p>
<h2 id="training-the-network">Training the Network</h2>
<p>We are close to our last step! Training the network is almost similar to the way we do in Python. That&rsquo;s why, I&rsquo;ll include the code snippet here which should be self explanatory (since we have already discussed the core parts of it).</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>dataset_size <span style="color:#f92672">=</span> custom_dataset.size().value();
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">int</span> n_epochs <span style="color:#f92672">=</span> <span style="color:#ae81ff">10</span>; <span style="color:#75715e">// Number of epochs
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">int</span> epoch<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; epoch<span style="color:#f92672">&lt;=</span>n_epochs; epoch<span style="color:#f92672">++</span>) {
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">for</span>(<span style="color:#66d9ef">auto</span><span style="color:#f92672">&amp;</span> batch: <span style="color:#f92672">*</span>data_loader) {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> data <span style="color:#f92672">=</span> batch.data;
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> target <span style="color:#f92672">=</span> batch.target.squeeze();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Convert data to float32 format and target to Int64 format
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// Assuming you have labels as integers
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    data <span style="color:#f92672">=</span> data.to(torch<span style="color:#f92672">::</span>kF2);
</span></span><span style="display:flex;"><span>    target <span style="color:#f92672">=</span> target.to(torch<span style="color:#f92672">::</span>kInt64);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Clear the optimizer parameters
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    optimizer.zero_grad();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> output <span style="color:#f92672">=</span> net<span style="color:#f92672">-&gt;</span>forward(data);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">auto</span> loss <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>nll_loss(output, target);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Backpropagate the loss
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    loss.backward();
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Update the parameters
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    optimizer.step();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Train Epoch: %d/%ld [%5ld/%5d] Loss: %.4f&#34;</span> <span style="color:#f92672">&lt;&lt;</span> epoch <span style="color:#f92672">&lt;&lt;</span> n_epochs <span style="color:#f92672">&lt;&lt;</span> batch_index <span style="color:#f92672">*</span> batch.data.size(<span style="color:#ae81ff">0</span>) <span style="color:#f92672">&lt;&lt;</span> dataset_size <span style="color:#f92672">&lt;&lt;</span> loss.item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>() <span style="color:#f92672">&lt;&lt;</span> endl;
</span></span><span style="display:flex;"><span>  }
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">// Save the model
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>torch<span style="color:#f92672">::</span>save(net, <span style="color:#e6db74">&#34;best_model.pt&#34;</span>);
</span></span></code></pre></div><p>In the next blog (<strong>coming soon</strong>), we&rsquo;ll be discussing about <strong>Making Predictions</strong> using our network and will also show an example of training our network on a benchmark dataset.</p>]]></content>
        </item>
        
        <item>
            <title>Announcing a series of blogs on PyTorch C&#43;&#43; API</title>
            <link>https://krshrimali.github.io/posts/2019/07/announcing-a-series-of-blogs-on-pytorch-c-api/</link>
            <pubDate>Thu, 04 Jul 2019 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2019/07/announcing-a-series-of-blogs-on-pytorch-c-api/</guid>
            <description>I&amp;rsquo;m happy to announce a Series of Blog Posts on PyTorch C++ API. Check out the blogs in the series here.
Happy Reading!</description>
            <content type="html"><![CDATA[<p><strong>I&rsquo;m happy to announce a Series of Blog Posts on PyTorch C++ API</strong>. Check out the blogs in the series <a href="https://krshrimali.github.io/categories/pytorch/">here</a>.</p>
<p>Happy Reading!</p>
]]></content>
        </item>
        
        <item>
            <title>Custom Data Loading using PyTorch C&#43;&#43; API</title>
            <link>https://krshrimali.github.io/posts/2019/07/custom-data-loading-using-pytorch-c-api/</link>
            <pubDate>Tue, 02 Jul 2019 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2019/07/custom-data-loading-using-pytorch-c-api/</guid>
            <description>Overview: How C++ API loads data? In the last blog, we discussed application of a VGG-16 Network on MNIST Data. For those, who are reading this blog for the first time, here is how we had loaded MNIST data:
auto data_loader = torch::data::make_data_loader&amp;lt;torch::data::samplers::SequentialSampler&amp;gt;( std::move(torch::data::datasets::MNIST(&amp;#34;../../data&amp;#34;).map(torch::data::transforms::Normalize&amp;lt;&amp;gt;(0.13707, 0.3081))).map( torch::data::transforms::Stack&amp;lt;&amp;gt;()), 64); Let&amp;rsquo;s break this piece by piece, as for beginners, this may be unclear. First, we ask the C++ API to load data (images and labels) into tensors.</description>
            <content type="html"><![CDATA[<h2 id="overview-how-c-api-loads-data">Overview: How C++ API loads data?</h2>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Cover-Custom-Data.png" alt=""></p>
<p>In the last blog, we discussed application of a VGG-16 Network on MNIST Data. For those, who are reading this blog for the first time, here is how we had loaded MNIST data:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> data_loader <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>make_data_loader<span style="color:#f92672">&lt;</span>torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>samplers<span style="color:#f92672">::</span>SequentialSampler<span style="color:#f92672">&gt;</span>(
</span></span><span style="display:flex;"><span>			std<span style="color:#f92672">::</span>move(torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>datasets<span style="color:#f92672">::</span>MNIST(<span style="color:#e6db74">&#34;../../data&#34;</span>).map(torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>transforms<span style="color:#f92672">::</span>Normalize<span style="color:#f92672">&lt;&gt;</span>(<span style="color:#ae81ff">0.13707</span>, <span style="color:#ae81ff">0.3081</span>))).map(
</span></span><span style="display:flex;"><span>				torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>transforms<span style="color:#f92672">::</span>Stack<span style="color:#f92672">&lt;&gt;</span>()), <span style="color:#ae81ff">64</span>);
</span></span></code></pre></div><p>Let&rsquo;s break this piece by piece, as for beginners, this may be unclear. First, we ask the C++ API to load data (images and labels) into tensors.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Your data should be at: ../data position
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">auto</span> data_set <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>datasets<span style="color:#f92672">::</span>MNIST(<span style="color:#e6db74">&#34;../data&#34;</span>);
</span></span></code></pre></div><p>If you have this question on how the API loads the images and labels to tensors - we&rsquo;ll get to that. For now, just take it as a black box, which loads the data. Next, we apply transforms (like normalizing to ImageNet standards):</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">auto</span> data_set <span style="color:#f92672">=</span> data_set.map(torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>transforms<span style="color:#f92672">::</span>Normalize<span style="color:#f92672">&lt;&gt;</span>(<span style="color:#ae81ff">0.13707</span>, <span style="color:#ae81ff">0.3081</span>)).map(torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>transforms<span style="color:#f92672">::</span>Stack<span style="color:#f92672">&lt;&gt;</span>())
</span></span></code></pre></div><p>For the sake of batch size, let&rsquo;s divide the data for batch size as 64.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>std<span style="color:#f92672">::</span>move(data_set, <span style="color:#ae81ff">64</span>);
</span></span></code></pre></div><p>Once this all is done, we can iterate through the data loader and pass each batch to the network. It&rsquo;s time to understand how this all works, let&rsquo;s go ahead and look at the source code of <code>torch::data::datasets::MNIST</code> class.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">namespace</span> torch {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">namespace</span> data {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">namespace</span> datasets {
</span></span><span style="display:flex;"><span><span style="color:#75715e">/// The MNIST dataset.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">TORCH_API</span> MNIST : <span style="color:#66d9ef">public</span> Dataset<span style="color:#f92672">&lt;</span>MNIST<span style="color:#f92672">&gt;</span> {
</span></span><span style="display:flex;"><span> <span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">/// The mode in which the dataset is loaded.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">enum</span> <span style="color:#66d9ef">class</span> <span style="color:#a6e22e">Mode</span> { kTrain, kTest };
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">/// Loads the MNIST dataset from the root path.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#75715e">///
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#75715e">/// The supplied root path should contain the content of the unzipped
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#75715e">/// MNIST dataset, available from http://yann.lecun.com/exdb/mnist.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">explicit</span> <span style="color:#a6e22e">MNIST</span>(<span style="color:#66d9ef">const</span> std<span style="color:#f92672">::</span>string<span style="color:#f92672">&amp;</span> root, Mode mode <span style="color:#f92672">=</span> Mode<span style="color:#f92672">::</span>kTrain);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">/// Returns the Example at the given index.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  Example<span style="color:#f92672">&lt;&gt;</span> get(size_t index) <span style="color:#66d9ef">override</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">/// Returns the size of the dataset.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  optional<span style="color:#f92672">&lt;</span>size_t<span style="color:#f92672">&gt;</span> size() <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">override</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">/// Returns true if this is the training subset of MNIST.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">bool</span> <span style="color:#a6e22e">is_train</span>() <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">noexcept</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">/// Returns all images stacked into a single tensor.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">const</span> Tensor<span style="color:#f92672">&amp;</span> images() <span style="color:#66d9ef">const</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">/// Returns all targets stacked into a single tensor.
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">const</span> Tensor<span style="color:#f92672">&amp;</span> targets() <span style="color:#66d9ef">const</span>;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span> <span style="color:#66d9ef">private</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>  Tensor images_, targets_;
</span></span><span style="display:flex;"><span>};
</span></span><span style="display:flex;"><span>} <span style="color:#75715e">// namespace datasets
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>} <span style="color:#75715e">// namespace data
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>} <span style="color:#75715e">// namespace torch
</span></span></span></code></pre></div><p>Reference: <a href="https://github.com/pytorch/pytorch/blob/master/torch/csrc/api/include/torch/data/datasets/mnist.h">https://github.com/pytorch/pytorch/blob/master/torch/csrc/api/include/torch/data/datasets/mnist.h</a></p>
<p>Assuming the reader has done some basic C++ before reading this, they will be very well aware of how to initialize a C++ Class. Let&rsquo;s go step by step. What happens when we initialize the class? Let&rsquo;s look at the definition of constructor of the class MNIST at <code>mnist.cpp</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>MNIST<span style="color:#f92672">::</span>MNIST(<span style="color:#66d9ef">const</span> std<span style="color:#f92672">::</span>string<span style="color:#f92672">&amp;</span> root, Mode mode)
</span></span><span style="display:flex;"><span>    <span style="color:#f92672">:</span> images_(read_images(root, mode <span style="color:#f92672">==</span> Mode<span style="color:#f92672">::</span>kTrain)),
</span></span><span style="display:flex;"><span>      targets_(read_targets(root, mode <span style="color:#f92672">==</span> Mode<span style="color:#f92672">::</span>kTrain)) {}
</span></span></code></pre></div><p>Observing the above snippet, it&rsquo;s clear that the constructor calls <code>read_images(root, mode)</code> and <code>read_targets</code> for loading images and labels into tensors. Let&rsquo;s go to the source code of <code>read_images()</code> and <code>read_targets()</code>.</p>
<ol>
<li><strong>read_images()</strong>:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>Tensor <span style="color:#a6e22e">read_images</span>(<span style="color:#66d9ef">const</span> std<span style="color:#f92672">::</span>string<span style="color:#f92672">&amp;</span> root, <span style="color:#66d9ef">bool</span> train) {
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// kTrainImagesFilename and kTestImagesFilename are specific to MNIST dataset here
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#75715e">// No need for using join_paths here
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">auto</span> path <span style="color:#f92672">=</span>
</span></span><span style="display:flex;"><span>      join_paths(root, train <span style="color:#f92672">?</span> kTrainImagesFilename : kTestImagesFilename);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Load images
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  std<span style="color:#f92672">::</span>ifstream images(path, std<span style="color:#f92672">::</span>ios<span style="color:#f92672">::</span>binary);
</span></span><span style="display:flex;"><span>  TORCH_CHECK(images, <span style="color:#e6db74">&#34;Error opening images file at &#34;</span>, path);
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// kTrainSize = len(training data)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#75715e">// kTestSize = len(testing_data)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">auto</span> count <span style="color:#f92672">=</span> train <span style="color:#f92672">?</span> kTrainSize : kTestSize;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Specific to MNIST data
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#75715e">// From http://yann.lecun.com/exdb/mnist/
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  expect_int32(images, kImageMagicNumber);
</span></span><span style="display:flex;"><span>  expect_int32(images, count);
</span></span><span style="display:flex;"><span>  expect_int32(images, kImageRows);
</span></span><span style="display:flex;"><span>  expect_int32(images, kImageColumns);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// This converts images to tensors
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#75715e">// Allocate an empty tensor of size of image (count, channels, height, width)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">auto</span> tensor <span style="color:#f92672">=</span>
</span></span><span style="display:flex;"><span>      torch<span style="color:#f92672">::</span>empty({count, <span style="color:#ae81ff">1</span>, kImageRows, kImageColumns}, torch<span style="color:#f92672">::</span>kByte);
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Read image and convert to tensor
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  images.read(<span style="color:#66d9ef">reinterpret_cast</span><span style="color:#f92672">&lt;</span><span style="color:#66d9ef">char</span><span style="color:#f92672">*&gt;</span>(tensor.data_ptr()), tensor.numel());
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Normalize the image from 0 to 255 to 0 to 1
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">return</span> tensor.to(torch<span style="color:#f92672">::</span>kFloat32).div_(<span style="color:#ae81ff">255</span>);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><ol start="2">
<li><strong>read_targets()</strong>:</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>Tensor <span style="color:#a6e22e">read_targets</span>(<span style="color:#66d9ef">const</span> std<span style="color:#f92672">::</span>string<span style="color:#f92672">&amp;</span> root, <span style="color:#66d9ef">bool</span> train) {
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Specific to MNIST dataset (kTrainImagesFilename and kTestTargetsFilename)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">auto</span> path <span style="color:#f92672">=</span>
</span></span><span style="display:flex;"><span>      join_paths(root, train <span style="color:#f92672">?</span> kTrainTargetsFilename : kTestTargetsFilename);
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Read the labels
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  std<span style="color:#f92672">::</span>ifstream targets(path, std<span style="color:#f92672">::</span>ios<span style="color:#f92672">::</span>binary);
</span></span><span style="display:flex;"><span>  TORCH_CHECK(targets, <span style="color:#e6db74">&#34;Error opening targets file at &#34;</span>, path);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// kTrainSize = len(training_labels)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#75715e">// kTestSize = len(testing_labels)
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">auto</span> count <span style="color:#f92672">=</span> train <span style="color:#f92672">?</span> kTrainSize : kTestSize;
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  expect_int32(targets, kTargetMagicNumber);
</span></span><span style="display:flex;"><span>  expect_int32(targets, count);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Allocate an empty tensor of size of number of labels
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">auto</span> tensor <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>empty(count, torch<span style="color:#f92672">::</span>kByte);
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Convert to tensor
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  targets.read(<span style="color:#66d9ef">reinterpret_cast</span><span style="color:#f92672">&lt;</span><span style="color:#66d9ef">char</span><span style="color:#f92672">*&gt;</span>(tensor.data_ptr()), count);
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> tensor.to(torch<span style="color:#f92672">::</span>kInt64);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>Since we are now done with how the constructor works, let&rsquo;s go ahead and see what other functions does the class inherit.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>Example<span style="color:#f92672">&lt;&gt;</span> MNIST<span style="color:#f92672">::</span>get(size_t index) {
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> {images_[index], targets_[index]};
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>optional<span style="color:#f92672">&lt;</span>size_t<span style="color:#f92672">&gt;</span> MNIST<span style="color:#f92672">::</span>size() <span style="color:#66d9ef">const</span> {
</span></span><span style="display:flex;"><span>  <span style="color:#66d9ef">return</span> images_.size(<span style="color:#ae81ff">0</span>);
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>The above two functions: <code>get(size_t)</code> and <code>size()</code> are used to get a sample image and label and length of the data respectively.</p>
<h2 id="the-pipeline">The Pipeline</h2>
<p>Since we are now clear with the possible pipeline of loading custom data:</p>
<ol>
<li>Read Images and Labels</li>
<li>Convert to Tensors</li>
<li>Write <code>get()</code> and <code>size()</code> functions</li>
<li>Initialize the class with paths of images and labels</li>
<li>Pass it to the data loader</li>
</ol>
<h2 id="coding-your-own-custom-data-loader">Coding your own Custom Data Loader</h2>
<p>Let&rsquo;s first write the template of our custom data loader:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Include libraries
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;ATen/ATen.h&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;torch/torch.h&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;iostream&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;vector&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;tuple&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;opencv2/opencv.hpp&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;string&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">/* Convert and Load image to tensor from location argument */</span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>Tensor read_data(std<span style="color:#f92672">::</span>string location) {
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Read Data here
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#75715e">// Return tensor form of the image
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">return</span> torch<span style="color:#f92672">::</span>Tensor;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">/* Converts label to tensor type in the integer argument */</span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>Tensor read_label(<span style="color:#66d9ef">int</span> label) {
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Read label here
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#75715e">// Convert to tensor and return
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">return</span> torch<span style="color:#f92672">::</span>Tensor;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">/* Loads images to tensor type in the string argument */</span>
</span></span><span style="display:flex;"><span>vector<span style="color:#f92672">&lt;</span>torch<span style="color:#f92672">::</span>Tensor<span style="color:#f92672">&gt;</span> process_images(vector<span style="color:#f92672">&lt;</span>string<span style="color:#f92672">&gt;</span> list_images) {
</span></span><span style="display:flex;"><span>  cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Reading Images...&#34;</span> <span style="color:#f92672">&lt;&lt;</span> endl;
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Return vector of Tensor form of all the images
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">return</span> vector<span style="color:#f92672">&lt;</span>torch<span style="color:#f92672">::</span>Tensor<span style="color:#f92672">&gt;</span>;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">/* Loads labels to tensor type in the string argument */</span>
</span></span><span style="display:flex;"><span>vector<span style="color:#f92672">&lt;</span>torch<span style="color:#f92672">::</span>Tensor<span style="color:#f92672">&gt;</span> process_labels(vector<span style="color:#f92672">&lt;</span>string<span style="color:#f92672">&gt;</span> list_labels) {
</span></span><span style="display:flex;"><span>  cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Reading Labels...&#34;</span> <span style="color:#f92672">&lt;&lt;</span> endl;
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Return vector of Tensor form of all the labels
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">return</span> vector<span style="color:#f92672">&lt;</span>torch<span style="color:#f92672">::</span>Tensor<span style="color:#f92672">&gt;</span>;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">CustomDataset</span> <span style="color:#f92672">:</span> <span style="color:#66d9ef">public</span> torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>dataset<span style="color:#f92672">&lt;</span>CustomDataset<span style="color:#f92672">&gt;</span> {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">private</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Declare 2 vectors of tensors for images and labels
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  vector<span style="color:#f92672">&lt;</span>torch<span style="color:#f92672">::</span>Tensor<span style="color:#f92672">&gt;</span> images, labels;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Constructor
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  CustomDataset(vector<span style="color:#f92672">&lt;</span>string<span style="color:#f92672">&gt;</span> list_images, vector<span style="color:#f92672">&lt;</span>string<span style="color:#f92672">&gt;</span> list_labels) {
</span></span><span style="display:flex;"><span>    images <span style="color:#f92672">=</span> process_images(list_images);
</span></span><span style="display:flex;"><span>    labels <span style="color:#f92672">=</span> process_labels(list_labels);
</span></span><span style="display:flex;"><span>  };
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Override get() function to return tensor at location index
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>Example<span style="color:#f92672">&lt;&gt;</span> get(size_t index) <span style="color:#66d9ef">override</span> {
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>Tensor sample_img <span style="color:#f92672">=</span> images.at(index);
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>Tensor sample_label <span style="color:#f92672">=</span> labels.at(index);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> {sample_img.clone(), sample_label.clone()};
</span></span><span style="display:flex;"><span>  };
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Return the length of data
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  torch<span style="color:#f92672">::</span>optional<span style="color:#f92672">&lt;</span>size_t<span style="color:#f92672">&gt;</span> size() <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">override</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> labels.size();
</span></span><span style="display:flex;"><span>  };
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p>We are almost there, all we need to do is - Read Images and Labels to <code>torch::Tensor</code> type. I&rsquo;ll be using OpenCV to read images, as it also helps later on to visualize results.</p>
<p><strong>Reading Images</strong>:</p>
<p>The process to read an image in OpenCV is trivial: <code>cv::imread(std::string location, int)</code>. We then convert it to a tensor. Note that a tensor is of form (batch size, channels, height, width), so we also permute the tensor to that form.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>Tensor read_data(std<span style="color:#f92672">::</span>string loc) {
</span></span><span style="display:flex;"><span>	<span style="color:#75715e">// Read Image from the location of image
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>	cv<span style="color:#f92672">::</span>Mat img <span style="color:#f92672">=</span> cv<span style="color:#f92672">::</span>imread(loc, <span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Convert image to tensor
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>	torch<span style="color:#f92672">::</span>Tensor img_tensor <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>from_blob(img.data, {img.rows, img.cols, <span style="color:#ae81ff">3</span>}, torch<span style="color:#f92672">::</span>kByte);
</span></span><span style="display:flex;"><span>	img_tensor <span style="color:#f92672">=</span> img_tensor.permute({<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>}); <span style="color:#75715e">// Channels x Height x Width
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> img_tensor.clone();
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p><strong>Reading Labels</strong>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Read Label (int) and convert to torch::Tensor type
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>torch<span style="color:#f92672">::</span>Tensor read_label(<span style="color:#66d9ef">int</span> label) {
</span></span><span style="display:flex;"><span>	torch<span style="color:#f92672">::</span>Tensor label_tensor <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>full({<span style="color:#ae81ff">1</span>}, label);
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> label_tensor.clone();
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><h2 id="final-code">Final Code</h2>
<p>Let&rsquo;s wrap up the code!</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">// Include libraries
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;ATen/ATen.h&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;torch/torch.h&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;iostream&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;vector&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;tuple&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;opencv2/opencv.hpp&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e">#include</span> <span style="color:#75715e">&lt;string&gt;</span><span style="color:#75715e">
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">/* Convert and Load image to tensor from location argument */</span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>Tensor read_data(std<span style="color:#f92672">::</span>string loc) {
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Read Data here
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#75715e">// Return tensor form of the image
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  cv<span style="color:#f92672">::</span>Mat img <span style="color:#f92672">=</span> cv<span style="color:#f92672">::</span>imread(loc, <span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>	cv<span style="color:#f92672">::</span>resize(img, img, cv<span style="color:#f92672">::</span>Size(<span style="color:#ae81ff">1920</span>, <span style="color:#ae81ff">1080</span>), cv<span style="color:#f92672">::</span>INTER_CUBIC);
</span></span><span style="display:flex;"><span>	std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Sizes: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> img.size() <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>	torch<span style="color:#f92672">::</span>Tensor img_tensor <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>from_blob(img.data, {img.rows, img.cols, <span style="color:#ae81ff">3</span>}, torch<span style="color:#f92672">::</span>kByte);
</span></span><span style="display:flex;"><span>	img_tensor <span style="color:#f92672">=</span> img_tensor.permute({<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>}); <span style="color:#75715e">// Channels x Height x Width
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> img_tensor.clone();
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">/* Converts label to tensor type in the integer argument */</span>
</span></span><span style="display:flex;"><span>torch<span style="color:#f92672">::</span>Tensor read_label(<span style="color:#66d9ef">int</span> label) {
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Read label here
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#75715e">// Convert to tensor and return
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  torch<span style="color:#f92672">::</span>Tensor label_tensor <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>full({<span style="color:#ae81ff">1</span>}, label);
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> label_tensor.clone();
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">/* Loads images to tensor type in the string argument */</span>
</span></span><span style="display:flex;"><span>vector<span style="color:#f92672">&lt;</span>torch<span style="color:#f92672">::</span>Tensor<span style="color:#f92672">&gt;</span> process_images(vector<span style="color:#f92672">&lt;</span>string<span style="color:#f92672">&gt;</span> list_images) {
</span></span><span style="display:flex;"><span>  cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Reading Images...&#34;</span> <span style="color:#f92672">&lt;&lt;</span> endl;
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Return vector of Tensor form of all the images
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  vector<span style="color:#f92672">&lt;</span>torch<span style="color:#f92672">::</span>Tensor<span style="color:#f92672">&gt;</span> states;
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> (std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span>string<span style="color:#f92672">&gt;::</span>iterator it <span style="color:#f92672">=</span> list_images.begin(); it <span style="color:#f92672">!=</span> list_images.end(); <span style="color:#f92672">++</span>it) {
</span></span><span style="display:flex;"><span>		torch<span style="color:#f92672">::</span>Tensor img <span style="color:#f92672">=</span> read_data(<span style="color:#f92672">*</span>it);
</span></span><span style="display:flex;"><span>		states.push_back(img);
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> states;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">/* Loads labels to tensor type in the string argument */</span>
</span></span><span style="display:flex;"><span>vector<span style="color:#f92672">&lt;</span>torch<span style="color:#f92672">::</span>Tensor<span style="color:#f92672">&gt;</span> process_labels(vector<span style="color:#f92672">&lt;</span>string<span style="color:#f92672">&gt;</span> list_labels) {
</span></span><span style="display:flex;"><span>  cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Reading Labels...&#34;</span> <span style="color:#f92672">&lt;&lt;</span> endl;
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Return vector of Tensor form of all the labels
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  vector<span style="color:#f92672">&lt;</span>torch<span style="color:#f92672">::</span>Tensor<span style="color:#f92672">&gt;</span> labels;
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span> (std<span style="color:#f92672">::</span>vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;::</span>iterator it <span style="color:#f92672">=</span> list_labels.begin(); it <span style="color:#f92672">!=</span> list_labels.end(); <span style="color:#f92672">++</span>it) {
</span></span><span style="display:flex;"><span>		torch<span style="color:#f92672">::</span>Tensor label <span style="color:#f92672">=</span> read_label(<span style="color:#f92672">*</span>it);
</span></span><span style="display:flex;"><span>		labels.push_back(label);
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">return</span> labels;
</span></span><span style="display:flex;"><span>}
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">class</span> <span style="color:#a6e22e">CustomDataset</span> <span style="color:#f92672">:</span> <span style="color:#66d9ef">public</span> torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>dataset<span style="color:#f92672">&lt;</span>CustomDataset<span style="color:#f92672">&gt;</span> {
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">private</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Declare 2 vectors of tensors for images and labels
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  vector<span style="color:#f92672">&lt;</span>torch<span style="color:#f92672">::</span>Tensor<span style="color:#f92672">&gt;</span> images, labels;
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">public</span><span style="color:#f92672">:</span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Constructor
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  CustomDataset(vector<span style="color:#f92672">&lt;</span>string<span style="color:#f92672">&gt;</span> list_images, vector<span style="color:#f92672">&lt;</span>string<span style="color:#f92672">&gt;</span> list_labels) {
</span></span><span style="display:flex;"><span>    images <span style="color:#f92672">=</span> process_images(list_images);
</span></span><span style="display:flex;"><span>    labels <span style="color:#f92672">=</span> process_labels(list_labels);
</span></span><span style="display:flex;"><span>  };
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Override get() function to return tensor at location index
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>Example<span style="color:#f92672">&lt;&gt;</span> get(size_t index) <span style="color:#66d9ef">override</span> {
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>Tensor sample_img <span style="color:#f92672">=</span> images.at(index);
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>Tensor sample_label <span style="color:#f92672">=</span> labels.at(index);
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> {sample_img.clone(), sample_label.clone()};
</span></span><span style="display:flex;"><span>  };
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Return the length of data
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  torch<span style="color:#f92672">::</span>optional<span style="color:#f92672">&lt;</span>size_t<span style="color:#f92672">&gt;</span> size() <span style="color:#66d9ef">const</span> <span style="color:#66d9ef">override</span> {
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> labels.size();
</span></span><span style="display:flex;"><span>  };
</span></span><span style="display:flex;"><span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>(<span style="color:#66d9ef">int</span> argc, <span style="color:#66d9ef">char</span><span style="color:#f92672">**</span> argv) {
</span></span><span style="display:flex;"><span>  vector<span style="color:#f92672">&lt;</span>string<span style="color:#f92672">&gt;</span> list_images; <span style="color:#75715e">// list of path of images
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  vector<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">int</span><span style="color:#f92672">&gt;</span> list_labels; <span style="color:#75715e">// list of integer labels
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span>  <span style="color:#75715e">// Dataset init and apply transforms - None!
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>  <span style="color:#66d9ef">auto</span> custom_dataset <span style="color:#f92672">=</span> CustomDataset(list_images, list_labels).map(torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>transforms<span style="color:#f92672">::</span>Stack<span style="color:#f92672">&lt;&gt;</span>());
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>That&rsquo;s it for today! In the next blog, we&rsquo;ll use this custom data loader and implement a CNN on our data. By then, happy learning. Hope you liked this blog. :)</p>
]]></content>
        </item>
        
        <item>
            <title>Introduction to PyTorch C&#43;&#43; API: MNIST Digit Recognition using VGG-16 Network</title>
            <link>https://krshrimali.github.io/posts/2019/06/introduction-to-pytorch-c-api-mnist-digit-recognition-using-vgg-16-network/</link>
            <pubDate>Fri, 07 Jun 2019 00:00:00 +0000</pubDate>
            
            <guid>https://krshrimali.github.io/posts/2019/06/introduction-to-pytorch-c-api-mnist-digit-recognition-using-vgg-16-network/</guid>
            <description>Environment Setup [Ubuntu 16.04, 18.04] Note: If you have already finished installing PyTorch C++ API, please skip this section.
Download libtorch:
CPU Version: wget https://download.pytorch.org/libtorch/cpu/libtorch-shared-with-deps-latest.zip -O libtorch.zip GPU Version (CUDA 9.0): wget https://download.pytorch.org/libtorch/cu90/libtorch-shared-with-deps-latest.zip -O libtorch.zip GPU Version (CUDA 10.0): wget https://download.pytorch.org/libtorch/cu100/libtorch-shared-with-deps-latest.zip Unzip libtorch.zip:
unzip libtorch.zip We&amp;rsquo;ll use the absolute path of extracted directory (libtorch) later on.
Implementation The VGG-16 Network is shown in the Figure below.
We&amp;rsquo;ll start of by first including libtorch header file.</description>
            <content type="html"><![CDATA[<h1 id="environment-setup-ubuntu-1604-1804">Environment Setup [Ubuntu 16.04, 18.04]</h1>
<p><em>Note: If you have already finished installing PyTorch C++ API, please skip this section.</em></p>
<ol>
<li>
<p>Download <code>libtorch</code>:</p>
<ul>
<li>CPU Version: <code>wget https://download.pytorch.org/libtorch/cpu/libtorch-shared-with-deps-latest.zip -O libtorch.zip</code></li>
<li>GPU Version (CUDA 9.0): <code>wget https://download.pytorch.org/libtorch/cu90/libtorch-shared-with-deps-latest.zip -O libtorch.zip</code></li>
<li>GPU Version (CUDA 10.0): <code>wget https://download.pytorch.org/libtorch/cu100/libtorch-shared-with-deps-latest.zip</code></li>
</ul>
</li>
<li>
<p>Unzip <code>libtorch.zip</code>:</p>
<ul>
<li><code>unzip libtorch.zip</code></li>
</ul>
</li>
</ol>
<p>We&rsquo;ll use the <code>absolute</code> path of extracted directory (<code>libtorch</code>) later on.</p>
<h1 id="implementation">Implementation</h1>
<p>The VGG-16 Network is shown in the Figure below.</p>
<p><img src="https://raw.githubusercontent.com/krshrimali/blog/main/assets/blogs/VGG-16-Architecture-resized.png" alt=""></p>
<p>We&rsquo;ll start of by first including <code>libtorch</code> header file.</p>
<p><code>#include &lt;torch/torch.h&gt;</code></p>
<p>We&rsquo;ll then go ahead and define the network. We&rsquo;ll inherit layers from <code>torch::nn::Module</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#75715e">/* Sample code for training a FCN on MNIST dataset using PyTorch C++ API */</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">/* This code uses VGG-16 Layer Network */</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">struct</span> <span style="color:#a6e22e">Net</span><span style="color:#f92672">:</span> torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Module {
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// VGG-16 Layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// conv1_1 - conv1_2 - pool 1 - conv2_1 - conv2_2 - pool 2 - conv3_1 - conv3_2 - conv3_3 - pool 3 -
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#75715e">// conv4_1 - conv4_2 - conv4_3 - pool 4 - conv5_1 - conv5_2 - conv5_3 - pool 5 - fc6 - fc7 - fc8
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Note: pool 5 not implemented as no need for MNIST dataset
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    Net() {
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Initialize VGG-16
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        <span style="color:#75715e">// On how to pass strides and padding: https://github.com/pytorch/pytorch/issues/12649#issuecomment-430156160
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv1_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv1_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv1_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv1_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">10</span>, <span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv2_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv2_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">30</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv2_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv2_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">30</span>, <span style="color:#ae81ff">40</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv3_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv3_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">40</span>, <span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv3_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv3_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">60</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv3_3 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv3_3&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">60</span>, <span style="color:#ae81ff">70</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv4_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv4_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">70</span>, <span style="color:#ae81ff">80</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv4_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv4_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">80</span>, <span style="color:#ae81ff">90</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv4_3 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv4_3&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">90</span>, <span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        conv5_1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv5_1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">100</span>, <span style="color:#ae81ff">110</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv5_2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv5_2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">110</span>, <span style="color:#ae81ff">120</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        conv5_3 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;conv5_3&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d(torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2dOptions(<span style="color:#ae81ff">120</span>, <span style="color:#ae81ff">130</span>, <span style="color:#ae81ff">3</span>).padding(<span style="color:#ae81ff">1</span>)));
</span></span><span style="display:flex;"><span>        <span style="color:#75715e">// Insert pool layer
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>        fc1 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc1&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">130</span>, <span style="color:#ae81ff">50</span>));
</span></span><span style="display:flex;"><span>        fc2 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc2&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">50</span>, <span style="color:#ae81ff">20</span>));
</span></span><span style="display:flex;"><span>        fc3 <span style="color:#f92672">=</span> register_module(<span style="color:#e6db74">&#34;fc3&#34;</span>, torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear(<span style="color:#ae81ff">20</span>, <span style="color:#ae81ff">10</span>));
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Implement Algorithm
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    torch<span style="color:#f92672">::</span>Tensor forward(torch<span style="color:#f92672">::</span>Tensor x) {
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv1_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv1_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv2_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv2_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv3_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv3_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv3_3<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv4_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv4_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv4_3<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>max_pool2d(x, <span style="color:#ae81ff">2</span>);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv5_1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv5_2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(conv5_3<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> x.view({<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">130</span>});
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(fc1<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>relu(fc2<span style="color:#f92672">-&gt;</span>forward(x));
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> fc3<span style="color:#f92672">-&gt;</span>forward(x);
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">return</span> torch<span style="color:#f92672">::</span>log_softmax(x, <span style="color:#ae81ff">1</span>);
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Declare layers
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv1_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv1_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv2_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv2_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv3_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv3_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv3_3{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv4_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv4_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv4_3{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv5_1{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv5_2{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Conv2d conv5_3{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>nn<span style="color:#f92672">::</span>Linear fc1{<span style="color:#66d9ef">nullptr</span>}, fc2{<span style="color:#66d9ef">nullptr</span>}, fc3{<span style="color:#66d9ef">nullptr</span>};
</span></span><span style="display:flex;"><span>};
</span></span></code></pre></div><p>Once done, we can go ahead and test the network on our sample dataset. Let&rsquo;s go ahead and load data first. We&rsquo;ll be using 10 epochs, learning rate (0.01), and <code>nll_loss</code> as loss functio.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-cpp" data-lang="cpp"><span style="display:flex;"><span><span style="color:#66d9ef">int</span> <span style="color:#a6e22e">main</span>() {
</span></span><span style="display:flex;"><span>	<span style="color:#75715e">// Create multi-threaded data loader for MNIST data
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>	<span style="color:#66d9ef">auto</span> data_loader <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>make_data_loader<span style="color:#f92672">&lt;</span>torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>samplers<span style="color:#f92672">::</span>SequentialSampler<span style="color:#f92672">&gt;</span>(
</span></span><span style="display:flex;"><span>			std<span style="color:#f92672">::</span>move(torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>datasets<span style="color:#f92672">::</span>MNIST(<span style="color:#e6db74">&#34;/absolute/path/to/data&#34;</span>).map(torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>transforms<span style="color:#f92672">::</span>Normalize<span style="color:#f92672">&lt;&gt;</span>(<span style="color:#ae81ff">0.13707</span>, <span style="color:#ae81ff">0.3081</span>)).map(
</span></span><span style="display:flex;"><span>				torch<span style="color:#f92672">::</span>data<span style="color:#f92672">::</span>transforms<span style="color:#f92672">::</span>Stack<span style="color:#f92672">&lt;&gt;</span>())), <span style="color:#ae81ff">64</span>);
</span></span><span style="display:flex;"><span>	
</span></span><span style="display:flex;"><span>    <span style="color:#75715e">// Build VGG-16 Network
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>    <span style="color:#66d9ef">auto</span> net <span style="color:#f92672">=</span> std<span style="color:#f92672">::</span>make_shared<span style="color:#f92672">&lt;</span>Net<span style="color:#f92672">&gt;</span>();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    torch<span style="color:#f92672">::</span>optim<span style="color:#f92672">::</span>SGD optimizer(net<span style="color:#f92672">-&gt;</span>parameters(), <span style="color:#ae81ff">0.01</span>); <span style="color:#75715e">// Learning Rate 0.01
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span>	<span style="color:#75715e">// net.train();
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>
</span></span><span style="display:flex;"><span>	<span style="color:#66d9ef">for</span>(size_t epoch<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>; epoch<span style="color:#f92672">&lt;=</span><span style="color:#ae81ff">10</span>; <span style="color:#f92672">++</span>epoch) {
</span></span><span style="display:flex;"><span>		size_t batch_index <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>;
</span></span><span style="display:flex;"><span>		<span style="color:#75715e">// Iterate data loader to yield batches from the dataset
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>		<span style="color:#66d9ef">for</span> (<span style="color:#66d9ef">auto</span><span style="color:#f92672">&amp;</span> batch: <span style="color:#f92672">*</span>data_loader) {
</span></span><span style="display:flex;"><span>			<span style="color:#75715e">// Reset gradients
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>			optimizer.zero_grad();
</span></span><span style="display:flex;"><span>			<span style="color:#75715e">// Execute the model
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>			torch<span style="color:#f92672">::</span>Tensor prediction <span style="color:#f92672">=</span> net<span style="color:#f92672">-&gt;</span>forward(batch.data);
</span></span><span style="display:flex;"><span>			<span style="color:#75715e">// Compute loss value
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>			torch<span style="color:#f92672">::</span>Tensor loss <span style="color:#f92672">=</span> torch<span style="color:#f92672">::</span>nll_loss(prediction, batch.target);
</span></span><span style="display:flex;"><span>			<span style="color:#75715e">// Compute gradients
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>			loss.backward();
</span></span><span style="display:flex;"><span>			<span style="color:#75715e">// Update the parameters
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>			optimizer.step();
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>			<span style="color:#75715e">// Output the loss and checkpoint every 100 batches
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span>			<span style="color:#66d9ef">if</span> (<span style="color:#f92672">++</span>batch_index <span style="color:#f92672">%</span> <span style="color:#ae81ff">2</span> <span style="color:#f92672">==</span> <span style="color:#ae81ff">0</span>) {
</span></span><span style="display:flex;"><span>				std<span style="color:#f92672">::</span>cout <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34;Epoch: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> epoch <span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34; | Batch: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> batch_index 
</span></span><span style="display:flex;"><span>					<span style="color:#f92672">&lt;&lt;</span> <span style="color:#e6db74">&#34; | Loss: &#34;</span> <span style="color:#f92672">&lt;&lt;</span> loss.item<span style="color:#f92672">&lt;</span><span style="color:#66d9ef">float</span><span style="color:#f92672">&gt;</span>() <span style="color:#f92672">&lt;&lt;</span> std<span style="color:#f92672">::</span>endl;
</span></span><span style="display:flex;"><span>				torch<span style="color:#f92672">::</span>save(net, <span style="color:#e6db74">&#34;net.pt&#34;</span>);
</span></span><span style="display:flex;"><span>			}
</span></span><span style="display:flex;"><span>		}
</span></span><span style="display:flex;"><span>	}
</span></span><span style="display:flex;"><span>}
</span></span></code></pre></div><p>For code, check out my repo here: <a href="https://github.com/krshrimali/Digit-Recognition-MNIST-SVHN-PyTorch-CPP">https://github.com/krshrimali/Digit-Recognition-MNIST-SVHN-PyTorch-CPP</a></p>
<p>In the next blog, we will discuss about another network on MNIST and SVHN Dataset.</p>
<h1 id="references">References</h1>
<ol>
<li><a href="https://pytorch.org/cppdocs/">https://pytorch.org/cppdocs/</a></li>
<li><a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a></li>
</ol>
]]></content>
        </item>
        
    </channel>
</rss>
