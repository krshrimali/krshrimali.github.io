<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Libtorch on Kushashwa Ravi Shrimali (Kush)</title>
    <link>https://krshrimali.github.io/tags/libtorch/</link>
    <description>Recent content in Libtorch on Kushashwa Ravi Shrimali (Kush)</description>
    <generator>Hugo -- 0.147.6</generator>
    <language>en</language>
    <copyright>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</copyright>
    <lastBuildDate>Tue, 15 Sep 2020 00:00:00 +0000</lastBuildDate>
    <atom:link href="https://krshrimali.github.io/tags/libtorch/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Releasing Docker Container and Binder for using Xeus-Cling, Libtorch and OpenCV in C&#43;&#43;</title>
      <link>https://krshrimali.github.io/posts/2020/09/releasing-docker-container-and-binder-for-using-xeus-cling-libtorch-and-opencv-in-c-/</link>
      <pubDate>Tue, 15 Sep 2020 00:00:00 +0000</pubDate>
      <guid>https://krshrimali.github.io/posts/2020/09/releasing-docker-container-and-binder-for-using-xeus-cling-libtorch-and-opencv-in-c-/</guid>
      <description>&lt;p&gt;Today, I am elated to share Docker image for &lt;code&gt;OpenCV&lt;/code&gt;, &lt;code&gt;Libtorch&lt;/code&gt; and &lt;code&gt;Xeus-Cling&lt;/code&gt;. We&amp;rsquo;ll discuss how to use the &lt;code&gt;dockerfile&lt;/code&gt; and &lt;code&gt;binder&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Cover-Docker-Binder.jpg&#34;&gt;&lt;/p&gt;
&lt;p&gt;Before I move on, the credits for creating and maintaining Docker image goes to &lt;a href=&#34;https://github.com/vishwesh5&#34;&gt;Vishwesh Ravi Shrimali&lt;/a&gt;. He has been working on some cool stuff, please do get in touch with him if you&amp;rsquo;re interested to know.&lt;/p&gt;
&lt;p&gt;First question in your mind would be, &lt;strong&gt;Why use Docker or Binder?&lt;/strong&gt; The answer to it lies in the frequency of queries on &lt;a href=&#34;http://www.discuss.pytorch.org&#34;&gt;the discussion forum of PyTorch&lt;/a&gt; and Stackoverflow on &lt;strong&gt;Installation of Libtorch with OpenCV in Windows/Linux/OSX&lt;/strong&gt;. I&amp;rsquo;ve had nightmares setting up the Windows system myself for &lt;code&gt;Libtorch&lt;/code&gt; and nothing could be better than using &lt;code&gt;Docker&lt;/code&gt;. Read on, to know why.&lt;/p&gt;</description>
    </item>
    <item>
      <title>[Training and Results] Deep Convolutional Generative Adversarial Networks on CelebA Dataset using PyTorch C&#43;&#43; API</title>
      <link>https://krshrimali.github.io/posts/2020/02/training-and-results-deep-convolutional-generative-adversarial-networks-on-celeba-dataset-using-pytorch-c-api/</link>
      <pubDate>Sun, 23 Feb 2020 00:00:00 +0000</pubDate>
      <guid>https://krshrimali.github.io/posts/2020/02/training-and-results-deep-convolutional-generative-adversarial-networks-on-celeba-dataset-using-pytorch-c-api/</guid>
      <description>&lt;p&gt;It&amp;rsquo;s been around 5 months since I released my last blog on &lt;a href=&#34;https://krshrimali.github.io/posts/2019/09/deep-convolutional-generative-adversarial-networks-review-and-implementation-using-pytorch-c-api/&#34;&gt;DCGAN Review and Implementation using PyTorch C++ API&lt;/a&gt; and I&amp;rsquo;ve missed writing blogs badly! Straight the to the point, I&amp;rsquo;m back!&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Cover-DCGAN-2.jpg&#34;&gt;&lt;/p&gt;
&lt;p&gt;But before we start, the PyTorch C++ Frontend has gone through several changes and thanks to the awesome contributors around the world, it resembles the Python API more than it ever did! Since a lot of things have changed, I have also updated my previous blogs (tested on 1.4 Stable build).&lt;/p&gt;</description>
    </item>
    <item>
      <title>Deep Convolutional Generative Adversarial Networks: Review and Implementation using PyTorch C&#43;&#43; API</title>
      <link>https://krshrimali.github.io/posts/2019/09/deep-convolutional-generative-adversarial-networks-review-and-implementation-using-pytorch-c-api/</link>
      <pubDate>Sun, 15 Sep 2019 00:00:00 +0000</pubDate>
      <guid>https://krshrimali.github.io/posts/2019/09/deep-convolutional-generative-adversarial-networks-review-and-implementation-using-pytorch-c-api/</guid>
      <description>&lt;p&gt;I&amp;rsquo;m pleased to start a series of blogs on GANs and their implementation with PyTorch C++ API. We&amp;rsquo;ll be starting with one of the initial GANs - DCGANs (Deep Convolutional Generative Adversarial Networks).&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Cover-DCGAN.jpg&#34;&gt;&lt;/p&gt;
&lt;p&gt;The authors (Soumith Chintala, Radford and Luke Metz) in &lt;a href=&#34;https://arxiv.org/pdf/1511.06434.pdf&#34;&gt;this&lt;/a&gt; Seminal Paper on DCGANs introduced DCGANs to the world like this:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Setting up Jupyter Notebook (Xeus Cling) for Libtorch and OpenCV Libraries</title>
      <link>https://krshrimali.github.io/posts/2019/08/setting-up-jupyter-notebook-xeus-cling-for-libtorch-and-opencv-libraries/</link>
      <pubDate>Wed, 28 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://krshrimali.github.io/posts/2019/08/setting-up-jupyter-notebook-xeus-cling-for-libtorch-and-opencv-libraries/</guid>
      <description>&lt;h2 id=&#34;introduction-to-xeus-cling&#34;&gt;Introduction to Xeus Cling&lt;/h2&gt;
&lt;p&gt;Today, we are going to run our C++ codes in the Jupyter Notebook. Sounds ambitious? Not much. Let&amp;rsquo;s see how we do it using Xeus Cling.&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Cover-Xeus-Cling.jpg&#34;&gt;&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ll quote the definition of Xeus Cling on the official &lt;a href=&#34;https://xeus-cling.readthedocs.io/en/latest/#targetText=xeus%2Dcling%20is%20a%20Jupyter,of%20the%20Jupyter%20protocol%20xeus&#34;&gt;documentation website&lt;/a&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;xeus-cling is a Jupyter kernel for C++ based on the C++ interpreter cling and the native implementation of the Jupyter protocol xeus.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;Just like we use Python Kernel in the Jupyter Notebook, we can also use a C++ based interpreter cling combined with a Jupyter protocol called Xeus to reach closer to implementing C++ code in the notebook.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C&#43;&#43; API</title>
      <link>https://krshrimali.github.io/posts/2019/08/applying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api/</link>
      <pubDate>Fri, 16 Aug 2019 00:00:00 +0000</pubDate>
      <guid>https://krshrimali.github.io/posts/2019/08/applying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api/</guid>
      <description>&lt;h2 id=&#34;transfer-learning&#34;&gt;Transfer Learning&lt;/h2&gt;
&lt;p&gt;&amp;ndash;
Before we go ahead and discuss the &lt;strong&gt;Why&lt;/strong&gt; question of Transfer Learning, let&amp;rsquo;s have a look at &lt;strong&gt;What is Transfer Learning?&lt;/strong&gt; Let&amp;rsquo;s have a look at the &lt;a href=&#34;http://cs231n.github.io/transfer-learning&#34;&gt;Notes&lt;/a&gt; from CS231n on Transfer Learning:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Classifying Dogs vs Cats using PyTorch C&#43;&#43;: Part 2</title>
      <link>https://krshrimali.github.io/posts/2019/07/classifying-dogs-vs-cats-using-pytorch-c-part-2/</link>
      <pubDate>Wed, 31 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://krshrimali.github.io/posts/2019/07/classifying-dogs-vs-cats-using-pytorch-c-part-2/</guid>
      <description>&lt;p&gt;In the last blog, we had discussed all but training and results of our custom CNN network on Dogs vs Cats dataset. Today, we&amp;rsquo;ll be making some small changes in the network and discussing training and results of the task.&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Classify-Dogs-Cats-Blog-05.jpg&#34;&gt;&lt;/p&gt;
&lt;p&gt;I&amp;rsquo;ll start with the network overview again, where we used a network similar to VGG-16 (with one extra Fully Connected Layer in the end). While there are absolutely no problems with that network, but since the dataset contains a lot of images (25000 in training dataset) and we were using (200x200x3) input shape to the network (which is 120,000 floating point numbers), this leads to high memory consumption. In short, I was out of RAM to store these many images during program execution.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Classifying Dogs vs Cats using PyTorch C&#43;&#43; API: Part-1</title>
      <link>https://krshrimali.github.io/posts/2019/07/classifying-dogs-vs-cats-using-pytorch-c-api-part-1/</link>
      <pubDate>Tue, 23 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://krshrimali.github.io/posts/2019/07/classifying-dogs-vs-cats-using-pytorch-c-api-part-1/</guid>
      <description>&lt;p&gt;Hi Everyone! So excited to be back with another blog in the series of PyTorch C++ Blogs.&lt;/p&gt;
&lt;p&gt;Today, we are going to see a practical example of applying a CNN to a Custom Dataset - Dogs vs Cats. This is going to be a short post of showing results and discussion about hyperparameters and loss functions for the task, as code snippets and explanation has been provided &lt;a href=&#34;https://krshrimali.github.io/Training-Network-Using-Custom-Dataset-PyTorch-CPP/&#34;&gt;here&lt;/a&gt;, &lt;a href=&#34;https://krshrimali.github.io/Custom-Data-Loading-Using-PyTorch-CPP-API/&#34;&gt;here&lt;/a&gt; and &lt;a href=&#34;https://krshrimali.github.io/PyTorch-C&amp;#43;&amp;#43;-API/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Cover-Dogs-Cats.jpg&#34;&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>Training a Network on Custom Dataset using PyTorch C&#43;&#43; API</title>
      <link>https://krshrimali.github.io/posts/2019/07/training-a-network-on-custom-dataset-using-pytorch-c-api/</link>
      <pubDate>Fri, 05 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://krshrimali.github.io/posts/2019/07/training-a-network-on-custom-dataset-using-pytorch-c-api/</guid>
      <description>&lt;h2 id=&#34;recap-of-the-last-blog&#34;&gt;Recap of the last blog&lt;/h2&gt;
&lt;p&gt;Before we move on, it&amp;rsquo;s important what we covered in the last blog. We&amp;rsquo;ll be going forward from loading Custom Dataset to now using the dataset to train our VGG-16 Network. Previously, we were able to load our custom dataset using the following template:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Announcing a series of blogs on PyTorch C&#43;&#43; API</title>
      <link>https://krshrimali.github.io/posts/2019/07/announcing-a-series-of-blogs-on-pytorch-c-api/</link>
      <pubDate>Thu, 04 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://krshrimali.github.io/posts/2019/07/announcing-a-series-of-blogs-on-pytorch-c-api/</guid>
      <description>&lt;p&gt;&lt;strong&gt;I&amp;rsquo;m happy to announce a Series of Blog Posts on PyTorch C++ API&lt;/strong&gt;. Check out the blogs in the series &lt;a href=&#34;https://krshrimali.github.io/categories/pytorch/&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Happy Reading!&lt;/p&gt;</description>
    </item>
    <item>
      <title>Custom Data Loading using PyTorch C&#43;&#43; API</title>
      <link>https://krshrimali.github.io/posts/2019/07/custom-data-loading-using-pytorch-c-api/</link>
      <pubDate>Tue, 02 Jul 2019 00:00:00 +0000</pubDate>
      <guid>https://krshrimali.github.io/posts/2019/07/custom-data-loading-using-pytorch-c-api/</guid>
      <description>&lt;h2 id=&#34;overview-how-c-api-loads-data&#34;&gt;Overview: How C++ API loads data?&lt;/h2&gt;
&lt;p&gt;&lt;img loading=&#34;lazy&#34; src=&#34;https://raw.githubusercontent.com/krshrimali/blog/main/assets/cover-images/Cover-Custom-Data.png&#34;&gt;&lt;/p&gt;
&lt;p&gt;In the last blog, we discussed application of a VGG-16 Network on MNIST Data. For those, who are reading this blog for the first time, here is how we had loaded MNIST data:&lt;/p&gt;
&lt;div class=&#34;highlight&#34;&gt;&lt;pre tabindex=&#34;0&#34; style=&#34;color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;&#34;&gt;&lt;code class=&#34;language-cpp&#34; data-lang=&#34;cpp&#34;&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;&lt;span style=&#34;color:#66d9ef&#34;&gt;auto&lt;/span&gt; data_loader &lt;span style=&#34;color:#f92672&#34;&gt;=&lt;/span&gt; torch&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;make_data_loader&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&lt;/span&gt;torch&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;samplers&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;SequentialSampler&lt;span style=&#34;color:#f92672&#34;&gt;&amp;gt;&lt;/span&gt;(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;			std&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;move(torch&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;datasets&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;MNIST(&lt;span style=&#34;color:#e6db74&#34;&gt;&amp;#34;../../data&amp;#34;&lt;/span&gt;).map(torch&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;transforms&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;Normalize&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;gt;&lt;/span&gt;(&lt;span style=&#34;color:#ae81ff&#34;&gt;0.13707&lt;/span&gt;, &lt;span style=&#34;color:#ae81ff&#34;&gt;0.3081&lt;/span&gt;))).map(
&lt;/span&gt;&lt;/span&gt;&lt;span style=&#34;display:flex;&#34;&gt;&lt;span&gt;				torch&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;data&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;transforms&lt;span style=&#34;color:#f92672&#34;&gt;::&lt;/span&gt;Stack&lt;span style=&#34;color:#f92672&#34;&gt;&amp;lt;&amp;gt;&lt;/span&gt;()), &lt;span style=&#34;color:#ae81ff&#34;&gt;64&lt;/span&gt;);
&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;p&gt;Let&amp;rsquo;s break this piece by piece, as for beginners, this may be unclear. First, we ask the C++ API to load data (images and labels) into tensors.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
