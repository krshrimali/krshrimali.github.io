<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>Pytorch-Cpp | Kushashwa Ravi Shrimali (Kush)</title>
<meta name="keywords" content="">
<meta name="description" content="">
<meta name="author" content="map[name:Kushashwa Ravi Shrimali]">
<link rel="canonical" href="https://krshrimali.github.io/tags/pytorch-cpp/">
<link crossorigin="anonymous" href="https://krshrimali.github.io/assets/css/stylesheet.8fe10233a706bc87f2e08b3cf97b8bd4c0a80f10675a143675d59212121037c0.css" integrity="sha256-j&#43;ECM6cGvIfy4Is8&#43;XuL1MCoDxBnWhQ2ddWSEhIQN8A=" rel="preload stylesheet" as="style">
<link rel="icon" href="https://krshrimali.github.io/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://krshrimali.github.io/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://krshrimali.github.io/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://krshrimali.github.io/apple-touch-icon.png">
<link rel="mask-icon" href="https://krshrimali.github.io/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" type="application/rss+xml" href="https://krshrimali.github.io/tags/pytorch-cpp/index.xml">
<link rel="alternate" hreflang="en" href="https://krshrimali.github.io/tags/pytorch-cpp/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --code-block-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript><meta property="og:url" content="https://krshrimali.github.io/tags/pytorch-cpp/">
  <meta property="og:site_name" content="Kushashwa Ravi Shrimali (Kush)">
  <meta property="og:title" content="Pytorch-Cpp">
  <meta property="og:locale" content="en">
  <meta property="og:type" content="website">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Pytorch-Cpp">
<meta name="twitter:description" content="">

</head>

<body class="list" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://krshrimali.github.io/" accesskey="h" title="Kushashwa Ravi Shrimali (Kush) (Alt + H)">Kushashwa Ravi Shrimali (Kush)</a>
            <div class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)" aria-label="Toggle theme">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="https://krshrimali.github.io/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
            <li>
                <a href="https://krshrimali.github.io/about" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="https://krshrimali.github.io/posts" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main"> 
<header class="page-header"><div class="breadcrumbs"><a href="https://krshrimali.github.io/">Home</a>&nbsp;»&nbsp;<a href="https://krshrimali.github.io/tags/">Tags</a></div>
  <h1>
    Pytorch-Cpp
    <a href="https://krshrimali.github.io/tags/pytorch-cpp/index.xml" title="RSS" aria-label="RSS">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2"
        stroke-linecap="round" stroke-linejoin="round" height="23">
        <path d="M4 11a9 9 0 0 1 9 9" />
        <path d="M4 4a16 16 0 0 1 16 16" />
        <circle cx="5" cy="19" r="1" />
      </svg>
    </a>
  </h1>
</header>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Releasing Docker Container and Binder for using Xeus-Cling, Libtorch and OpenCV in C&#43;&#43;
    </h2>
  </header>
  <div class="entry-content">
    <p>Today, I am elated to share Docker image for OpenCV, Libtorch and Xeus-Cling. We’ll discuss how to use the dockerfile and binder.
Before I move on, the credits for creating and maintaining Docker image goes to Vishwesh Ravi Shrimali. He has been working on some cool stuff, please do get in touch with him if you’re interested to know.
First question in your mind would be, Why use Docker or Binder? The answer to it lies in the frequency of queries on the discussion forum of PyTorch and Stackoverflow on Installation of Libtorch with OpenCV in Windows/Linux/OSX. I’ve had nightmares setting up the Windows system myself for Libtorch and nothing could be better than using Docker. Read on, to know why.
...</p>
  </div>
  <footer class="entry-footer"><span title='2020-09-15 00:00:00 +0000 UTC'>September 15, 2020</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;map[name:Kushashwa Ravi Shrimali]</footer>
  <a class="entry-link" aria-label="post link to Releasing Docker Container and Binder for using Xeus-Cling, Libtorch and OpenCV in C&#43;&#43;" href="https://krshrimali.github.io/posts/2020/09/releasing-docker-container-and-binder-for-using-xeus-cling-libtorch-and-opencv-in-c-/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">[Training and Results] Deep Convolutional Generative Adversarial Networks on CelebA Dataset using PyTorch C&#43;&#43; API
    </h2>
  </header>
  <div class="entry-content">
    <p>It’s been around 5 months since I released my last blog on DCGAN Review and Implementation using PyTorch C&#43;&#43; API and I’ve missed writing blogs badly! Straight the to the point, I’m back!
But before we start, the PyTorch C&#43;&#43; Frontend has gone through several changes and thanks to the awesome contributors around the world, it resembles the Python API more than it ever did! Since a lot of things have changed, I have also updated my previous blogs (tested on 1.4 Stable build).
...</p>
  </div>
  <footer class="entry-footer"><span title='2020-02-23 00:00:00 +0000 UTC'>February 23, 2020</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;map[name:Kushashwa Ravi Shrimali]</footer>
  <a class="entry-link" aria-label="post link to [Training and Results] Deep Convolutional Generative Adversarial Networks on CelebA Dataset using PyTorch C&#43;&#43; API" href="https://krshrimali.github.io/posts/2020/02/training-and-results-deep-convolutional-generative-adversarial-networks-on-celeba-dataset-using-pytorch-c-api/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Deep Convolutional Generative Adversarial Networks: Review and Implementation using PyTorch C&#43;&#43; API
    </h2>
  </header>
  <div class="entry-content">
    <p>I’m pleased to start a series of blogs on GANs and their implementation with PyTorch C&#43;&#43; API. We’ll be starting with one of the initial GANs - DCGANs (Deep Convolutional Generative Adversarial Networks).
The authors (Soumith Chintala, Radford and Luke Metz) in this Seminal Paper on DCGANs introduced DCGANs to the world like this:
We introduce a class of CNNs called deep convolutional generative adversarial networks (DCGANs), that have certain architectural constraints, and demonstrate that they are a strong candidate for unsupervised learning. Training on various image datasets, we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator. Additionally, we use the learned features for novel tasks - demonstrating their applicability as general image representations.
...</p>
  </div>
  <footer class="entry-footer"><span title='2019-09-15 00:00:00 +0000 UTC'>September 15, 2019</span>&nbsp;·&nbsp;10 min&nbsp;·&nbsp;map[name:Kushashwa Ravi Shrimali]</footer>
  <a class="entry-link" aria-label="post link to Deep Convolutional Generative Adversarial Networks: Review and Implementation using PyTorch C&#43;&#43; API" href="https://krshrimali.github.io/posts/2019/09/deep-convolutional-generative-adversarial-networks-review-and-implementation-using-pytorch-c-api/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Setting up Jupyter Notebook (Xeus Cling) for Libtorch and OpenCV Libraries
    </h2>
  </header>
  <div class="entry-content">
    <p>Introduction to Xeus Cling Today, we are going to run our C&#43;&#43; codes in the Jupyter Notebook. Sounds ambitious? Not much. Let’s see how we do it using Xeus Cling.
I’ll quote the definition of Xeus Cling on the official documentation website.
xeus-cling is a Jupyter kernel for C&#43;&#43; based on the C&#43;&#43; interpreter cling and the native implementation of the Jupyter protocol xeus.
Just like we use Python Kernel in the Jupyter Notebook, we can also use a C&#43;&#43; based interpreter cling combined with a Jupyter protocol called Xeus to reach closer to implementing C&#43;&#43; code in the notebook.
...</p>
  </div>
  <footer class="entry-footer"><span title='2019-08-28 00:00:00 +0000 UTC'>August 28, 2019</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;map[name:Kushashwa Ravi Shrimali]</footer>
  <a class="entry-link" aria-label="post link to Setting up Jupyter Notebook (Xeus Cling) for Libtorch and OpenCV Libraries" href="https://krshrimali.github.io/posts/2019/08/setting-up-jupyter-notebook-xeus-cling-for-libtorch-and-opencv-libraries/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C&#43;&#43; API
    </h2>
  </header>
  <div class="entry-content">
    <p>Transfer Learning – Before we go ahead and discuss the Why question of Transfer Learning, let’s have a look at What is Transfer Learning? Let’s have a look at the Notes from CS231n on Transfer Learning:
In practice, very few people train an entire Convolutional Network from scratch (with random initialization), because it is relatively rare to have a dataset of sufficient size. Instead, it is common to pretrain a ConvNet on a very large dataset (e.g. ImageNet, which contains 1.2 million images with 1000 categories), and then use the ConvNet either as an initialization or a fixed feature extractor for the task of interest.
...</p>
  </div>
  <footer class="entry-footer"><span title='2019-08-16 00:00:00 +0000 UTC'>August 16, 2019</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;map[name:Kushashwa Ravi Shrimali]</footer>
  <a class="entry-link" aria-label="post link to Applying Transfer Learning on Dogs vs Cats Dataset (ResNet18) using PyTorch C&#43;&#43; API" href="https://krshrimali.github.io/posts/2019/08/applying-transfer-learning-on-dogs-vs-cats-dataset-resnet18-using-pytorch-c-api/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Classifying Dogs vs Cats using PyTorch C&#43;&#43;: Part 2
    </h2>
  </header>
  <div class="entry-content">
    <p>In the last blog, we had discussed all but training and results of our custom CNN network on Dogs vs Cats dataset. Today, we’ll be making some small changes in the network and discussing training and results of the task.
I’ll start with the network overview again, where we used a network similar to VGG-16 (with one extra Fully Connected Layer in the end). While there are absolutely no problems with that network, but since the dataset contains a lot of images (25000 in training dataset) and we were using (200x200x3) input shape to the network (which is 120,000 floating point numbers), this leads to high memory consumption. In short, I was out of RAM to store these many images during program execution.
...</p>
  </div>
  <footer class="entry-footer"><span title='2019-07-31 00:00:00 +0000 UTC'>July 31, 2019</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;map[name:Kushashwa Ravi Shrimali]</footer>
  <a class="entry-link" aria-label="post link to Classifying Dogs vs Cats using PyTorch C&#43;&#43;: Part 2" href="https://krshrimali.github.io/posts/2019/07/classifying-dogs-vs-cats-using-pytorch-c-part-2/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Classifying Dogs vs Cats using PyTorch C&#43;&#43; API: Part-1
    </h2>
  </header>
  <div class="entry-content">
    <p>Hi Everyone! So excited to be back with another blog in the series of PyTorch C&#43;&#43; Blogs.
Today, we are going to see a practical example of applying a CNN to a Custom Dataset - Dogs vs Cats. This is going to be a short post of showing results and discussion about hyperparameters and loss functions for the task, as code snippets and explanation has been provided here, here and here.
...</p>
  </div>
  <footer class="entry-footer"><span title='2019-07-23 00:00:00 +0000 UTC'>July 23, 2019</span>&nbsp;·&nbsp;7 min&nbsp;·&nbsp;map[name:Kushashwa Ravi Shrimali]</footer>
  <a class="entry-link" aria-label="post link to Classifying Dogs vs Cats using PyTorch C&#43;&#43; API: Part-1" href="https://krshrimali.github.io/posts/2019/07/classifying-dogs-vs-cats-using-pytorch-c-api-part-1/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Training a Network on Custom Dataset using PyTorch C&#43;&#43; API
    </h2>
  </header>
  <div class="entry-content">
    <p>Recap of the last blog Before we move on, it’s important what we covered in the last blog. We’ll be going forward from loading Custom Dataset to now using the dataset to train our VGG-16 Network. Previously, we were able to load our custom dataset using the following template:
...</p>
  </div>
  <footer class="entry-footer"><span title='2019-07-05 00:00:00 +0000 UTC'>July 5, 2019</span>&nbsp;·&nbsp;4 min&nbsp;·&nbsp;map[name:Kushashwa Ravi Shrimali]</footer>
  <a class="entry-link" aria-label="post link to Training a Network on Custom Dataset using PyTorch C&#43;&#43; API" href="https://krshrimali.github.io/posts/2019/07/training-a-network-on-custom-dataset-using-pytorch-c-api/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Announcing a series of blogs on PyTorch C&#43;&#43; API
    </h2>
  </header>
  <div class="entry-content">
    <p>I’m happy to announce a Series of Blog Posts on PyTorch C&#43;&#43; API. Check out the blogs in the series here.
Happy Reading!
</p>
  </div>
  <footer class="entry-footer"><span title='2019-07-04 00:00:00 +0000 UTC'>July 4, 2019</span>&nbsp;·&nbsp;1 min&nbsp;·&nbsp;map[name:Kushashwa Ravi Shrimali]</footer>
  <a class="entry-link" aria-label="post link to Announcing a series of blogs on PyTorch C&#43;&#43; API" href="https://krshrimali.github.io/posts/2019/07/announcing-a-series-of-blogs-on-pytorch-c-api/"></a>
</article>

<article class="post-entry tag-entry"> 
  <header class="entry-header">
    <h2 class="entry-hint-parent">Custom Data Loading using PyTorch C&#43;&#43; API
    </h2>
  </header>
  <div class="entry-content">
    <p>Overview: How C&#43;&#43; API loads data? In the last blog, we discussed application of a VGG-16 Network on MNIST Data. For those, who are reading this blog for the first time, here is how we had loaded MNIST data:
auto data_loader = torch::data::make_data_loader&lt;torch::data::samplers::SequentialSampler&gt;( std::move(torch::data::datasets::MNIST(&#34;../../data&#34;).map(torch::data::transforms::Normalize&lt;&gt;(0.13707, 0.3081))).map( torch::data::transforms::Stack&lt;&gt;()), 64); Let’s break this piece by piece, as for beginners, this may be unclear. First, we ask the C&#43;&#43; API to load data (images and labels) into tensors.
...</p>
  </div>
  <footer class="entry-footer"><span title='2019-07-02 00:00:00 +0000 UTC'>July 2, 2019</span>&nbsp;·&nbsp;8 min&nbsp;·&nbsp;map[name:Kushashwa Ravi Shrimali]</footer>
  <a class="entry-link" aria-label="post link to Custom Data Loading using PyTorch C&#43;&#43; API" href="https://krshrimali.github.io/posts/2019/07/custom-data-loading-using-pytorch-c-api/"></a>
</article>
<footer class="page-footer">
  <nav class="pagination">
    <a class="next" href="https://krshrimali.github.io/tags/pytorch-cpp/page/2/">Next&nbsp;&nbsp;»
    </a>
  </nav>
</footer>
    </main>
    
<footer class="footer">
        <span>This work is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License.</span> · 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
